{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Credentials"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "!mkdir ~/.aws"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/cyprien/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/.aws/credentials\n",
    "\n",
    "[default]\n",
    "aws_access_key_id=\n",
    "aws_secret_access_key="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/cyprien/.aws/config\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/.aws/config\n",
    "\n",
    "[default]\n",
    "region=eu-west-3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export to s3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21097/21097 [10:27<00:00, 33.60it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "\n",
    "def export_files_to_s3(bucket_name, s3_prefix, local_folder, file_extensions):\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Create a ThreadPoolExecutor with a certain number of threads\n",
    "    with ProcessPoolExecutor(max_workers=100) as executor:\n",
    "      # Iterate through all the files in the folder\n",
    "        for filename in tqdm(os.listdir(folder_path)):\n",
    "        # Check if the file has the desired extension\n",
    "            if any([filename.endswith(file_extension) for file_extension in file_extensions]):\n",
    "              # Construct the full path to the file\n",
    "              file_path = os.path.join(folder_path, filename)\n",
    "              # Construct the full S3 object key (including the path within the bucket)\n",
    "              s3_key = os.path.join(s3_prefix, filename)\n",
    "              # Check if the file already exists in the S3 bucket\n",
    "            try:\n",
    "                s3_object = s3.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "                # If the file exists, check if the size of the local file is the same as the size of the S3 object\n",
    "                if os.path.getsize(file_path) == s3_object['ContentLength']:\n",
    "                # If the sizes are the same, skip the file\n",
    "                    continue\n",
    "            except s3.exceptions.ClientError as e:\n",
    "              # If the file does not exist, or if there is any other error, catch the exception and proceed with the upload\n",
    "                pass # TODO\n",
    "\n",
    "            # Submit a task to the executor to upload the file to S3\n",
    "            executor.submit(s3.upload_file, file_path, bucket_name, s3_key)\n",
    "\n",
    "\n",
    "bucket_name = 'basalt-neurips'\n",
    "folder_path = '../../basalt_neurips_data/MineRLBasaltMakeWaterfall-v0/'\n",
    "s3_prefix = 'basalt_neurips_data/MineRLBasaltMakeWaterfall-v0/'\n",
    "\n",
    "export_files_to_s3(bucket_name, s3_prefix, folder_path, [pp_video, pp_actions, pp_annotations])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import from s3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.invalid_files import pp_video, pp_actions, pp_annotations\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_files_from_s3(bucket_name, s3_prefix, local_folder, file_extensions):\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # List all the objects in the specified S3 prefix\n",
    "    objects = s3.list_objects(Bucket=bucket_name, Prefix=s3_prefix)\n",
    "\n",
    "    # Create a ThreadPoolExecutor with a certain number of threads\n",
    "    with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        # Iterate through the objects\n",
    "        for obj in objects['Contents']:\n",
    "            # Get the object key (i.e., the file name)\n",
    "            key = obj['Key']\n",
    "            # Check if the file has the desired extension\n",
    "            if any([key.endswith(file_extension) for file_extension in file_extensions]):\n",
    "                # Construct the full path to the local file\n",
    "                local_file_path = os.path.join(local_folder, key)\n",
    "                # Check if the file already exists locally\n",
    "                try:\n",
    "                    local_file_size = os.path.getsize(local_file_path)\n",
    "                    # If the file exists, check if the size of the local file is the same as the size of the S3 object\n",
    "                    if local_file_size == obj['Size']:\n",
    "                        # If the sizes are the same, skip the file\n",
    "                        continue\n",
    "                except FileNotFoundError:\n",
    "                    # If the file does not exist, proceed with the download\n",
    "                    pass\n",
    "                # Submit a task to the executor to download the file from S3\n",
    "                future = executor.submit(s3.download_file, bucket_name, key, local_file_path)\n",
    "\n",
    "\n",
    "download_files_from_s3('basalt-neurips', 'basalt_neurips_data/MineRLBasaltMakeWaterfall-v0/', '../../basalt_neurips_data/MineRLBasaltMakeWaterfall-v0/', [pp_video, pp_actions, pp_annotations])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
