{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load original"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "out_weights = \"../data/agent_st/foundation-model-tl-tt-2x.weights\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('net.img_process.cnn.stacks.0.firstconv.layer.weight',\n              tensor([[[[ 3.7042e-02, -6.4809e-02, -5.1988e-02],\n                        [-8.3571e-02, -1.9411e-02,  4.0863e-02],\n                        [-3.2426e-02,  7.7259e-02,  4.8328e-02]],\n              \n                       [[ 4.0237e-02, -5.8202e-02, -6.2113e-02],\n                        [-8.3681e-02, -4.0295e-02,  3.2863e-02],\n                        [-2.9362e-02,  6.6627e-02,  7.6046e-02]],\n              \n                       [[ 3.0695e-02,  2.5573e-02,  5.4368e-03],\n                        [ 1.7040e-02, -9.2496e-03, -2.1626e-03],\n                        [-2.7389e-03, -2.8656e-02, -1.8573e-02]]],\n              \n              \n                      [[[ 3.1902e-02,  3.0894e-02, -3.6394e-02],\n                        [-9.3464e-03, -2.1614e-02, -3.6015e-02],\n                        [-3.7105e-02, -2.7153e-02,  1.0896e-02]],\n              \n                       [[ 7.7584e-02,  1.5076e-02, -1.4173e-02],\n                        [-1.0305e-02, -4.7940e-02, -3.6105e-02],\n                        [-2.7824e-02, -3.0610e-02,  2.2853e-02]],\n              \n                       [[ 2.2796e-02, -2.2931e-02, -1.6135e-02],\n                        [ 7.7290e-03, -2.4601e-03,  4.5620e-03],\n                        [-2.2324e-02, -1.8125e-02, -1.1028e-03]]],\n              \n              \n                      [[[ 7.7679e-02, -8.4451e-02,  1.5624e-02],\n                        [ 4.1986e-05,  1.5368e-04, -9.2990e-04],\n                        [ 1.5219e-03,  7.7773e-04,  4.7136e-04]],\n              \n                       [[ 7.2543e-02, -8.6760e-02,  1.9711e-02],\n                        [-9.4831e-04,  5.4184e-04, -1.4984e-04],\n                        [ 4.4069e-04, -7.2804e-04, -5.1567e-04]],\n              \n                       [[ 5.9815e-02, -6.5361e-02,  1.8574e-02],\n                        [-2.7425e-03,  1.4605e-03,  3.1974e-04],\n                        [-8.8940e-04, -8.1342e-04,  8.2515e-05]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 7.1144e-04,  1.3114e-03, -5.0222e-04],\n                        [ 6.9484e-02,  2.9384e-03,  1.0901e-03],\n                        [ 1.9111e-03,  2.1445e-03, -1.0576e-03]],\n              \n                       [[ 2.2441e-03,  5.1004e-06,  5.9700e-05],\n                        [ 9.0654e-02,  4.6066e-03, -8.2664e-04],\n                        [ 1.5425e-03, -2.3893e-03,  1.8542e-04]],\n              \n                       [[-4.8532e-03, -1.7768e-03,  1.7634e-03],\n                        [ 2.6758e-02, -1.6066e-03, -1.5657e-03],\n                        [-8.0794e-03,  1.5348e-05,  1.3077e-03]]],\n              \n              \n                      [[[ 2.1881e-05, -1.8135e-04,  2.9610e-04],\n                        [ 2.2678e-04,  9.9105e-02, -9.9624e-02],\n                        [-2.3179e-04,  1.1953e-05,  3.3366e-04]],\n              \n                       [[-7.2976e-05,  5.9556e-04, -4.1270e-04],\n                        [ 7.1770e-04,  1.3174e-01, -1.3211e-01],\n                        [-7.7791e-04,  3.6865e-04, -2.4248e-04]],\n              \n                       [[ 2.9554e-05, -2.4135e-03,  1.9973e-03],\n                        [ 4.5726e-05,  1.0915e-01, -1.0834e-01],\n                        [-4.6438e-05, -2.8058e-03,  2.3853e-03]]],\n              \n              \n                      [[[-5.6255e-04,  1.8123e-04, -3.9624e-04],\n                        [-4.5412e-04,  5.2158e-04, -6.1256e-05],\n                        [-8.7680e-02,  8.8221e-02, -2.6279e-04]],\n              \n                       [[-2.3937e-04,  3.1429e-04, -1.6769e-05],\n                        [-3.5449e-04,  6.7046e-04, -1.4662e-04],\n                        [-1.0251e-01,  1.0250e-01, -7.5124e-04]],\n              \n                       [[ 1.1713e-03, -1.4475e-03,  4.4007e-04],\n                        [ 2.5345e-03, -1.6914e-03,  2.2496e-04],\n                        [-7.9808e-02,  8.0847e-02,  1.2818e-04]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.firstconv.layer.bias',\n              tensor([ 8.9364e-02,  1.9560e-01,  3.1461e-02, -7.5377e-02,  1.5321e-01,\n                       3.9688e-02, -6.4963e-02,  7.6433e-01,  5.4786e-02,  1.5814e-01,\n                       1.5993e-02,  2.6910e-03,  2.5207e-04,  4.2185e-04,  4.5748e-03,\n                       5.2428e-02,  4.6000e-02, -5.2184e-02, -3.0920e-02,  6.6608e-03,\n                       3.6515e-02,  1.6075e-04,  3.9192e-04,  2.0888e-02,  1.4698e-01,\n                       1.6603e-01, -7.6356e-02,  1.1456e-02,  3.6714e-03,  2.9537e-02,\n                       3.6182e-02,  1.5132e-03, -1.1033e-01,  6.5416e-03, -5.1902e-02,\n                       3.3705e-04,  9.8279e-03,  2.9156e-02,  4.0848e-01,  3.9275e-02,\n                       6.7363e-03, -7.6707e-02,  5.3422e-02, -6.3436e-02,  6.3744e-04,\n                       1.8041e-01,  3.4981e-02,  3.5870e-03,  5.9824e-01, -3.6681e-03,\n                      -2.2425e-02,  4.1102e-02, -1.3872e-01, -2.2906e-02,  6.0816e-01,\n                       1.6512e-05,  7.5189e-03,  1.6029e-01,  1.5421e-03,  1.0481e-03,\n                       2.8231e-04,  1.5558e-01,  5.0029e-01,  3.3740e-03,  3.7688e-02,\n                      -1.3833e-01, -6.7380e-02,  4.8336e-02,  4.2752e-02,  6.6330e-02,\n                       1.8892e-03,  3.5229e-03,  7.2804e-03, -5.5078e-02,  1.6462e-01,\n                       4.2460e-03,  1.2994e-01,  1.6160e-01,  3.7134e-02,  1.8651e-03,\n                       3.6258e-02,  3.4646e-02, -8.8639e-02,  1.1629e-02,  3.7818e-03,\n                       1.4361e-02, -1.2488e-01,  5.7673e-03,  1.2650e-01,  7.0035e-01,\n                      -5.3692e-01,  3.5025e-02,  2.4600e-01,  1.0486e-03, -8.1658e-04,\n                       5.9949e-02,  4.2421e-03,  5.6483e-02,  1.7477e-01,  4.2325e-03,\n                       3.7934e-02,  1.0244e-02,  1.6852e-03,  7.3782e-03,  5.2500e-03,\n                       1.3953e-01,  1.2005e-02,  2.5357e-04,  8.1295e-03,  1.5551e-03,\n                      -2.2209e-02,  1.4418e-01,  3.4709e-03,  8.4672e-02,  3.4834e-02,\n                       6.2465e-04, -1.0522e-01,  4.1922e-03,  1.7758e-01,  3.2227e-02,\n                       1.3529e-02,  1.6160e-01,  1.3939e-01,  1.8718e-03, -4.8225e-03,\n                       4.3032e-01,  5.3817e-04,  6.8180e-02], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.n.weight',\n              tensor([0.5698, 0.1654, 1.5156, 1.6294, 0.8865, 0.4867, 1.0917, 0.2618, 1.1063,\n                      0.4269, 0.9857, 0.7552, 1.2786, 1.1971, 1.5865, 1.5616, 0.6640, 1.0392,\n                      0.6232, 0.6582, 1.1034, 0.0931, 0.6748, 0.4976, 0.4476, 0.8325, 1.1446,\n                      1.4386, 0.9243, 1.2589, 0.3868, 0.8662, 1.0696, 0.8001, 1.0373, 1.5782,\n                      0.7990, 0.5222, 0.3431, 0.2143, 0.4787, 1.0433, 0.7252, 1.0319, 1.1070,\n                      0.5928, 0.2333, 0.7178, 0.3458, 0.8042, 1.0820, 0.2590, 1.1579, 0.3333,\n                      0.3396, 1.0509, 0.1666, 0.4994, 1.1720, 1.0860, 1.1466, 0.4058, 1.1748,\n                      1.1834, 1.1850, 1.0274, 0.9405, 0.4941, 0.4931, 0.2419, 0.8771, 1.1286,\n                      0.7943, 1.1440, 0.4291, 1.2487, 0.6381, 0.8930, 1.6586, 0.2232, 1.1027,\n                      0.0837, 1.0208, 0.8254, 1.5140, 1.1074, 1.0581, 1.2117, 1.0583, 0.4866,\n                      0.1388, 0.7246, 0.5554, 1.0944, 0.6001, 0.1347, 0.2185, 0.8752, 0.8560,\n                      1.0914, 0.9355, 1.2625, 1.0251, 0.9005, 1.3477, 0.1384, 0.9462, 1.5746,\n                      0.4888, 1.2142, 0.5956, 0.7722, 0.4272, 1.3550, 1.2319, 1.1014, 1.1247,\n                      1.4141, 0.6103, 0.7282, 1.0460, 0.5242, 0.2178, 0.9069, 0.2564, 0.3996,\n                      0.5066, 0.5357], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.n.bias',\n              tensor([-0.1330, -0.2290,  0.0045, -0.3610, -0.7663, -0.2011,  0.1779, -1.4856,\n                      -0.1308, -0.4907,  0.0697, -0.0760,  0.1487,  0.2540,  0.3665, -0.1239,\n                      -0.1332,  0.2438,  0.0609, -0.0902,  0.3050, -0.3703, -0.0518,  0.0428,\n                      -0.4064, -0.7214, -0.1222,  0.1545,  0.0331,  0.0915, -0.1721,  0.1081,\n                      -0.5207, -0.0186,  0.2094,  0.3905,  0.0289, -0.1164, -0.5015, -0.1777,\n                      -0.0740,  0.1968,  0.0881,  0.1636,  0.1821, -0.6816, -0.1786,  0.0730,\n                      -1.7497,  0.0560,  0.1815, -0.1701,  0.0231, -0.0341, -1.6788,  0.1230,\n                      -0.0846, -0.4482,  0.2012,  0.0980,  0.1470, -0.4548, -0.0373,  0.1485,\n                       0.0698,  0.1842,  0.1941, -0.1229, -0.1392, -0.1553, -0.0236,  0.2161,\n                       0.1166,  0.2695, -0.4548,  0.2352, -0.1903, -0.8313,  0.0147, -0.1579,\n                      -0.0263, -0.1178,  0.1867,  0.0808,  0.3557, -0.0355,  0.1726,  0.0523,\n                      -0.0858, -1.1769, -0.2407, -0.0941, -1.2114,  0.1621, -0.0630, -0.2059,\n                      -0.1645, -0.1350, -0.7338,  0.1710, -0.1369,  0.2552,  0.1697,  0.0447,\n                       0.1976, -0.1473,  0.0516,  0.3429, -0.1190,  0.2514, -0.0265, -0.6132,\n                      -0.1145, -0.2201, -0.0029,  0.1570,  0.1803,  0.2959, -0.6383, -0.0621,\n                       0.0385, -0.5809,  0.0056, -0.0397, -0.0955, -1.5529, -0.1831, -0.2789],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv0.norm.weight',\n              tensor([0.4887, 1.4877, 0.4024, 0.2125, 1.4079, 0.7988, 1.1688, 2.5025, 1.4501,\n                      2.7172, 0.7861, 0.3633, 0.7165, 2.1884, 1.6905, 1.6893, 1.8865, 2.4289,\n                      0.6059, 0.4843, 0.4587, 2.5913, 1.2910, 0.4303, 2.5589, 1.5490, 0.9433,\n                      0.5090, 0.4351, 0.3901, 1.0287, 1.0021, 0.2558, 0.7443, 1.3205, 1.6135,\n                      0.4876, 0.5481, 1.0294, 1.3850, 0.8127, 1.3192, 0.5017, 0.9644, 0.8384,\n                      1.8028, 0.4529, 0.9629, 1.5785, 0.3715, 1.2385, 0.4303, 0.9974, 0.9269,\n                      1.9614, 0.8175, 1.3228, 2.2268, 1.3383, 0.3259, 0.6795, 2.4803, 0.2204,\n                      0.5268, 0.3067, 1.0515, 1.0134, 0.6529, 0.6017, 0.5974, 0.2938, 2.3532,\n                      0.7699, 2.3437, 2.9596, 2.0395, 0.1662, 1.2757, 0.2648, 1.8099, 0.6024,\n                      1.2153, 0.9641, 0.7520, 2.0907, 0.3039, 0.8923, 0.4773, 0.2680, 0.3276,\n                      1.5101, 0.4934, 0.8830, 1.7552, 0.5878, 2.0512, 1.1502, 0.4074, 1.5205,\n                      1.7366, 0.3693, 0.9184, 1.8891, 0.7582, 1.8217, 2.0049, 0.8450, 1.7856,\n                      0.4862, 1.8500, 0.4572, 1.7039, 0.7378, 0.2789, 0.3167, 0.8554, 1.1630,\n                      2.0490, 2.1769, 0.9087, 0.6839, 2.3797, 0.8842, 0.2675, 1.0763, 1.2230,\n                      1.1364, 1.2197], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv0.norm.bias',\n              tensor([-0.1978, -0.5475,  0.0755,  0.5223, -0.1120,  0.0803,  0.3820, -0.5021,\n                      -0.0245, -0.3726,  0.0840,  0.1472,  0.4722,  0.4955,  0.5097,  0.2712,\n                      -0.0402,  0.1722, -0.0187,  0.1268, -0.0361,  0.9437,  0.3982, -0.1752,\n                      -0.5896, -0.3212,  1.1782,  0.2329,  0.1431,  0.0412,  0.0311,  0.1054,\n                       0.5548,  0.2169,  0.2145,  0.5902,  0.0526, -0.0357, -1.2828, -0.1376,\n                       0.0592,  0.2734, -0.3409,  0.2673,  0.1830, -0.3195,  0.0345,  0.0897,\n                       0.4541,  0.0966,  0.3765, -0.0086,  0.0441, -0.1467,  0.4140,  0.2310,\n                      -0.3380, -0.6619,  0.4006,  0.1126,  0.2653, -0.3597, -1.9513,  0.1902,\n                      -0.0636,  0.2279,  0.0550, -0.0656, -0.0535,  0.0137,  0.1075,  0.4013,\n                       0.0626,  0.3404, -0.6671,  0.5081,  0.0427, -0.1008,  0.0740,  0.0276,\n                      -0.0128, -0.4018,  0.1888,  0.1601,  0.5624,  0.1405,  0.2493,  0.2856,\n                      -0.3333, -1.2397,  0.2704, -0.0054,  0.2223,  0.5504,  0.1752, -0.1916,\n                       0.0592, -0.0526, -0.5441,  0.3774,  0.0693,  0.3006,  0.3582,  0.1738,\n                       0.8271, -0.8286,  0.1710,  0.8772,  0.0810,  0.4109,  0.0651, -0.2945,\n                       0.0723, -0.1733,  0.0288,  0.2418,  0.4232,  0.6060, -0.4781, -0.0110,\n                       0.1982, -0.1841, -0.6731,  0.1227, -0.0792,  0.6288,  0.4829,  0.0477],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv0.layer.weight',\n              tensor([[[[ 8.2952e-04, -7.5227e-02, -9.7389e-03],\n                        [ 9.4680e-04, -8.7626e-02, -2.2677e-02],\n                        [ 6.0703e-02,  9.7919e-02, -3.2445e-03]],\n              \n                       [[-2.1258e-02, -1.2922e-01, -5.3830e-02],\n                        [-1.8662e-02, -1.6741e-01, -1.5901e-02],\n                        [-3.5482e-02,  1.6066e-02, -1.1042e-01]],\n              \n                       [[ 2.1035e-02,  3.6821e-02,  1.5213e-03],\n                        [ 2.3304e-02,  3.0900e-02,  4.5168e-03],\n                        [ 5.4353e-02,  8.8914e-02, -6.7360e-02]],\n              \n                       ...,\n              \n                       [[-4.3620e-02, -8.5792e-02,  2.3240e-02],\n                        [-5.0875e-02,  1.4000e-01,  1.7607e-01],\n                        [-5.4907e-02, -2.9688e-02, -4.7134e-02]],\n              \n                       [[ 1.0204e-02, -9.5071e-03, -2.1266e-02],\n                        [-1.4379e-02,  2.0354e-02, -2.3224e-03],\n                        [-2.6377e-02, -4.9138e-03, -2.5833e-02]],\n              \n                       [[ 1.8524e-02, -3.0317e-02,  4.3575e-02],\n                        [ 2.8177e-02, -2.8732e-02,  3.6657e-02],\n                        [-2.7111e-02, -1.1766e-02, -1.9746e-02]]],\n              \n              \n                      [[[ 1.3637e-02, -1.1304e-01, -3.9187e-02],\n                        [-1.4834e-01, -1.8217e-01, -1.5447e-01],\n                        [-1.0237e-02, -7.4134e-02, -1.1246e-02]],\n              \n                       [[-8.3508e-02, -7.7723e-02, -2.0505e-02],\n                        [-2.6210e-01,  5.0454e-02, -3.2299e-02],\n                        [-1.2348e-01, -8.2736e-02,  1.5905e-02]],\n              \n                       [[ 4.4265e-02, -1.1221e-02,  3.2734e-02],\n                        [ 4.7954e-03,  4.3787e-02, -3.0796e-02],\n                        [-1.9089e-02,  2.0645e-02, -6.4655e-02]],\n              \n                       ...,\n              \n                       [[ 5.0196e-02,  3.6453e-02,  4.0853e-02],\n                        [ 2.0871e-02, -4.0073e-02, -2.0354e-01],\n                        [-9.4709e-03, -1.3286e-02, -8.9374e-02]],\n              \n                       [[ 4.0078e-02,  5.3090e-03, -3.6606e-02],\n                        [ 1.4312e-01,  1.9099e-03, -2.1343e-02],\n                        [-3.4243e-03,  3.0851e-02, -2.1745e-02]],\n              \n                       [[-2.0857e-02, -3.2877e-02, -1.3001e-02],\n                        [ 3.8244e-03,  3.7758e-01,  1.3078e-01],\n                        [ 4.7899e-02, -5.0964e-02, -1.9538e-02]]],\n              \n              \n                      [[[-3.6976e-03, -9.9416e-03, -1.9952e-03],\n                        [ 1.5420e-02,  1.1752e-02, -5.9963e-03],\n                        [ 2.0080e-03,  1.6716e-03, -3.1119e-05]],\n              \n                       [[ 1.5068e-03, -4.3611e-03, -3.0184e-03],\n                        [ 2.0900e-02,  1.6143e-02,  1.9423e-02],\n                        [ 7.7512e-03,  3.7635e-02,  2.1667e-02]],\n              \n                       [[-5.9396e-03, -4.3968e-03, -5.0605e-03],\n                        [ 2.1827e-03, -9.0017e-03, -4.5450e-03],\n                        [-4.4244e-03,  7.8962e-03, -8.2641e-03]],\n              \n                       ...,\n              \n                       [[ 1.6387e-03,  4.5385e-03, -6.6232e-03],\n                        [ 4.9233e-03,  1.6733e-02, -1.9122e-02],\n                        [ 1.5686e-02,  2.4239e-03, -2.1945e-02]],\n              \n                       [[ 1.6335e-04,  2.3662e-04,  4.3836e-03],\n                        [ 8.6761e-03,  2.7685e-03, -6.7428e-05],\n                        [ 1.6515e-02,  3.9251e-03,  4.1957e-03]],\n              \n                       [[-7.4924e-03,  9.2287e-03,  1.0399e-03],\n                        [-3.5558e-03, -1.6775e-02, -1.7859e-03],\n                        [ 3.3272e-03,  5.9343e-03,  3.8567e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 2.3794e-03, -2.3149e-02, -8.4927e-03],\n                        [ 4.1881e-02, -7.6551e-02,  8.5290e-03],\n                        [-1.4412e-02, -1.0754e-01,  5.1483e-02]],\n              \n                       [[ 3.1153e-02,  1.0376e-02,  4.3393e-02],\n                        [ 1.5172e-02, -3.0761e-01,  2.1400e-02],\n                        [-5.7712e-02, -6.3553e-02,  8.0321e-02]],\n              \n                       [[-3.1542e-02,  2.7212e-02, -3.1222e-02],\n                        [-3.4432e-02, -3.9750e-02,  1.7944e-02],\n                        [ 3.7842e-02, -9.9977e-03, -1.3478e-03]],\n              \n                       ...,\n              \n                       [[-6.8406e-02, -2.3725e-02,  2.9875e-03],\n                        [-2.0778e-02, -1.2234e-02,  8.3961e-02],\n                        [-6.1945e-02, -3.7212e-02,  5.7675e-02]],\n              \n                       [[ 1.6167e-02, -2.0751e-02,  4.2218e-03],\n                        [-3.4250e-02,  3.4739e-02,  2.6678e-02],\n                        [ 8.5094e-03,  4.4959e-02,  4.5420e-03]],\n              \n                       [[ 2.5311e-02,  3.8112e-02, -2.1186e-02],\n                        [ 3.0760e-02, -1.1485e-03, -5.2278e-02],\n                        [-1.7766e-02,  3.5597e-02,  2.8742e-02]]],\n              \n              \n                      [[[-1.7050e-02, -2.4755e-02, -1.0778e-02],\n                        [ 3.8195e-02,  1.1150e-03, -3.2850e-04],\n                        [ 1.2044e-02,  6.1665e-02,  7.5999e-04]],\n              \n                       [[-1.0489e-02, -5.3826e-03,  6.3002e-02],\n                        [ 2.2196e-02, -1.9611e-02,  2.4221e-02],\n                        [-1.8911e-03, -4.0794e-02,  9.2958e-03]],\n              \n                       [[ 2.0884e-02,  2.3356e-02,  2.1309e-03],\n                        [ 5.2157e-03,  7.5201e-03, -7.8243e-03],\n                        [ 1.3950e-02,  3.0735e-03, -4.7458e-02]],\n              \n                       ...,\n              \n                       [[ 8.5182e-03, -2.2672e-03, -8.2640e-03],\n                        [-4.1832e-03,  5.9722e-02, -5.2576e-02],\n                        [-2.3381e-03,  2.8268e-02, -9.9815e-03]],\n              \n                       [[ 6.8574e-03,  1.0087e-02,  6.6389e-03],\n                        [ 1.4631e-02, -1.7272e-03,  1.2674e-02],\n                        [-5.1721e-03, -6.6913e-03, -1.2995e-03]],\n              \n                       [[ 4.2473e-03,  6.4382e-03, -4.0151e-03],\n                        [-1.3478e-02,  3.1470e-02,  4.4061e-03],\n                        [-5.0825e-03,  2.6200e-03,  3.6579e-03]]],\n              \n              \n                      [[[-6.0554e-03, -6.1533e-03,  4.6539e-02],\n                        [ 1.8018e-02,  7.2753e-03,  3.1974e-02],\n                        [-4.3220e-02, -8.3021e-02, -8.4746e-02]],\n              \n                       [[-1.3950e-02, -4.8301e-02,  6.9292e-02],\n                        [ 1.1851e-02, -1.7583e-01,  1.7891e-01],\n                        [-1.9015e-02,  6.1954e-02, -1.2959e-01]],\n              \n                       [[ 3.1530e-02,  4.7913e-02,  2.1039e-02],\n                        [-3.3731e-02, -6.4192e-02,  6.2034e-02],\n                        [ 1.3928e-02, -5.5860e-02, -3.1970e-03]],\n              \n                       ...,\n              \n                       [[-1.8154e-02,  6.9305e-03,  5.9075e-02],\n                        [ 1.4323e-02, -3.8764e-02,  5.2897e-03],\n                        [ 2.4974e-02, -1.4364e-02,  6.5815e-02]],\n              \n                       [[-3.7423e-02,  8.5776e-03,  2.4076e-02],\n                        [-5.2016e-02, -3.6630e-02, -1.9115e-02],\n                        [ 3.6811e-03,  4.2249e-02, -1.2791e-02]],\n              \n                       [[ 3.7318e-02, -3.9788e-03, -1.4130e-02],\n                        [ 2.4669e-02,  4.6372e-02, -1.7685e-02],\n                        [ 7.9770e-03, -3.4944e-03,  3.1887e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv1.norm.weight',\n              tensor([1.1441, 0.7422, 1.7724, 0.6539, 0.3754, 0.4354, 0.4422, 1.0675, 2.0453,\n                      0.5399, 1.4705, 0.8760, 1.1947, 0.9717, 1.2202, 0.7445, 1.4293, 0.2650,\n                      0.4437, 2.0300, 0.5486, 0.4046, 1.0537, 2.1343, 0.5887, 1.1589, 0.5640,\n                      0.4359, 1.7707, 0.7929, 0.4860, 0.9480, 0.5946, 0.6647, 1.5576, 1.2069,\n                      1.6328, 1.6718, 1.1784, 0.9882, 0.6577, 1.0191, 1.6476, 0.7097, 0.8514,\n                      0.9754, 1.0018, 1.9795, 0.3379, 0.9384, 0.4168, 0.0514, 0.4573, 1.3563,\n                      1.0581, 2.4969, 1.3268, 0.7250, 1.1571, 0.3460, 1.2327, 1.6976, 1.8534,\n                      0.5230, 0.3056, 0.3861, 1.7529, 0.5516, 1.6520, 0.6019, 0.4212, 0.8633,\n                      1.1347, 0.9897, 1.5354, 0.4896, 0.4090, 1.3095, 0.8217, 0.3003, 0.9809,\n                      0.7994, 0.9685, 0.3851, 1.4371, 0.7639, 1.0341, 1.0793, 1.8114, 1.9111,\n                      0.3699, 0.6849, 0.6170, 1.0613, 1.5367, 0.1356, 0.5582, 1.0820, 0.5682,\n                      1.2194, 0.5531, 1.1324, 1.3032, 0.9685, 1.3074, 0.6723, 1.1342, 1.0494,\n                      0.8168, 0.6324, 0.5066, 0.9300, 0.3117, 0.1215, 1.2189, 0.9591, 0.9931,\n                      1.3651, 0.3530, 0.2982, 1.3648, 1.1238, 0.5380, 1.3968, 1.2249, 0.3995,\n                      1.2864, 1.5146], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv1.norm.bias',\n              tensor([ 5.4450e-01,  3.4226e-01,  3.9011e-01, -5.6003e-01, -8.5473e-02,\n                       1.2278e-01,  1.4259e-01,  4.4460e-01, -6.5946e-02, -2.5702e-01,\n                       2.4142e-01, -1.3601e-01,  2.5228e-01,  1.5029e-01,  2.7907e-01,\n                       1.3989e-01,  6.5977e-01,  8.2227e-02, -1.9227e-01,  1.0086e+00,\n                       1.6051e-01, -2.0910e-01,  2.9472e-01,  1.0145e+00,  2.1686e-01,\n                       2.1520e-01,  2.1258e-01,  8.3650e-02,  6.8308e-01,  3.1084e-01,\n                       1.4009e-01,  4.3481e-01,  1.4747e-01, -6.0289e-01,  2.6138e-01,\n                       5.5391e-01,  5.0783e-01,  3.0045e-01,  2.6309e-01,  1.7300e-01,\n                      -1.1690e-01,  2.8870e-01,  4.0638e-02,  3.1405e-01,  2.4123e-01,\n                       1.5372e-01,  2.4646e-01,  1.0594e+00, -3.3253e-01,  1.3282e-01,\n                       6.7122e-04,  5.3681e-03,  1.5108e-01, -1.9181e-01,  2.8812e-01,\n                       1.2094e+00,  5.8533e-01,  3.1313e-01,  3.5944e-01, -2.6184e-01,\n                      -8.8405e-01,  5.8411e-01,  5.8826e-01,  1.6437e-01, -3.8158e-01,\n                       1.4235e-01,  8.2895e-01, -4.0985e-02,  6.3641e-01, -6.9926e-03,\n                       1.0761e-01,  3.4661e-01, -1.1425e+00,  3.4583e-01,  4.7272e-01,\n                       1.6213e-01,  1.0820e-02,  3.9777e-01, -7.9790e-01, -6.0900e-02,\n                       2.1459e-01,  3.2507e-01,  4.3392e-01, -2.1334e-01,  4.0097e-01,\n                      -8.8235e-01, -6.9008e-01,  3.1696e-01, -2.5209e-01,  7.6597e-01,\n                       9.1434e-02, -1.2866e-01, -2.4803e-01,  1.6661e-01,  7.3432e-01,\n                      -1.5404e-01,  2.3787e-01,  4.7921e-01,  1.9349e-01,  4.8500e-01,\n                      -4.6433e-01,  2.2494e-01,  6.2941e-01, -1.2988e+00,  2.9391e-01,\n                       2.6780e-01,  2.0633e-01,  3.5040e-01,  3.5686e-01,  2.4859e-02,\n                       1.6340e-01,  1.7383e-01, -3.5777e-01, -6.9032e-01,  3.0331e-01,\n                       2.4676e-01,  1.1616e-01, -1.1068e-02,  3.7205e-02, -2.2143e-01,\n                       5.5264e-01,  2.0873e-01, -2.8224e-01,  3.7475e-01,  3.4409e-01,\n                      -7.6480e-01, -2.9759e-01,  7.2825e-01], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.0.conv1.layer.weight',\n              tensor([[[[ 0.0178, -0.0149,  0.0283],\n                        [-0.0120, -0.0319, -0.0505],\n                        [ 0.0190,  0.0283,  0.0054]],\n              \n                       [[ 0.0530, -0.0458,  0.1352],\n                        [ 0.0159,  0.0315,  0.1120],\n                        [-0.0156,  0.0718,  0.0047]],\n              \n                       [[-0.0172, -0.0111,  0.0206],\n                        [-0.0297, -0.0087,  0.0136],\n                        [ 0.0032, -0.0247, -0.0122]],\n              \n                       ...,\n              \n                       [[-0.0868, -0.1105, -0.0635],\n                        [ 0.0183,  0.0577,  0.0106],\n                        [ 0.1116,  0.3754,  0.1663]],\n              \n                       [[-0.0090,  0.0235, -0.0237],\n                        [ 0.0613,  0.0217, -0.0310],\n                        [-0.0143, -0.0302,  0.0032]],\n              \n                       [[ 0.0599,  0.0691,  0.0534],\n                        [-0.0688, -0.0637, -0.0071],\n                        [-0.0231,  0.1013, -0.0050]]],\n              \n              \n                      [[[ 0.0544,  0.0609,  0.0284],\n                        [-0.1040, -0.0584,  0.0524],\n                        [ 0.0040, -0.0448, -0.0012]],\n              \n                       [[-0.0292,  0.0513, -0.0645],\n                        [ 0.0592,  0.2893,  0.0557],\n                        [-0.0291, -0.0013,  0.0306]],\n              \n                       [[-0.0204,  0.0473, -0.0311],\n                        [ 0.0057,  0.0889,  0.0185],\n                        [-0.0588,  0.0408, -0.0017]],\n              \n                       ...,\n              \n                       [[-0.0279,  0.0871, -0.0180],\n                        [ 0.0128,  0.0538,  0.0133],\n                        [ 0.0445,  0.1698, -0.0201]],\n              \n                       [[ 0.0227,  0.0189,  0.0126],\n                        [-0.0159, -0.0554,  0.0049],\n                        [ 0.0594,  0.0044, -0.0026]],\n              \n                       [[ 0.1030,  0.0636,  0.0104],\n                        [-0.0293, -0.0075,  0.0138],\n                        [-0.0942, -0.1290,  0.0219]]],\n              \n              \n                      [[[ 0.0145, -0.0466, -0.0338],\n                        [ 0.0697, -0.0273, -0.0037],\n                        [ 0.0484,  0.1021, -0.0093]],\n              \n                       [[-0.0117,  0.2659, -0.1525],\n                        [-0.0793,  0.0513, -0.1274],\n                        [-0.0208,  0.0721,  0.0218]],\n              \n                       [[-0.0280,  0.0056, -0.0283],\n                        [ 0.0019, -0.1020, -0.0148],\n                        [ 0.0202,  0.0077,  0.0027]],\n              \n                       ...,\n              \n                       [[ 0.1108, -0.0719, -0.0011],\n                        [ 0.1330, -0.1373,  0.0157],\n                        [ 0.0835,  0.0165,  0.0676]],\n              \n                       [[-0.0055,  0.0377,  0.0228],\n                        [-0.0781, -0.0226, -0.0145],\n                        [ 0.0222, -0.0282, -0.0280]],\n              \n                       [[ 0.0142,  0.0489,  0.0255],\n                        [-0.0396, -0.1263,  0.0473],\n                        [ 0.0515,  0.1200, -0.0413]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.1063, -0.0259, -0.0012],\n                        [-0.0701,  0.0274, -0.0172],\n                        [-0.0798,  0.0364, -0.0181]],\n              \n                       [[ 0.0769,  0.0436, -0.0102],\n                        [ 0.1417, -0.1440, -0.1691],\n                        [-0.0175,  0.0412, -0.0414]],\n              \n                       [[ 0.0142,  0.0119,  0.0083],\n                        [ 0.0041,  0.0237, -0.0113],\n                        [ 0.0080, -0.0080,  0.0161]],\n              \n                       ...,\n              \n                       [[-0.0257,  0.0188,  0.0121],\n                        [-0.0321,  0.0033, -0.0256],\n                        [-0.0297, -0.0090, -0.0332]],\n              \n                       [[ 0.0353,  0.0163,  0.0111],\n                        [-0.0557, -0.0218,  0.0013],\n                        [ 0.0070, -0.0089, -0.0204]],\n              \n                       [[-0.0150,  0.0354,  0.0398],\n                        [-0.0193,  0.0084,  0.0181],\n                        [-0.0813,  0.0152, -0.0229]]],\n              \n              \n                      [[[-0.0906, -0.0063, -0.0318],\n                        [ 0.0098, -0.0197, -0.0516],\n                        [-0.1057, -0.0851, -0.0841]],\n              \n                       [[ 0.0152,  0.0264,  0.0162],\n                        [ 0.0284, -0.0033, -0.0629],\n                        [ 0.0154, -0.0121, -0.0139]],\n              \n                       [[-0.0103,  0.0029,  0.0337],\n                        [-0.0470, -0.0958,  0.0018],\n                        [-0.0659,  0.0332, -0.0451]],\n              \n                       ...,\n              \n                       [[ 0.0018, -0.0447, -0.0276],\n                        [-0.0087,  0.0049,  0.0335],\n                        [ 0.0106,  0.0093,  0.0080]],\n              \n                       [[ 0.0361,  0.0201, -0.0093],\n                        [-0.0838,  0.0145, -0.0113],\n                        [-0.0249, -0.0410,  0.0032]],\n              \n                       [[ 0.0149,  0.0184, -0.0096],\n                        [-0.0170,  0.0468, -0.0252],\n                        [ 0.0221,  0.0574, -0.0317]]],\n              \n              \n                      [[[ 0.0174, -0.0547, -0.0226],\n                        [ 0.0634,  0.0324, -0.0069],\n                        [ 0.0047,  0.0450,  0.0194]],\n              \n                       [[-0.0631, -0.1288,  0.0269],\n                        [-0.0505, -0.0199,  0.0846],\n                        [ 0.0840, -0.0610,  0.0108]],\n              \n                       [[-0.0229, -0.0143,  0.0482],\n                        [-0.0150,  0.0184,  0.0300],\n                        [-0.0245, -0.0352,  0.0088]],\n              \n                       ...,\n              \n                       [[ 0.0172, -0.0371, -0.0006],\n                        [ 0.0456, -0.0248,  0.0148],\n                        [ 0.0115,  0.0114,  0.0480]],\n              \n                       [[-0.0069, -0.0089, -0.0255],\n                        [ 0.0258, -0.0156,  0.0275],\n                        [ 0.0143, -0.0414, -0.0180]],\n              \n                       [[ 0.0228, -0.0555,  0.0015],\n                        [ 0.0276,  0.0367,  0.0058],\n                        [ 0.0352,  0.0189, -0.0487]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv0.norm.weight',\n              tensor([0.2950, 1.2829, 0.3497, 0.5287, 0.9479, 0.6505, 1.5262, 0.3881, 0.3937,\n                      1.4940, 1.0720, 0.3291, 0.6065, 0.7801, 0.5583, 0.3902, 1.6645, 1.3250,\n                      0.4739, 0.9907, 1.3173, 0.9633, 0.9373, 1.2534, 1.2350, 0.4890, 0.6199,\n                      1.0503, 0.5022, 0.7472, 1.5924, 1.0275, 0.6083, 0.3686, 1.0253, 1.5983,\n                      1.2502, 0.7488, 1.0322, 1.5242, 1.5043, 1.5421, 1.6205, 1.0287, 1.0367,\n                      1.2734, 0.4118, 0.8579, 0.9734, 0.4846, 0.6504, 0.5377, 0.6348, 1.1066,\n                      0.7625, 1.1048, 1.0830, 1.0830, 0.7036, 0.5893, 1.0318, 0.6803, 0.2635,\n                      0.7390, 0.3501, 1.0154, 0.9997, 0.9541, 1.0154, 0.8027, 0.3104, 1.0383,\n                      0.5962, 1.1007, 1.5941, 1.4522, 0.3386, 0.9267, 0.4567, 1.1862, 0.9687,\n                      1.1429, 0.9743, 0.2809, 0.6184, 0.3283, 0.8118, 0.7925, 0.5136, 0.9340,\n                      1.6681, 1.1872, 1.2512, 1.2175, 0.9758, 2.5178, 1.1441, 0.7504, 1.0128,\n                      0.7057, 0.7167, 0.6053, 0.3610, 0.3388, 1.0473, 1.3882, 1.3540, 0.6034,\n                      0.4037, 1.2560, 0.6878, 0.5495, 0.9347, 0.5139, 0.5592, 0.9114, 0.5689,\n                      0.4217, 0.6865, 1.0788, 0.4690, 1.0963, 1.6113, 0.7369, 1.3258, 0.9902,\n                      0.7869, 0.6955], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv0.norm.bias',\n              tensor([-0.3365,  0.5125,  0.1612,  0.2491, -0.9653, -0.3809,  0.7141, -0.0629,\n                      -0.1520,  0.5250,  0.2976, -0.4286, -0.1278,  0.2667,  0.2969, -0.6887,\n                       0.7332,  0.7729,  0.2070, -0.2182,  0.6634,  0.6518,  0.0871,  0.2561,\n                       0.4168, -0.6229,  0.2102,  0.3208, -0.2471, -0.2214,  0.6095,  0.5868,\n                       0.1729, -0.6363,  0.5322,  1.0897,  0.7382,  0.0266,  0.0380,  0.5291,\n                       0.6060,  0.8096,  0.0600,  0.5275,  0.1805,  0.5612, -0.2298, -0.0958,\n                       0.2621, -0.0887,  0.3889, -0.6598, -0.3731,  0.3706,  0.3038,  0.2727,\n                       0.3483,  0.1251,  0.2824,  0.1723,  0.2062,  0.3118, -1.5721,  0.1827,\n                       0.0251,  0.3828,  0.3956,  0.3042,  0.4153,  0.3701, -0.3378,  0.0046,\n                      -0.3387,  0.6912,  0.5057,  0.7237, -0.3396,  0.3328, -0.3944,  0.5500,\n                       0.4713,  0.2616,  0.3872,  0.0778,  0.2212, -0.3873, -0.1904, -0.2461,\n                      -0.6413,  0.3405,  0.8733, -0.0242,  0.6295,  0.7259,  0.2230,  1.3046,\n                       0.5119,  0.3251, -0.0790,  0.3505, -0.2521,  0.2486,  0.0572, -0.2295,\n                       0.0451,  0.3506,  0.9104,  0.0421,  0.1309,  0.6215,  0.2876,  0.1122,\n                       0.4232, -0.7076, -0.2250, -0.0905,  0.1034, -0.0259,  0.2086, -0.3636,\n                       0.0591,  0.3881,  0.3787,  0.4070,  0.5821,  0.7376, -0.3703,  0.1866],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv0.layer.weight',\n              tensor([[[[ 1.6588e-03, -1.2435e-02,  8.3493e-03],\n                        [ 1.7517e-02, -4.8095e-02,  3.1575e-02],\n                        [ 1.2627e-02,  1.1545e-03,  2.2043e-02]],\n              \n                       [[ 1.8155e-02,  5.3995e-04, -2.5571e-02],\n                        [ 2.7759e-02,  3.0034e-02,  8.7815e-03],\n                        [ 1.5709e-02, -1.1628e-02, -5.4226e-02]],\n              \n                       [[ 2.8776e-02,  4.8448e-02, -8.7923e-03],\n                        [-4.0221e-02,  1.8637e-02,  1.6423e-02],\n                        [ 7.4359e-03,  4.5596e-03,  2.5368e-02]],\n              \n                       ...,\n              \n                       [[ 5.8963e-03, -8.9907e-03,  4.4404e-03],\n                        [ 1.7577e-02,  1.3827e-02,  9.8430e-03],\n                        [ 5.8263e-03,  4.5444e-02,  6.8431e-03]],\n              \n                       [[-2.4214e-02, -6.0793e-03,  3.2345e-02],\n                        [ 9.2952e-03, -2.6935e-01, -3.0100e-03],\n                        [-2.7631e-02,  4.2003e-02,  3.6935e-02]],\n              \n                       [[ 1.4502e-02,  8.5524e-03, -2.9985e-02],\n                        [ 4.4407e-02, -2.8958e-04, -1.9763e-02],\n                        [-3.2329e-03,  7.5045e-03, -1.4131e-02]]],\n              \n              \n                      [[[-2.7244e-02,  5.6378e-02,  3.5671e-02],\n                        [-8.7975e-02, -2.2849e-01, -4.4414e-02],\n                        [ 1.1326e-02, -6.3986e-02, -1.3325e-02]],\n              \n                       [[ 2.0497e-03, -9.2011e-02, -1.2512e-01],\n                        [-2.5376e-02, -9.6725e-02, -8.3945e-02],\n                        [ 3.5865e-02,  1.0907e-03, -8.4249e-02]],\n              \n                       [[-6.0948e-02, -5.1786e-03, -4.8072e-02],\n                        [ 6.4915e-02,  4.8062e-02,  1.8440e-02],\n                        [-2.9865e-02,  2.7181e-02,  7.9513e-03]],\n              \n                       ...,\n              \n                       [[ 2.2630e-02,  1.0217e-01,  1.5852e-02],\n                        [ 4.2283e-02,  1.5987e-01,  3.8906e-02],\n                        [-4.0194e-02, -2.0724e-01, -3.8773e-02]],\n              \n                       [[-2.3029e-03,  1.7341e-03, -1.8609e-02],\n                        [-1.4879e-02,  5.3058e-02, -2.8092e-02],\n                        [ 2.3571e-02, -1.1763e-02, -7.5502e-03]],\n              \n                       [[-3.1305e-02, -5.0535e-02,  6.7303e-03],\n                        [-1.6146e-02,  1.1975e-01,  4.7233e-02],\n                        [-1.6759e-02,  1.6510e-04, -3.4840e-02]]],\n              \n              \n                      [[[ 1.8274e-02,  1.3511e-01, -6.6735e-02],\n                        [-4.8487e-02,  7.4229e-02, -1.2936e-01],\n                        [-6.0773e-02,  4.1394e-02,  8.5462e-03]],\n              \n                       [[-1.6187e-03, -3.7723e-02,  1.8764e-02],\n                        [ 4.9128e-02,  3.5022e-02,  6.1586e-02],\n                        [ 3.3186e-03, -2.6238e-02, -9.5202e-02]],\n              \n                       [[ 4.8889e-02, -1.7284e-02, -6.0653e-02],\n                        [ 1.0651e-01, -9.8382e-02,  1.2126e-02],\n                        [-4.2226e-02,  8.3105e-02,  1.8048e-02]],\n              \n                       ...,\n              \n                       [[ 2.7933e-02, -2.1817e-03,  6.9430e-02],\n                        [-4.0646e-02, -4.3400e-02, -4.7547e-02],\n                        [ 2.4182e-03,  4.0354e-02, -4.2797e-02]],\n              \n                       [[-5.1006e-02,  2.9623e-02, -3.8757e-03],\n                        [-3.9602e-02,  2.8716e-02, -2.8876e-02],\n                        [ 1.4122e-02,  3.0158e-02,  3.0684e-02]],\n              \n                       [[ 1.1636e-02, -9.2066e-03, -9.9432e-03],\n                        [-6.5219e-02,  1.5835e-02, -4.2685e-02],\n                        [ 2.4981e-02, -6.3836e-02,  3.3399e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.2750e-02, -7.2981e-02, -1.4875e-02],\n                        [ 8.3639e-02,  1.3918e-01,  2.2056e-02],\n                        [-1.6312e-02,  1.8332e-01, -9.3227e-03]],\n              \n                       [[ 3.7955e-02, -4.4485e-02,  2.8038e-02],\n                        [ 2.1222e-02, -8.4038e-02, -2.4663e-02],\n                        [-6.6877e-02, -1.1329e-01, -2.9919e-02]],\n              \n                       [[ 2.4759e-02,  1.8978e-02,  2.7464e-02],\n                        [-3.2168e-03,  5.1330e-04,  2.4044e-02],\n                        [-3.1574e-02,  5.5154e-02,  4.8904e-02]],\n              \n                       ...,\n              \n                       [[ 3.5486e-02, -1.0913e-01,  1.3602e-02],\n                        [-6.6656e-02, -2.2583e-01, -8.1570e-02],\n                        [ 1.7387e-01,  2.0948e-01,  5.7228e-02]],\n              \n                       [[ 6.1717e-03,  1.2772e-02,  5.9348e-03],\n                        [ 3.9932e-02,  1.0658e-02, -1.2536e-02],\n                        [ 8.6055e-03,  1.8955e-02,  2.2921e-02]],\n              \n                       [[ 1.8222e-02,  6.4086e-03, -3.9231e-02],\n                        [-2.4904e-02, -1.1382e-02,  2.7903e-02],\n                        [ 4.3521e-02,  2.7700e-02,  2.0929e-02]]],\n              \n              \n                      [[[ 7.3579e-03, -4.9712e-02,  3.9484e-02],\n                        [-4.8664e-02, -1.8478e-01, -8.5836e-02],\n                        [ 3.4880e-02, -1.0744e-01, -7.1393e-02]],\n              \n                       [[ 6.7651e-02,  7.3154e-02, -3.3597e-02],\n                        [-2.0812e-02,  1.0533e-01,  2.4888e-02],\n                        [-2.2076e-02, -6.2598e-02, -4.0821e-03]],\n              \n                       [[-4.6572e-02, -1.2003e-03, -7.5712e-02],\n                        [-3.2575e-03,  5.9067e-02,  4.8532e-02],\n                        [ 5.2946e-03, -9.6060e-02,  5.0274e-02]],\n              \n                       ...,\n              \n                       [[-2.9660e-02, -8.0499e-02,  2.2228e-02],\n                        [-6.1335e-02, -1.1839e-01,  3.0803e-03],\n                        [ 7.6044e-02,  1.7117e-01,  1.4597e-01]],\n              \n                       [[ 3.4980e-02,  5.7140e-02,  3.1572e-02],\n                        [ 4.5715e-02,  1.4829e-02, -5.3567e-03],\n                        [-1.4217e-02, -5.1408e-03, -5.0163e-02]],\n              \n                       [[ 4.5027e-02, -5.4409e-03, -6.1346e-03],\n                        [ 1.9112e-02,  4.6487e-02,  1.6924e-02],\n                        [ 8.9702e-03,  7.0010e-03, -1.8356e-02]]],\n              \n              \n                      [[[ 3.5791e-02,  1.0107e-02, -3.3051e-03],\n                        [-2.0151e-02, -7.5663e-02, -3.2312e-02],\n                        [-2.2164e-02,  4.7307e-02,  3.8865e-02]],\n              \n                       [[ 5.2563e-02, -1.9642e-02, -3.9322e-03],\n                        [-2.8678e-04,  2.8625e-02,  1.6507e-02],\n                        [-6.5046e-02, -1.2366e-01, -5.9196e-03]],\n              \n                       [[ 4.3318e-02, -3.1273e-02,  2.0122e-02],\n                        [ 1.5046e-03,  2.3033e-02,  1.2108e-01],\n                        [-2.6605e-02, -1.6161e-02, -1.1106e-02]],\n              \n                       ...,\n              \n                       [[ 6.2731e-03, -3.0833e-03,  7.4929e-03],\n                        [-5.5660e-02,  2.4350e-02,  3.9917e-02],\n                        [-1.4868e-02,  1.1685e-02,  5.6758e-02]],\n              \n                       [[ 7.7550e-02,  2.3702e-03,  2.0564e-03],\n                        [ 2.2169e-02, -4.7605e-02, -1.2449e-02],\n                        [ 2.0552e-02,  7.4743e-02, -4.7858e-02]],\n              \n                       [[-7.9075e-02, -9.3064e-02,  4.3396e-02],\n                        [ 3.2144e-02, -5.0216e-02, -6.2804e-02],\n                        [-1.0218e-02,  1.6858e-02,  1.6646e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv1.norm.weight',\n              tensor([2.2163, 1.6441, 1.0586, 1.0034, 1.0677, 1.2096, 1.5886, 1.4163, 1.4780,\n                      1.2053, 1.4953, 1.2114, 1.0067, 1.0803, 1.8547, 1.3581, 1.1513, 1.3232,\n                      1.3850, 1.2107, 1.1053, 1.3208, 1.0841, 0.8281, 2.2733, 1.2288, 1.2408,\n                      1.2687, 1.9463, 1.9317, 1.7340, 1.6446, 2.3013, 2.0494, 2.3103, 1.2446,\n                      1.2675, 1.8227, 1.9153, 1.1512, 1.8083, 1.6685, 1.7540, 0.9793, 1.5945,\n                      1.1524, 1.3399, 1.2042, 1.9045, 1.2709, 1.4306, 1.9384, 1.1338, 1.9114,\n                      1.6570, 1.7775, 1.3235, 0.8404, 1.8186, 1.3997, 2.4897, 1.4709, 1.5191,\n                      1.0684, 0.9519, 1.2031, 1.7073, 3.0810, 1.3345, 1.5843, 2.1500, 1.2367,\n                      2.4443, 1.3075, 1.0679, 1.5156, 1.1556, 2.0727, 1.1955, 1.6222, 1.9325,\n                      1.5011, 1.5155, 1.7592, 1.2034, 1.7324, 1.1247, 1.8934, 1.2873, 1.0657,\n                      1.1035, 2.0949, 1.4653, 1.1777, 0.9569, 1.1881, 1.4458, 1.3132, 1.1567,\n                      1.6684, 2.0026, 1.5099, 3.0322, 0.7792, 1.7596, 0.4225, 2.2444, 1.8847,\n                      1.5602, 1.2413, 2.2338, 2.2116, 1.5960, 1.2114, 1.1417, 1.4730, 1.4553,\n                      1.0962, 1.3580, 1.0267, 1.2187, 1.3467, 1.6597, 1.1354, 1.3075, 0.9011,\n                      1.0696, 1.1930], device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv1.norm.bias',\n              tensor([ 0.8745,  0.5953, -0.3212,  0.0225, -0.3971, -0.3764,  0.3688,  0.2765,\n                       0.2776, -0.3006,  0.4292,  0.1566, -0.8253, -0.1371,  0.4004,  0.6605,\n                       0.1285, -0.2557, -0.2746,  0.4294, -0.4218,  0.5202, -0.8602, -0.6658,\n                       1.1108,  0.2330,  0.2643, -0.8373,  0.4760,  1.0299,  1.0131,  0.6210,\n                       1.2816,  0.3166,  1.2298,  0.1905, -1.9756,  0.7221,  0.8652,  0.3016,\n                      -0.3180,  0.7608,  0.5157,  0.0741,  0.5998,  0.3585,  0.3388,  1.5941,\n                      -0.2764,  0.4753,  0.2485,  0.3540,  0.0107,  0.9758,  0.5996,  0.5915,\n                       0.4016, -0.7828,  0.5523,  0.2208,  1.2423, -0.6844,  0.3616, -0.9086,\n                      -0.3353, -1.7413,  0.3797,  1.4477,  0.4497,  0.4754,  0.8766, -0.0720,\n                      -0.2674, -1.6044, -0.7002,  0.2947, -1.1604,  0.2221,  0.2114, -1.1319,\n                       0.2361,  0.5502,  0.4990,  0.7331,  0.3017,  0.6556, -0.8421,  0.7964,\n                       0.1539, -0.8960,  0.5718,  0.6455,  0.2623,  0.1231, -0.8500, -0.6624,\n                       0.5162,  0.2543, -0.1473,  0.8394,  0.7406,  0.3085,  1.6772, -0.5554,\n                       0.0102, -2.2098,  1.0278,  0.0947,  0.0526,  0.0201,  1.1885,  0.9188,\n                       0.3650, -0.5452,  0.1955,  0.1874,  0.3913, -0.0548,  0.4099,  0.4705,\n                       0.1226,  0.6345,  0.9391,  0.1365,  0.3991, -0.6507,  0.2936, -1.3763],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.0.blocks.1.conv1.layer.weight',\n              tensor([[[[ 5.5441e-03, -5.8119e-03, -1.0702e-02],\n                        [-1.3440e-02, -1.4902e-02,  6.0804e-03],\n                        [-8.6002e-03, -4.0292e-03, -4.6898e-03]],\n              \n                       [[-1.3885e-02,  1.1707e-02, -1.3694e-02],\n                        [-1.9567e-03, -7.3999e-02,  2.1941e-03],\n                        [ 3.7425e-03, -5.5612e-02, -2.9199e-02]],\n              \n                       [[ 1.9544e-02,  6.2945e-02, -2.0806e-04],\n                        [-4.0574e-03,  7.2119e-02,  5.0271e-02],\n                        [ 4.2175e-03,  4.9493e-02,  3.9390e-02]],\n              \n                       ...,\n              \n                       [[ 1.1885e-02,  1.3822e-01,  7.0588e-02],\n                        [ 1.5001e-02,  1.0567e-01,  1.3625e-01],\n                        [ 1.2960e-02,  5.9408e-02,  2.1562e-02]],\n              \n                       [[-2.5331e-02, -4.0056e-02, -4.1866e-02],\n                        [-1.6734e-02, -8.8554e-02, -8.8311e-03],\n                        [-1.7219e-02, -7.3378e-02, -3.9439e-02]],\n              \n                       [[-4.0493e-03, -1.5349e-02, -3.7126e-04],\n                        [ 7.3235e-03, -1.1620e-02,  8.4602e-03],\n                        [ 4.2242e-03,  3.1540e-02,  1.2142e-02]]],\n              \n              \n                      [[[ 9.2173e-03, -1.4373e-02,  1.8238e-02],\n                        [-2.0488e-02, -1.9978e-02,  2.8018e-02],\n                        [-8.1575e-03, -1.2970e-03, -9.1189e-03]],\n              \n                       [[ 7.0084e-02,  5.8658e-02,  1.9392e-02],\n                        [-3.1721e-02, -4.6309e-02,  1.3361e-02],\n                        [-8.6408e-03, -3.1516e-02,  3.2611e-03]],\n              \n                       [[ 3.5527e-02,  5.5295e-02,  3.3754e-02],\n                        [ 9.5761e-02, -2.1661e-03, -5.1969e-02],\n                        [-6.2801e-03, -8.8011e-02, -1.2141e-02]],\n              \n                       ...,\n              \n                       [[-1.2073e-02, -1.0460e-02,  1.3325e-02],\n                        [-7.1223e-02,  5.3691e-02,  1.6755e-01],\n                        [-4.7767e-02,  4.3241e-03,  3.5487e-02]],\n              \n                       [[ 1.5749e-02,  3.9115e-02,  4.3758e-02],\n                        [-5.1456e-02, -6.4535e-02,  5.2553e-02],\n                        [ 2.7885e-02,  9.4042e-02,  2.3831e-02]],\n              \n                       [[ 1.7674e-02,  2.4617e-02, -8.3858e-03],\n                        [-2.2838e-02,  7.7895e-02, -5.7754e-02],\n                        [-1.1813e-02,  6.1562e-03, -6.4236e-02]]],\n              \n              \n                      [[[-4.6182e-02,  2.7032e-02, -2.5731e-02],\n                        [-6.6896e-02,  9.8039e-02, -2.9648e-02],\n                        [ 1.3118e-02,  5.9168e-03,  2.0255e-02]],\n              \n                       [[ 1.1797e-02,  4.4453e-02,  5.3621e-02],\n                        [ 2.7259e-02,  5.9777e-02,  6.7601e-02],\n                        [-3.1176e-02, -4.9468e-03, -6.0831e-03]],\n              \n                       [[ 1.2722e-02,  1.3322e-02,  3.7350e-02],\n                        [ 2.7597e-02, -6.4893e-02, -1.1279e-02],\n                        [-1.5117e-02,  3.4963e-03, -2.1227e-02]],\n              \n                       ...,\n              \n                       [[-2.1033e-02,  1.6396e-02,  1.4337e-03],\n                        [-2.8067e-02, -9.8572e-02, -4.0539e-02],\n                        [-9.4679e-03,  5.0680e-03,  1.8417e-03]],\n              \n                       [[-3.4185e-02, -4.6796e-03, -1.0978e-02],\n                        [-3.0305e-02,  7.9687e-02,  1.6869e-02],\n                        [-5.9407e-03, -4.2665e-02, -9.1886e-03]],\n              \n                       [[-2.5175e-03,  1.5395e-02,  8.4818e-05],\n                        [ 8.2254e-03, -3.2263e-02,  2.7424e-02],\n                        [ 8.4968e-03, -2.0679e-02,  8.5898e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-4.2568e-02, -2.9162e-02, -2.6144e-02],\n                        [ 3.2697e-03,  2.8390e-03,  2.2416e-03],\n                        [-7.4018e-03,  3.1316e-02,  5.1356e-02]],\n              \n                       [[ 4.9250e-02,  2.9723e-02,  1.5473e-02],\n                        [ 5.1956e-02,  4.8309e-02, -1.7977e-02],\n                        [-3.5241e-02, -8.2091e-02, -3.8372e-02]],\n              \n                       [[ 2.7247e-02,  3.0955e-02,  3.9909e-02],\n                        [ 2.3397e-02, -1.6371e-02, -3.4388e-02],\n                        [ 2.3883e-02, -1.9919e-02,  1.9452e-03]],\n              \n                       ...,\n              \n                       [[ 8.4003e-03,  4.6038e-02, -1.2514e-02],\n                        [ 1.4710e-02,  3.0999e-02,  4.7610e-02],\n                        [ 2.5394e-02,  8.3697e-03,  1.2444e-02]],\n              \n                       [[ 3.6887e-03,  1.0457e-02,  2.1088e-02],\n                        [ 9.6820e-03, -4.9293e-02, -5.4841e-02],\n                        [-3.6301e-03, -2.1322e-02,  2.6295e-02]],\n              \n                       [[ 2.4844e-02, -4.1768e-03,  7.5033e-02],\n                        [-1.8945e-02,  2.2408e-02,  4.4718e-02],\n                        [ 3.2107e-02,  2.1495e-02,  1.6071e-01]]],\n              \n              \n                      [[[ 1.5543e-03, -3.0205e-02, -5.7589e-03],\n                        [ 9.1109e-03,  1.9665e-01,  3.2059e-02],\n                        [ 1.3481e-02, -3.8624e-02,  7.3784e-03]],\n              \n                       [[ 4.0427e-03, -1.2760e-02,  2.6485e-02],\n                        [ 3.0699e-03, -6.8051e-03,  8.0026e-03],\n                        [ 1.9377e-02, -1.0134e-02, -1.1679e-02]],\n              \n                       [[ 5.7121e-03,  9.2829e-03,  3.1966e-02],\n                        [ 1.6046e-02, -5.8855e-02, -5.8323e-02],\n                        [ 8.9230e-03,  2.5173e-02, -1.3701e-02]],\n              \n                       ...,\n              \n                       [[ 1.4743e-02, -3.2757e-02,  6.5819e-02],\n                        [ 1.0918e-03,  3.7592e-02, -1.7316e-02],\n                        [-1.4668e-02,  2.9189e-02, -6.0902e-03]],\n              \n                       [[-6.3147e-04,  2.3537e-03, -2.5385e-02],\n                        [ 1.8279e-02, -2.6630e-02,  1.7351e-02],\n                        [ 4.1878e-03, -1.4634e-02,  4.2397e-03]],\n              \n                       [[-1.3233e-03, -6.0314e-03,  7.0986e-03],\n                        [-2.9795e-03,  5.7445e-02, -7.3491e-03],\n                        [-2.1151e-02,  2.0586e-02,  2.3414e-02]]],\n              \n              \n                      [[[ 3.2212e-02,  1.9354e-02,  3.5545e-02],\n                        [ 4.1396e-02,  2.6040e-02, -1.3324e-02],\n                        [ 8.2874e-03, -3.0789e-02,  1.9769e-02]],\n              \n                       [[ 1.2473e-02, -3.8658e-02,  1.2421e-02],\n                        [ 6.3337e-03,  8.4277e-03, -6.0836e-03],\n                        [-1.8785e-02, -9.0068e-02, -3.7348e-03]],\n              \n                       [[ 8.5421e-03, -6.4194e-02, -4.0432e-03],\n                        [ 1.2370e-02, -6.1719e-02, -9.0185e-03],\n                        [-3.5189e-03,  1.3278e-02,  7.3706e-03]],\n              \n                       ...,\n              \n                       [[ 2.2356e-02,  1.2081e-02, -2.3897e-02],\n                        [ 4.3056e-03, -1.1637e-01, -1.2194e-02],\n                        [ 3.9494e-02, -3.9742e-02,  3.8243e-02]],\n              \n                       [[ 6.9162e-03,  1.1914e-01, -3.8328e-02],\n                        [-2.4945e-02,  1.6932e-02, -5.4387e-02],\n                        [-8.7102e-03, -5.6327e-02,  9.4433e-03]],\n              \n                       [[-3.8631e-02,  9.6787e-02, -8.4596e-03],\n                        [-2.3622e-02,  1.6417e-02,  2.3897e-02],\n                        [-3.9485e-02, -9.2624e-02,  3.3867e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.firstconv.norm.weight',\n              tensor([0.9773, 0.7664, 0.9643, 0.8809, 0.9102, 1.1945, 1.0117, 0.8486, 1.0851,\n                      0.7945, 0.8343, 1.3005, 0.5922, 1.1042, 0.8496, 0.9814, 0.8529, 0.8505,\n                      0.7114, 0.7477, 0.8159, 0.9726, 0.9253, 0.7305, 1.0344, 1.1691, 0.9293,\n                      0.8047, 1.3832, 0.7494, 0.7147, 0.9092, 1.0727, 1.0620, 0.8531, 0.6842,\n                      0.9717, 0.7857, 1.1836, 0.5982, 0.7699, 0.7925, 1.3929, 0.6851, 0.8385,\n                      0.7794, 0.9109, 0.9809, 0.8450, 1.0506, 0.5565, 1.3319, 0.9007, 0.8843,\n                      0.9872, 0.6542, 0.7595, 0.7157, 0.8794, 0.7231, 0.5583, 1.1861, 0.5416,\n                      0.8297, 1.3452, 0.8890, 0.6972, 0.9840, 0.7310, 0.6544, 1.3836, 1.7491,\n                      0.9332, 0.9863, 1.2462, 1.1203, 1.0780, 0.8487, 1.0835, 0.5943, 0.8248,\n                      0.7131, 0.7569, 0.8878, 0.8749, 1.1366, 0.8875, 0.9762, 0.7264, 2.7936,\n                      0.7270, 1.0545, 0.8450, 0.7195, 0.7465, 0.6769, 0.5613, 0.7703, 0.7090,\n                      0.8259, 0.7009, 1.0626, 0.9057, 1.1897, 0.8073, 0.6287, 0.9165, 0.9716,\n                      1.0059, 0.9815, 0.6948, 0.7452, 0.9766, 1.3809, 0.7095, 0.8195, 0.6465,\n                      0.8891, 0.7168, 1.6962, 0.7097, 0.6593, 0.9123, 1.0818, 0.6055, 0.7613,\n                      1.3815, 1.0137], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.firstconv.norm.bias',\n              tensor([-0.2753, -0.2481,  0.4844,  0.5428, -0.2324,  0.4377, -0.0115, -0.4004,\n                       0.4419,  0.4205,  0.1151,  0.0177, -0.4527,  0.8683,  0.3671, -0.1945,\n                      -0.0554,  0.6693,  0.4785, -0.7627,  0.0740, -0.4332,  0.4982,  0.1904,\n                       0.2613, -0.0120,  0.6098,  0.0725,  0.3751, -0.1883,  0.1811, -0.0520,\n                       0.7867, -0.2337,  0.4975, -0.3147,  0.5013,  0.1942,  0.2530, -0.6432,\n                       0.1557,  0.5367,  0.8105, -0.1864,  0.5619, -0.4903,  0.0118,  0.4190,\n                       0.3357,  0.4852, -1.0540,  0.0491,  0.2481, -0.5023,  0.2576, -0.2597,\n                       0.2394,  0.3230,  0.3251, -0.3395,  0.0144,  0.4715, -1.5470,  0.1413,\n                       0.8848,  0.1186,  0.0488,  0.5567, -0.8216, -0.3303,  0.1323,  1.2021,\n                       0.0988,  0.6038,  0.8922,  0.7811,  0.2323,  0.2136,  0.1815, -1.5513,\n                      -0.2355, -0.0588,  0.2177, -0.3882,  0.5394,  0.0136, -0.0937,  0.2362,\n                      -0.6467, -0.0059, -0.6818,  0.5055,  0.7275,  0.1531, -0.9363, -0.2024,\n                      -0.8246, -0.6228,  0.3553, -0.5199, -0.5335,  0.6037, -0.6628,  0.3495,\n                       0.5183, -0.5388, -0.6451,  0.6270,  0.5597,  0.8513, -0.9174, -0.0737,\n                       0.5534, -0.0408, -0.1816,  0.3891, -0.6553, -0.3719, -0.0130,  0.7399,\n                      -0.2365, -0.8836, -0.0679,  0.5871, -0.2042, -0.4895,  0.5454,  0.4443],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.firstconv.layer.weight',\n              tensor([[[[-8.1205e-03, -3.3711e-02,  2.8848e-02],\n                        [-1.5080e-01, -2.2481e-01, -7.5957e-03],\n                        [-8.6801e-02, -2.5822e-01, -3.4945e-02]],\n              \n                       [[ 9.3626e-03,  1.8859e-03, -1.8983e-02],\n                        [ 2.3600e-02,  3.5109e-02,  1.2526e-02],\n                        [ 5.7273e-02,  6.0786e-02,  1.6962e-02]],\n              \n                       [[-3.3688e-02, -2.8153e-02,  6.6648e-03],\n                        [-1.3271e-04,  8.0120e-02,  1.7171e-02],\n                        [ 1.9887e-02,  9.3458e-02,  1.7807e-02]],\n              \n                       ...,\n              \n                       [[ 1.2979e-02,  1.2537e-02,  7.8727e-03],\n                        [ 5.0025e-02,  1.9184e-02, -6.8825e-03],\n                        [ 2.0699e-02, -7.5855e-03, -5.2879e-02]],\n              \n                       [[ 4.4206e-02, -2.3166e-02,  3.0567e-02],\n                        [-1.3490e-02, -1.0762e-01,  2.1101e-03],\n                        [-7.4061e-02, -1.5344e-01, -3.2007e-02]],\n              \n                       [[ 3.6654e-02,  4.7191e-02,  3.5278e-02],\n                        [ 4.3626e-02,  1.0844e-02,  1.7551e-02],\n                        [ 3.1620e-02,  4.0912e-02,  4.2754e-02]]],\n              \n              \n                      [[[-2.8776e-04, -7.8951e-03, -5.7852e-03],\n                        [-1.3649e-02,  1.5074e-03, -1.6948e-02],\n                        [-1.1091e-02, -1.2909e-02, -2.6778e-03]],\n              \n                       [[-1.3380e-02, -3.9744e-02, -1.6939e-02],\n                        [-9.7406e-03,  3.2209e-03,  1.2921e-02],\n                        [ 2.1520e-02, -1.5216e-02, -5.5493e-02]],\n              \n                       [[ 7.2366e-02, -3.5167e-02, -4.9574e-02],\n                        [-4.7403e-02, -9.9847e-02,  4.4783e-03],\n                        [-1.9734e-02, -2.8288e-02,  3.2140e-02]],\n              \n                       ...,\n              \n                       [[-1.1011e-01, -4.4760e-02, -7.6214e-02],\n                        [ 7.8382e-02, -3.9417e-03, -1.1438e-03],\n                        [ 6.1033e-02, -3.9205e-02,  4.1747e-02]],\n              \n                       [[-1.4755e-02,  1.0108e-02, -7.2054e-03],\n                        [ 7.3255e-04,  8.4797e-04, -1.2562e-02],\n                        [ 2.1393e-03,  1.9461e-02,  1.7856e-02]],\n              \n                       [[ 1.2429e-02, -5.0655e-03,  1.3574e-02],\n                        [-3.8213e-03,  9.5854e-03,  2.6003e-02],\n                        [ 3.0353e-02,  6.3644e-03,  1.0306e-03]]],\n              \n              \n                      [[[-2.7981e-03,  3.5268e-03, -1.2215e-03],\n                        [-2.9710e-02,  1.0474e-02, -4.1727e-02],\n                        [-4.4886e-02, -3.4653e-02, -3.8381e-02]],\n              \n                       [[-7.7962e-03, -2.9332e-02, -5.1005e-03],\n                        [-3.6458e-03,  3.2115e-02,  8.4271e-03],\n                        [-2.9839e-02, -1.9836e-02, -7.6937e-03]],\n              \n                       [[-3.0130e-03,  5.1557e-03,  3.8524e-02],\n                        [ 8.1056e-03,  4.9589e-02,  1.5561e-02],\n                        [-1.1030e-02, -2.8271e-02, -2.6980e-02]],\n              \n                       ...,\n              \n                       [[-1.2498e-02,  3.9041e-02, -6.8305e-03],\n                        [ 2.7982e-02,  8.5739e-03,  3.6055e-03],\n                        [-5.2749e-03, -5.4051e-02,  6.0634e-03]],\n              \n                       [[ 1.6179e-05, -1.6007e-02,  3.5577e-02],\n                        [-5.6560e-02, -3.6593e-02,  7.3869e-02],\n                        [ 3.8192e-03, -7.4150e-02, -2.2710e-02]],\n              \n                       [[ 6.0789e-03,  1.1819e-02, -1.7350e-02],\n                        [-8.9773e-03,  7.9403e-03, -5.9940e-03],\n                        [-1.1912e-02,  4.7777e-02,  3.7890e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-7.1749e-02, -1.3633e-01, -3.2614e-02],\n                        [ 1.4688e-01,  1.0364e-01, -2.7799e-02],\n                        [ 5.8839e-02,  1.4722e-01, -2.4705e-02]],\n              \n                       [[-5.6145e-02, -1.8361e-02,  2.7718e-02],\n                        [-2.6325e-02,  6.8180e-02,  6.0368e-02],\n                        [-2.1289e-03, -6.2134e-03,  5.2787e-02]],\n              \n                       [[-8.7446e-03,  8.6555e-03,  8.0855e-03],\n                        [-5.4564e-02, -2.9952e-02,  5.3209e-02],\n                        [-1.0687e-01, -5.0029e-02,  6.5095e-02]],\n              \n                       ...,\n              \n                       [[ 4.8741e-03, -5.8984e-03, -2.3638e-02],\n                        [-8.4877e-03,  2.8034e-02,  9.4722e-03],\n                        [ 5.4429e-02, -4.1532e-03, -4.6687e-03]],\n              \n                       [[-1.1156e-02, -2.5949e-02,  2.3658e-02],\n                        [-4.0477e-02, -4.4719e-02, -1.9269e-02],\n                        [-9.7755e-04, -5.6841e-02,  3.8000e-02]],\n              \n                       [[ 1.5534e-02,  2.1878e-02,  9.6182e-03],\n                        [ 1.9085e-02,  1.8827e-02,  2.8472e-02],\n                        [-3.6894e-03,  2.8135e-02,  1.5681e-02]]],\n              \n              \n                      [[[-1.8397e-03,  1.5491e-03, -1.7521e-02],\n                        [-5.1590e-03,  2.1273e-02, -4.8722e-02],\n                        [-7.7250e-03, -3.0269e-02, -3.4464e-02]],\n              \n                       [[-2.0759e-02, -8.6524e-03, -6.2292e-03],\n                        [ 1.1081e-02,  4.9908e-02,  1.2516e-03],\n                        [ 1.5766e-02,  1.2287e-02, -2.4738e-03]],\n              \n                       [[-2.5006e-03,  8.6851e-03, -2.0786e-02],\n                        [-2.2863e-02, -5.5769e-03,  5.5798e-02],\n                        [ 3.8537e-03, -7.6004e-03,  1.1855e-02]],\n              \n                       ...,\n              \n                       [[ 4.0184e-02,  1.0727e-02, -4.1479e-03],\n                        [-3.9054e-03, -1.7758e-03, -2.7532e-02],\n                        [ 1.5214e-02, -5.2954e-02,  4.7581e-05]],\n              \n                       [[-4.8666e-04,  1.9296e-02,  1.5064e-02],\n                        [-1.7386e-02,  2.3117e-02,  2.4766e-02],\n                        [-2.3537e-02,  1.4084e-02,  2.6656e-02]],\n              \n                       [[ 9.6710e-03, -3.9448e-04, -1.3644e-03],\n                        [ 2.2175e-02, -3.9271e-03, -4.0667e-02],\n                        [ 3.4525e-02,  1.1164e-01, -1.1156e-02]]],\n              \n              \n                      [[[ 1.5855e-03,  3.1140e-02, -2.0193e-02],\n                        [ 3.9714e-02, -5.9378e-02, -7.8793e-02],\n                        [-3.3386e-02, -1.7184e-02,  1.1038e-02]],\n              \n                       [[-1.0280e-01, -1.0498e-01, -3.7914e-02],\n                        [ 9.7960e-03, -2.5970e-02,  2.0105e-02],\n                        [-8.1054e-02,  3.0205e-03, -2.8677e-02]],\n              \n                       [[ 4.4850e-02,  9.6830e-03, -2.2911e-02],\n                        [ 3.7802e-02, -3.4267e-02, -2.6599e-02],\n                        [-2.8396e-02, -1.2176e-01, -4.1779e-02]],\n              \n                       ...,\n              \n                       [[-1.3535e-02,  4.1864e-02,  1.8733e-02],\n                        [ 5.0092e-03,  5.4991e-02,  3.5114e-02],\n                        [ 3.6239e-02,  4.0471e-02, -1.0079e-02]],\n              \n                       [[-9.7006e-03, -6.0112e-04, -2.7894e-02],\n                        [ 6.2430e-02, -5.6402e-02, -9.2501e-02],\n                        [-4.6871e-02, -1.1024e-01, -3.0273e-02]],\n              \n                       [[ 1.7822e-02,  1.3294e-02, -1.3753e-02],\n                        [ 6.3388e-03,  2.7036e-02,  3.7085e-03],\n                        [ 2.1547e-04, -8.2920e-03, -1.2009e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.n.weight',\n              tensor([0.6341, 0.2105, 0.4208, 0.3240, 0.1811, 0.3816, 0.2256, 0.2378, 1.1924,\n                      0.4639, 1.1125, 0.1421, 0.2704, 1.0574, 0.5222, 0.2846, 0.8677, 0.4572,\n                      0.2444, 1.4343, 0.3452, 0.2866, 0.2771, 0.3541, 0.3600, 0.6731, 0.2202,\n                      0.4257, 0.2967, 0.3710, 1.3736, 0.1765, 0.2085, 0.3348, 0.8111, 1.5873,\n                      0.5532, 0.3263, 0.3534, 0.3518, 0.3160, 0.2194, 0.8309, 0.2713, 0.6842,\n                      0.2834, 0.3969, 0.8292, 0.2802, 0.2800, 0.3708, 0.4707, 0.2038, 0.1400,\n                      1.3860, 0.5161, 0.3624, 0.2991, 0.4420, 0.5518, 0.4239, 1.1313, 1.0542,\n                      0.7010, 0.9365, 0.5125, 0.4834, 0.6182, 0.8283, 0.6623, 0.4664, 0.2530,\n                      0.4348, 0.4169, 0.2753, 0.4622, 0.3010, 0.4111, 0.3508, 0.3044, 0.3477,\n                      0.5213, 0.4129, 0.3520, 0.1632, 0.4725, 0.2409, 0.5768, 0.5794, 0.2521,\n                      0.2186, 2.2488, 0.6847, 1.0706, 0.6040, 0.7524, 1.5573, 0.1787, 0.4175,\n                      0.8137, 0.8350, 0.1871, 0.1606, 0.5233, 0.5833, 0.3627, 0.2434, 0.1700,\n                      0.3037, 1.0988, 0.5033, 0.5836, 0.9504, 0.4478, 0.3773, 0.2926, 1.1905,\n                      0.2495, 0.1478, 0.4403, 1.7208, 0.4900, 0.4331, 0.5234, 0.7622, 0.1473,\n                      0.2478, 0.3535, 1.1667, 0.4912, 0.3517, 0.4662, 0.4292, 0.8606, 0.4984,\n                      0.9042, 0.2526, 0.6135, 0.4271, 0.4308, 0.8799, 0.6238, 0.7677, 0.2979,\n                      0.3830, 0.2953, 0.1403, 0.2560, 0.2005, 0.3744, 1.8336, 0.2981, 0.1980,\n                      0.9542, 0.3876, 0.2391, 0.5336, 0.2880, 0.1817, 0.2190, 0.6741, 0.2795,\n                      0.2001, 0.2197, 0.3675, 0.2479, 1.0616, 0.2896, 0.5657, 0.1973, 0.3403,\n                      0.3293, 0.2959, 0.3941, 0.5170, 0.8138, 0.5845, 0.2927, 0.4716, 0.4518,\n                      0.3844, 0.2357, 0.2082, 0.1787, 0.2330, 0.1083, 0.4006, 1.4234, 1.1699,\n                      0.2522, 0.3050, 0.3589, 0.3656, 0.3505, 1.0134, 0.6581, 0.2669, 0.3762,\n                      0.3118, 0.1276, 0.3063, 0.2045, 0.3483, 0.3534, 0.2274, 0.2672, 0.4856,\n                      0.4510, 0.2156, 0.2999, 1.2790, 0.2889, 0.9493, 0.2786, 0.2841, 0.2812,\n                      0.6477, 0.9832, 0.4801, 0.3228, 0.3345, 0.6665, 0.4964, 0.2122, 0.2190,\n                      0.2489, 0.1325, 0.7018, 0.2719, 0.5547, 0.5623, 0.3084, 0.2139, 0.5411,\n                      0.1202, 0.4347, 0.4016, 0.2270, 0.3671, 0.3933, 0.4968, 0.8119, 0.6946,\n                      0.3271, 0.6583, 0.4453, 0.2805, 0.2783, 0.3336, 0.5486, 0.3171, 0.5821,\n                      0.7383, 0.3015, 0.2801, 0.3158], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.n.bias',\n              tensor([-4.8421e-02, -9.1149e-02,  1.1821e-01,  1.2238e-01,  3.2342e-02,\n                       5.7584e-02, -9.5852e-02, -9.4263e-02,  6.3992e-01,  1.6994e-01,\n                       4.4012e-03,  3.8735e-02,  6.3789e-02,  1.3394e-01,  6.0006e-02,\n                      -3.5873e-03, -5.2433e-02, -1.3146e-01, -2.6839e-01,  3.7755e-01,\n                      -1.3547e-01, -4.9076e-02, -2.1818e-01,  1.0704e-01,  8.1700e-03,\n                      -8.1457e-02,  8.7380e-02,  2.3591e-01, -2.6551e-01, -7.2266e-02,\n                      -3.8058e-02, -5.3052e-02, -1.3732e-01,  1.2766e-01,  2.2618e-01,\n                      -5.3169e-01,  1.8323e-02, -1.6940e-01,  1.0183e-01,  2.1438e-01,\n                       1.7255e-01,  7.6145e-02,  4.0150e-01, -1.4640e-02,  1.6909e-01,\n                      -1.6073e-01, -3.1284e-01, -1.0225e+00, -7.4657e-02, -2.0345e-01,\n                      -3.2062e-01,  1.5520e-01,  3.0300e-01, -1.0835e-02,  5.3403e-02,\n                      -3.4489e-01,  4.6350e-02,  5.0412e-02, -2.0401e-01,  1.2606e-01,\n                      -5.4232e-01, -1.2865e-02, -1.4675e-01,  4.8666e-01, -1.4701e-01,\n                      -4.7807e-01,  1.3644e-01, -4.6558e-01, -2.0551e-01,  3.0959e-01,\n                      -1.5430e-01, -1.4271e-01, -1.1248e-01,  1.2824e-01, -5.8860e-01,\n                       3.3625e-02, -1.7391e-01, -2.0920e-01, -2.3874e-01,  4.1763e-02,\n                      -2.8571e-02,  7.9291e-02, -1.2438e-01, -1.9176e-01,  2.5828e-01,\n                      -8.5725e-02,  9.0490e-02, -4.5563e-01, -2.3402e-02, -3.8366e-03,\n                       8.0263e-02, -6.4576e-01,  5.4897e-02,  3.7538e-01, -5.0731e-01,\n                       1.2317e-01,  1.3383e-01,  1.1119e-01, -3.5323e-02, -3.1652e-01,\n                       6.2946e-02, -4.5985e-03, -9.2976e-02, -1.4653e-01, -4.7706e-01,\n                       9.5371e-02,  3.1491e-02,  4.2312e-02,  7.0627e-02, -1.1765e-02,\n                      -3.2950e-01,  2.0712e-01, -1.5711e-01, -4.2787e-04,  4.9712e-02,\n                      -5.4817e-02,  5.7461e-01, -4.8619e-02,  3.6170e-02, -2.1646e-02,\n                      -2.9513e-01, -8.0846e-01, -1.7510e-02,  5.1425e-02, -4.1536e-01,\n                      -4.4367e-02, -1.0279e-01,  1.3750e-02, -1.0763e-01, -1.9309e-02,\n                      -2.1364e-01, -1.1437e-01, -4.3668e-01,  4.6137e-01,  1.6263e-01,\n                       2.7374e-01, -2.4199e-02,  1.6399e-01, -2.9557e-01, -5.2094e-01,\n                      -4.9030e-02, -2.7180e-01, -1.0824e+00,  2.7695e-01,  9.9890e-02,\n                       1.9390e-02, -4.9311e-02,  6.7409e-02, -1.7820e-02,  7.0271e-02,\n                       3.2804e-01, -1.3099e-01, -7.1832e-02,  1.4689e-01, -5.6420e-02,\n                      -2.4281e-01, -1.2631e-01,  9.4898e-02,  5.8986e-02, -8.4768e-02,\n                      -7.0653e-02, -2.5755e-02, -7.7856e-02,  2.6531e-02,  9.0769e-02,\n                      -4.1717e-02, -2.4762e-01, -1.2699e-01, -1.0021e-01, -5.7897e-02,\n                       2.2289e-02, -2.7583e-01, -1.1581e-01, -1.2498e-01, -1.9739e-01,\n                      -7.5024e-01, -2.1226e-01, -1.3400e-01, -5.6250e-02,  4.2875e-02,\n                       1.0023e-01,  1.4086e-01,  1.3305e-02, -7.1918e-03, -7.8194e-02,\n                       7.9021e-01, -9.1028e-02,  2.4475e-01, -3.9689e-01,  3.6107e-02,\n                      -1.0781e-01, -4.8944e-01,  1.6143e-01, -3.5215e-01, -2.4744e-01,\n                      -7.8402e-02,  4.2275e-02, -1.0434e-01,  2.4925e-02, -9.1585e-02,\n                      -1.3503e-01, -4.8645e-02, -2.3401e-01, -3.1299e-02, -1.0233e-02,\n                      -8.4399e-02,  1.2892e-01, -9.0152e-02, -1.5761e-01, -1.0057e-01,\n                       1.9496e-01,  4.1892e-02,  3.4400e-02,  2.1046e-02, -1.1857e-01,\n                      -1.4941e-01, -7.0297e-02, -5.5445e-02,  4.9000e-03,  1.0061e-01,\n                      -1.1464e-01, -2.7171e-02, -2.2336e-02, -1.4344e-01,  4.6448e-02,\n                       7.0807e-03,  7.7074e-02, -3.3524e-01, -6.9566e-02,  8.9255e-02,\n                       3.1702e-02, -9.9422e-02, -3.6316e-02, -1.9714e-01, -7.9250e-03,\n                      -7.6272e-03, -2.1146e-01, -8.6376e-02, -1.8290e-01,  6.6324e-02,\n                      -5.7864e-02, -3.1279e-02,  2.6182e-01, -2.0090e-01, -1.2003e-01,\n                       9.9619e-03,  1.5545e-01,  1.1124e-02, -1.1000e-01, -4.6491e-01,\n                      -7.6225e-02,  4.3484e-01,  1.3434e-01,  1.6014e-02,  1.0708e-01,\n                      -1.6218e-01], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv0.norm.weight',\n              tensor([0.5798, 1.6780, 1.3983, 1.5783, 1.7886, 1.4944, 1.7012, 1.6541, 1.1280,\n                      1.8290, 0.3057, 2.3797, 1.5772, 0.5164, 0.6730, 1.2195, 0.3968, 0.8663,\n                      1.3044, 0.6107, 1.0289, 1.1127, 1.1470, 2.6276, 0.7195, 0.7027, 1.4521,\n                      1.9579, 0.8237, 0.9924, 0.2559, 1.9830, 1.4100, 1.1389, 0.3985, 0.1439,\n                      0.5821, 0.9823, 1.5988, 2.1545, 1.2425, 0.9263, 1.1827, 1.7975, 1.0430,\n                      1.1155, 0.5779, 0.2014, 1.6905, 1.2170, 0.7661, 1.6035, 1.3167, 2.7731,\n                      0.2427, 0.3494, 0.7563, 1.2769, 0.6633, 1.0223, 0.3422, 0.3616, 0.2524,\n                      1.5629, 0.2158, 0.4751, 1.3975, 0.2572, 0.2853, 2.1231, 0.7730, 1.5085,\n                      0.6460, 0.8594, 0.8121, 1.1050, 1.6557, 0.8573, 0.2851, 1.3638, 0.8958,\n                      0.6306, 0.9487, 0.8612, 1.4473, 1.0664, 1.5156, 0.4560, 1.3426, 1.4854,\n                      1.7332, 0.1280, 0.6139, 1.0107, 0.4492, 0.3495, 0.4136, 1.9025, 0.7691,\n                      0.3238, 0.4867, 1.7845, 1.7139, 0.5777, 0.5093, 1.1370, 1.2178, 2.2694,\n                      1.3292, 0.3240, 0.5356, 1.3778, 0.3473, 0.8664, 1.4210, 1.0131, 1.2443,\n                      1.5948, 2.3733, 0.7966, 0.1568, 0.4109, 0.9149, 0.5682, 0.2712, 2.2051,\n                      1.8315, 0.9721, 0.3673, 1.3029, 0.6334, 0.9387, 0.7841, 1.8685, 1.2794,\n                      0.3905, 1.7738, 1.0452, 0.9433, 0.6794, 0.3344, 0.4804, 0.1961, 1.1986,\n                      0.7989, 1.8881, 2.4293, 1.7250, 2.4041, 1.4389, 0.1046, 1.1509, 2.2574,\n                      0.5817, 0.7673, 1.4762, 0.8534, 2.3063, 2.3115, 1.4847, 0.5463, 1.1673,\n                      2.0278, 2.0040, 1.0310, 1.4656, 0.4476, 1.2029, 0.4448, 1.5396, 1.2994,\n                      1.1966, 1.3746, 0.4351, 0.6036, 0.2415, 0.4075, 0.5064, 1.8246, 0.6714,\n                      1.3550, 1.6895, 2.2013, 1.9297, 1.6686, 0.9113, 0.7324, 0.1949, 0.2440,\n                      1.8021, 1.1993, 0.7828, 0.9707, 0.7307, 0.3133, 0.6369, 1.3954, 0.9279,\n                      1.5354, 2.5101, 1.0994, 1.4189, 0.8547, 0.9747, 1.7066, 1.0006, 0.8899,\n                      1.1193, 1.2420, 1.4373, 0.2190, 1.6410, 0.4388, 1.9751, 1.3379, 1.0480,\n                      0.4489, 0.3231, 0.7481, 1.8248, 0.9243, 0.8513, 1.4466, 1.9510, 2.2629,\n                      1.8283, 1.9874, 0.3213, 1.5597, 0.6571, 0.7565, 1.1377, 1.2591, 0.3475,\n                      3.3953, 1.2094, 1.2625, 1.2285, 0.9782, 1.2974, 0.6608, 0.7175, 0.9802,\n                      1.2453, 0.6406, 1.2522, 1.6392, 1.3515, 1.3829, 0.3768, 1.0333, 1.6513,\n                      0.4067, 1.0122, 1.8873, 1.2008], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv0.norm.bias',\n              tensor([ 1.7141e-01, -1.1385e-01,  1.6242e-01, -7.5268e-02, -3.2198e-01,\n                      -1.0763e-02,  3.6332e-02,  1.1539e-01,  5.2870e-01,  1.9868e-01,\n                       2.0433e-01, -8.1180e-01,  3.4427e-02,  2.3064e-01,  7.2501e-02,\n                      -1.3637e-01, -5.3004e-02,  5.2296e-02,  2.8291e-01,  5.4807e-01,\n                       3.5493e-01, -3.5471e-02, -6.7213e-02,  4.1081e-02, -1.8539e-01,\n                       3.1407e-01, -3.3470e-01,  1.0103e-01, -1.2725e-01, -1.1364e-01,\n                      -1.3864e-01, -4.9765e-02,  6.5214e-02, -5.4277e-02,  2.4000e-02,\n                       3.4977e-01,  6.7676e-03, -7.5526e-02,  5.7463e-02, -1.3534e-01,\n                      -2.4414e-01, -3.5449e-01,  3.6467e-01,  7.2737e-02,  5.0247e-01,\n                       1.0822e-01,  9.4764e-02, -2.1945e-01, -1.6683e-01,  4.0222e-01,\n                       7.2035e-02,  2.8126e-01, -9.3780e-01, -1.8590e-01,  1.9655e-01,\n                      -1.2004e-01, -1.7367e-01, -6.9930e-02,  2.7162e-01,  2.4823e-01,\n                      -3.5320e-01,  2.7581e-01,  1.3754e-02,  1.3059e-01, -2.1856e-01,\n                       7.5555e-02, -2.9563e-01, -2.3795e-01, -1.5327e-01,  3.9653e-01,\n                       2.0377e-01, -8.8894e-02, -2.2886e-02, -1.5582e-01,  1.5908e-01,\n                       1.1275e-01,  1.0345e-01,  1.2363e-01, -5.3587e-01, -4.8185e-02,\n                      -1.0018e-01,  1.1908e-01,  8.8700e-02, -1.0712e-01, -6.3354e-01,\n                      -2.8400e-01, -1.7682e-01,  9.2077e-04, -1.5773e-02,  1.9655e-02,\n                      -2.2148e-01,  9.5820e-02,  1.9732e-01,  6.5721e-01,  5.5671e-02,\n                      -2.1154e-01,  5.9191e-01, -4.8628e-01, -8.0214e-02,  2.1277e-01,\n                       1.1358e-01, -2.4504e-01, -1.3836e-01, -6.8259e-02,  2.6842e-03,\n                      -7.2195e-02, -1.4726e-01, -1.5027e-01,  2.2834e-03,  2.1174e-01,\n                      -1.5081e-01,  3.8845e-01,  1.4997e-01, -3.4221e-03, -8.8379e-02,\n                      -6.1404e-02,  7.8513e-01,  5.7003e-02, -3.1444e-01, -4.4970e-02,\n                      -1.2877e-01, -3.0935e-01,  2.0744e-01, -6.5544e-02, -6.3205e-02,\n                      -9.7626e-02, -8.8550e-02, -8.5288e-03,  3.4272e-01,  1.8524e-03,\n                      -1.9605e-01,  2.3320e-01,  2.7853e-01,  4.3355e-01,  2.7360e-01,\n                       2.0247e-03,  1.1567e-01,  2.3778e-01,  2.3226e-01,  3.4838e-01,\n                       2.4944e-01, -3.4980e-02, -1.6787e-01, -3.7459e-01, -1.3857e-01,\n                      -1.0818e-01,  1.2561e-01,  7.1975e-03, -1.2588e-02,  1.6706e-01,\n                      -5.2734e-01,  1.2361e-01,  4.6144e-02,  4.9134e-01,  6.1307e-02,\n                      -2.2728e-01, -1.2445e-01,  6.1446e-02, -2.4210e-01,  8.3370e-02,\n                      -1.0923e-02, -2.2744e-01, -9.2686e-02,  6.9814e-02, -6.7156e-02,\n                       9.0421e-03,  5.1578e-01, -7.7769e-02, -1.9965e-01, -2.1072e-01,\n                       2.0985e-01,  2.2720e-01, -7.8804e-02, -5.7041e-01,  1.9786e-01,\n                      -3.7302e-02,  1.4856e-01, -4.4701e-01,  6.3468e-02, -5.7617e-02,\n                      -3.7912e-02, -4.1983e-01, -1.0079e-02, -3.9296e-02, -4.3701e-02,\n                       7.0816e-01, -2.3778e-03, -2.3037e-02,  1.4896e-01,  1.3127e-01,\n                      -1.2698e-01,  3.0770e-01, -1.8391e-01, -1.1640e-01,  1.8092e-01,\n                       2.7357e-01, -2.0502e-01,  3.1132e-01,  1.3603e-01, -1.2956e-01,\n                       1.9741e-01, -1.3526e-01,  9.1381e-02,  4.0709e-02, -9.5740e-02,\n                      -2.0948e-01,  2.0532e-02, -7.4478e-02,  3.2722e-03,  2.4893e-01,\n                       5.2595e-02, -1.1236e-01,  3.3546e-01,  1.2354e-02,  1.7286e-01,\n                      -6.6660e-03,  8.0162e-02,  9.7858e-02,  9.4191e-02,  1.5149e-01,\n                      -1.7347e-01,  1.3207e-01,  1.7604e-02,  2.3205e-01, -1.5323e-01,\n                       1.9082e-01, -6.2584e-01,  4.8150e-02,  1.9536e-01, -3.0163e-01,\n                       1.4003e-01,  8.3727e-02, -5.3695e-01, -5.1869e-01, -2.5255e-01,\n                       3.7496e-02,  2.4426e-01, -5.5475e-02,  2.0079e-01,  9.6135e-02,\n                      -1.4862e-01,  4.4631e-01,  2.0598e-01,  4.1570e-02,  2.6068e-01,\n                       2.4061e-01, -2.0934e-01,  1.8456e-02,  2.6867e-01, -5.5883e-04,\n                       2.1585e-01, -1.1697e-02, -1.3925e-01, -2.6066e-01, -1.2646e-01,\n                       1.3050e-01], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv0.layer.weight',\n              tensor([[[[ 8.2341e-03,  1.9781e-02,  4.6556e-02],\n                        [ 6.3928e-02, -1.0694e-02,  6.1180e-02],\n                        [ 2.7156e-02, -4.4110e-02,  8.8626e-02]],\n              \n                       [[-9.7486e-05,  1.6054e-02,  1.1523e-02],\n                        [ 1.9497e-02, -1.3256e-02,  2.5461e-02],\n                        [ 1.3867e-02, -3.2400e-02, -3.0570e-02]],\n              \n                       [[-1.6706e-02,  1.8513e-02,  7.2089e-03],\n                        [ 2.0826e-02,  8.0488e-02,  2.1948e-02],\n                        [-2.0247e-02,  2.2566e-02, -5.7579e-02]],\n              \n                       ...,\n              \n                       [[ 3.0786e-02,  3.5540e-02,  2.3565e-02],\n                        [-2.5950e-02,  2.4285e-02,  2.8305e-02],\n                        [ 1.1008e-02,  1.2753e-02,  2.2272e-02]],\n              \n                       [[-2.0963e-03,  3.1807e-02, -2.4793e-02],\n                        [-2.1103e-02,  4.6445e-02, -3.4151e-02],\n                        [-5.2321e-04,  3.4044e-02, -4.0801e-02]],\n              \n                       [[ 8.1017e-03,  3.4246e-02, -2.0703e-02],\n                        [ 1.0178e-03,  7.3369e-02, -2.2471e-02],\n                        [-3.3720e-02,  4.5212e-02, -1.5976e-02]]],\n              \n              \n                      [[[ 3.4227e-02,  7.9068e-02,  3.8561e-02],\n                        [-4.2297e-02, -1.0929e-02,  2.1135e-02],\n                        [ 6.1655e-03, -9.5533e-03, -1.7366e-02]],\n              \n                       [[ 1.5724e-02,  1.3586e-02,  3.7106e-02],\n                        [ 8.7885e-03, -8.9978e-03, -1.0584e-02],\n                        [ 1.7667e-02,  3.8155e-03,  1.6724e-03]],\n              \n                       [[-1.1186e-02, -5.9195e-02, -2.3240e-02],\n                        [-3.8017e-02,  2.4109e-02, -4.0830e-02],\n                        [-2.2252e-02, -4.8413e-02, -1.4441e-02]],\n              \n                       ...,\n              \n                       [[-7.4932e-04,  4.0968e-02, -1.2655e-02],\n                        [ 2.5454e-02,  7.8105e-02, -2.9048e-02],\n                        [ 1.5459e-02, -1.4151e-02,  1.8442e-02]],\n              \n                       [[-5.7471e-02, -1.2099e-01, -2.9603e-02],\n                        [-1.9910e-02, -4.1195e-02, -7.7476e-02],\n                        [-1.7658e-02,  8.7411e-03,  1.0672e-03]],\n              \n                       [[ 2.0477e-02,  3.1173e-02, -1.4306e-02],\n                        [-2.1040e-02,  2.3144e-03,  1.2975e-02],\n                        [ 2.8465e-03,  1.4160e-02,  8.7752e-02]]],\n              \n              \n                      [[[-4.6903e-02, -5.6077e-02, -3.9751e-02],\n                        [-1.0001e-02,  2.6655e-02, -2.5361e-02],\n                        [-2.8005e-02, -1.8933e-02,  4.2783e-02]],\n              \n                       [[-2.8857e-02, -1.5029e-02, -3.2671e-02],\n                        [-4.6297e-03,  2.3759e-03,  2.0156e-02],\n                        [-3.8378e-02, -1.6546e-02,  7.3819e-03]],\n              \n                       [[-6.4822e-02, -2.2176e-02,  8.1389e-03],\n                        [-2.3011e-02, -3.1274e-02,  1.0761e-02],\n                        [ 2.1208e-02,  8.9084e-03, -6.4159e-04]],\n              \n                       ...,\n              \n                       [[-9.0333e-03,  1.9302e-02,  1.5937e-02],\n                        [-4.6969e-02, -7.9648e-02, -3.0867e-02],\n                        [ 1.5536e-02,  9.7924e-03, -5.6162e-03]],\n              \n                       [[-1.6182e-02,  1.2154e-02, -3.7326e-02],\n                        [-2.1654e-02,  1.0641e-02, -1.0692e-02],\n                        [-4.4569e-02, -7.2071e-03, -3.1088e-02]],\n              \n                       [[-2.8767e-02,  2.5560e-03, -4.1600e-02],\n                        [ 1.2465e-02, -9.3216e-02, -5.6838e-02],\n                        [ 4.5028e-03, -4.9555e-02, -2.2476e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-2.5617e-02, -1.4999e-02, -4.2350e-02],\n                        [ 9.2227e-03,  1.4626e-02,  1.5509e-02],\n                        [-1.7193e-02, -4.5482e-03,  7.9979e-03]],\n              \n                       [[ 4.0137e-02, -2.1479e-03,  8.9470e-02],\n                        [-6.1953e-02,  6.2241e-02,  4.8663e-02],\n                        [-1.5605e-02,  1.1418e-01,  1.1784e-01]],\n              \n                       [[-1.8390e-02, -3.4396e-02, -2.7416e-02],\n                        [-2.6319e-02, -1.8440e-02,  7.2997e-03],\n                        [-2.7383e-03, -1.3226e-02,  1.5204e-02]],\n              \n                       ...,\n              \n                       [[ 3.8665e-03, -5.5149e-03,  1.5243e-02],\n                        [-2.1216e-02, -8.8536e-03, -3.4171e-02],\n                        [-7.0277e-03, -7.5920e-03, -2.2914e-02]],\n              \n                       [[ 1.4237e-02, -1.0447e-02, -5.8557e-03],\n                        [-2.4639e-02, -3.3529e-02, -9.1412e-03],\n                        [-3.1015e-03, -1.7666e-02,  5.7200e-03]],\n              \n                       [[-3.1114e-02, -4.0219e-02, -1.1853e-02],\n                        [ 2.8009e-02,  3.6909e-02,  2.7704e-02],\n                        [-6.2696e-03, -2.3854e-02, -2.1096e-02]]],\n              \n              \n                      [[[-1.0641e-02, -2.0835e-02,  3.8679e-02],\n                        [-5.4320e-02, -5.3218e-02, -1.5522e-02],\n                        [-3.5861e-03, -3.2646e-02, -1.2239e-02]],\n              \n                       [[-5.9108e-02, -1.2597e-02, -4.2972e-04],\n                        [ 1.3592e-02,  5.4749e-02,  7.4080e-02],\n                        [-9.2023e-02, -8.3944e-02, -1.1347e-02]],\n              \n                       [[ 3.9569e-03, -7.6913e-04, -1.3554e-03],\n                        [-1.5115e-02, -2.6043e-02, -1.9896e-02],\n                        [ 8.5281e-03, -1.0936e-02, -1.5442e-03]],\n              \n                       ...,\n              \n                       [[-1.2194e-03,  1.6448e-02, -1.7116e-02],\n                        [ 5.2246e-03,  5.0540e-02,  1.8504e-02],\n                        [-1.3235e-02, -4.3925e-02, -6.3379e-03]],\n              \n                       [[ 6.3235e-03, -2.0026e-02, -8.8831e-03],\n                        [-2.5241e-02, -1.7050e-02, -6.2537e-03],\n                        [ 4.2884e-02,  3.8548e-02,  5.0648e-02]],\n              \n                       [[ 9.6880e-04, -1.8508e-02,  2.6834e-03],\n                        [-7.7418e-03, -1.4423e-02,  7.6071e-03],\n                        [-7.0646e-03, -9.2751e-02, -1.3948e-02]]],\n              \n              \n                      [[[-1.5981e-02,  6.8601e-02,  1.3592e-02],\n                        [ 1.2780e-02,  9.7988e-03, -2.7494e-03],\n                        [ 3.9376e-02,  1.4572e-02,  2.0557e-02]],\n              \n                       [[-5.8654e-03,  9.7418e-04, -9.4052e-03],\n                        [ 8.7551e-03, -1.0550e-02, -7.4107e-03],\n                        [ 2.5273e-03,  8.8779e-04,  1.9389e-02]],\n              \n                       [[ 4.4019e-02,  4.3635e-03,  6.1538e-03],\n                        [-1.3955e-03,  3.9811e-02,  1.7705e-02],\n                        [ 7.9441e-02,  2.2963e-02,  1.0808e-02]],\n              \n                       ...,\n              \n                       [[-2.2240e-02, -2.7822e-02,  1.6071e-02],\n                        [ 3.3261e-02, -3.2869e-02,  1.7156e-02],\n                        [ 3.1276e-02, -4.5716e-02, -9.9025e-03]],\n              \n                       [[-1.2152e-02,  7.4617e-03,  1.2460e-02],\n                        [ 2.4099e-03,  7.0567e-03,  2.3268e-02],\n                        [-5.0206e-03, -1.8533e-02, -1.3085e-02]],\n              \n                       [[-3.5825e-02, -7.9936e-03, -1.8984e-02],\n                        [ 3.1837e-02, -1.3675e-02, -4.9012e-02],\n                        [-1.8400e-03,  2.8218e-02, -1.9812e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv1.norm.weight',\n              tensor([0.9305, 1.4943, 0.5962, 0.8307, 0.6697, 0.8295, 0.9663, 0.6739, 1.2867,\n                      0.7234, 1.3563, 0.7688, 1.2988, 0.9518, 0.8592, 0.8058, 0.9893, 1.2220,\n                      1.0789, 2.1220, 0.9886, 0.6688, 0.6419, 0.6486, 1.2025, 1.0259, 0.9027,\n                      1.6086, 0.6212, 0.9092, 0.8983, 0.8220, 0.5374, 1.2110, 0.9438, 1.6941,\n                      2.4589, 0.7391, 0.9176, 1.0786, 1.2052, 0.9068, 0.8710, 1.0234, 0.8511,\n                      1.6531, 0.6841, 0.6212, 1.3871, 1.6341, 1.0104, 0.4357, 0.7190, 0.7752,\n                      1.2634, 0.7456, 0.7177, 0.8573, 1.5038, 0.6232, 0.5994, 0.9366, 0.9976,\n                      0.9012, 0.5791, 0.5188, 0.9091, 0.8882, 0.6937, 1.0635, 1.1746, 1.0468,\n                      0.4214, 1.2582, 1.2809, 2.3496, 0.6028, 0.8272, 0.6880, 0.9826, 1.1683,\n                      0.4446, 0.9209, 0.9474, 0.7911, 0.6871, 0.8708, 0.9214, 0.5876, 0.8424,\n                      0.8500, 0.7866, 0.8634, 0.8754, 0.8324, 0.6329, 0.9232, 0.9905, 1.3751,\n                      0.5955, 2.2222, 0.6273, 1.0466, 1.1048, 0.2972, 1.1133, 1.2443, 0.8974,\n                      0.6982, 0.7678, 0.5810, 0.6600, 1.2291, 0.7056, 1.2968, 1.2891, 0.9885,\n                      0.6092, 0.7506, 0.8112, 1.3305, 0.8376, 1.3942, 0.7873, 1.0092, 0.7493,\n                      1.1396, 0.6765, 1.1097, 1.0060, 1.3259, 0.6468, 0.6181, 0.7930, 0.8990,\n                      1.1763, 0.9739, 0.6881, 1.9492, 1.2891, 1.2042, 0.4841, 1.1762, 0.8520,\n                      1.2470, 0.5347, 0.6826, 0.6317, 0.9064, 0.5905, 0.8518, 0.6996, 1.3296,\n                      1.0015, 1.3578, 0.7796, 0.5786, 0.7783, 0.7878, 0.8772, 0.7777, 0.9016,\n                      1.6793, 0.9724, 0.5174, 1.2088, 0.4396, 1.6954, 0.8378, 1.0748, 1.0682,\n                      1.0290, 1.0091, 0.7753, 0.6725, 0.9257, 0.9805, 0.5672, 1.5872, 0.9049,\n                      0.3877, 0.9095, 1.4491, 0.4456, 0.7968, 0.8070, 0.8358, 1.1927, 0.8568,\n                      0.7578, 1.1209, 0.8723, 0.6136, 1.0617, 0.7811, 1.0568, 0.6012, 0.5950,\n                      0.7175, 1.5713, 0.9637, 1.0944, 1.1813, 0.9056, 1.5925, 1.2482, 3.1914,\n                      0.5248, 0.7693, 1.0569, 0.5302, 0.9460, 0.9034, 1.1773, 0.9323, 0.6385,\n                      0.6975, 1.0784, 1.1647, 0.5908, 0.5193, 0.6994, 0.7600, 1.4368, 0.7473,\n                      1.1269, 1.0897, 0.6979, 0.7441, 0.8292, 0.9141, 0.9835, 0.9658, 1.0871,\n                      0.5919, 0.6098, 1.1801, 0.9088, 0.8833, 1.0005, 0.6456, 1.6878, 1.3460,\n                      0.9312, 1.1574, 0.9430, 1.5474, 0.7004, 0.6264, 0.9188, 1.1466, 0.7928,\n                      1.7094, 0.9165, 0.5370, 2.6015], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv1.norm.bias',\n              tensor([ 0.1759,  0.6860, -0.3171, -0.1193, -0.0902,  0.1375,  0.2086, -0.2156,\n                       0.5252, -0.1740,  0.5949,  0.0916,  0.4187,  0.1449,  0.1756,  0.1424,\n                      -0.0029, -0.0134,  0.3538,  1.0152,  0.2020, -0.0527, -0.1033, -0.0715,\n                       0.5205,  0.2836,  0.0424,  0.4916,  0.0378,  0.1251,  0.1579, -0.0081,\n                      -0.3125,  0.3311,  0.4215,  0.8541,  1.1814, -0.0881, -0.0604,  0.2249,\n                       0.5122,  0.0883, -0.2723,  0.3645,  0.1186,  0.8024, -0.1816, -0.0656,\n                       0.4463,  0.7505,  0.1569, -0.9316, -0.0184, -0.0296,  0.5813,  0.0864,\n                       0.0743, -0.0118,  0.5358, -0.4544, -0.1751,  0.2521,  0.0017, -0.0080,\n                      -0.2316, -0.6504,  0.0974,  0.2660,  0.1077,  0.2322, -0.3244,  0.1909,\n                      -0.8066,  0.4151,  0.4458,  1.0719, -0.1444,  0.0902,  0.0476,  0.3648,\n                       0.4750, -0.4774,  0.1585,  0.2859,  0.2692, -0.1582,  0.1404,  0.2900,\n                      -0.3762,  0.1497,  0.1639, -0.0298, -0.8016,  0.1935,  0.3183, -0.3522,\n                       0.2279,  0.3428,  0.5868, -0.6372,  0.9602, -0.1618,  0.3872,  0.3350,\n                       0.7194,  0.2415,  0.4772,  0.3407, -0.3266,  0.1419, -0.3291,  0.0431,\n                       0.4035, -0.2108,  0.5030,  0.4867,  0.3139, -0.3705,  0.1956, -0.0533,\n                       0.5212,  0.0546,  0.1537,  0.0817,  0.2646,  0.0043,  0.2766, -0.0191,\n                       0.4655,  0.3623,  0.4373, -0.1184, -0.0855,  0.1131,  0.1368,  0.5186,\n                       0.1513, -0.1750,  0.9144,  0.5574,  0.3098, -0.3433,  0.2745,  0.0045,\n                       0.5881, -0.4621, -0.2333, -1.5404,  0.2919, -0.3874,  0.1931,  0.0104,\n                       0.3601,  0.2252,  0.3197, -0.0778, -0.9699, -0.1887,  0.1076,  0.1835,\n                       0.0288,  0.2053,  0.7084,  0.2759, -0.3273,  0.4039, -0.4870,  0.8031,\n                       0.0275,  0.3476,  0.3015,  0.3367,  0.2561,  0.2111, -0.0179,  0.1224,\n                       0.2955, -0.3553,  0.6971,  0.2500,  0.7534,  0.2681,  0.6691, -0.5004,\n                      -0.0186,  0.1198,  0.0927,  0.4980, -0.2341, -0.0395,  0.3975,  0.3566,\n                      -0.3711,  0.2493, -0.1721,  0.4066, -0.3439, -0.3586, -0.0602,  0.6230,\n                       0.2190,  0.2586,  0.5027,  0.2196,  0.6760,  0.3875,  1.4895, -0.6599,\n                       0.0879,  0.2602, -0.3610,  0.2294,  0.0857,  0.3963,  0.3284, -0.1246,\n                      -0.3401,  0.2846,  0.5041, -0.3848, -0.2062, -0.0747,  0.2025,  0.6683,\n                      -0.0318,  0.4071,  0.2345, -0.0384, -0.2535,  0.1370,  0.1043,  0.2023,\n                       0.1460,  0.3809, -0.1315, -0.1164,  0.3947,  0.3153,  0.1859,  0.0179,\n                      -0.3173,  0.5948,  0.5350,  0.2935,  0.3029,  0.3693,  0.6700,  0.1287,\n                      -0.3920,  0.1731, -0.1395,  0.0763,  0.6782,  0.1353, -0.9820,  1.1703],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.0.conv1.layer.weight',\n              tensor([[[[ 6.6647e-02,  3.0570e-02,  3.5126e-03],\n                        [-7.1620e-03, -5.6533e-03,  6.2211e-03],\n                        [-3.9087e-02,  3.9184e-03, -1.1155e-02]],\n              \n                       [[-1.0693e-02, -1.0316e-02, -1.5800e-02],\n                        [-1.7455e-02, -5.7283e-02, -8.2820e-03],\n                        [-1.4858e-02, -9.8335e-03, -3.0003e-02]],\n              \n                       [[-2.2925e-02, -2.5772e-02, -3.6743e-02],\n                        [ 1.9107e-02,  6.6469e-02,  1.1189e-02],\n                        [ 1.8155e-02, -1.1965e-02,  3.6229e-02]],\n              \n                       ...,\n              \n                       [[ 7.2225e-03,  4.1600e-03, -1.1272e-02],\n                        [ 2.7942e-02,  3.3125e-02,  1.1274e-02],\n                        [ 3.5281e-03,  1.4156e-02,  6.5994e-03]],\n              \n                       [[ 4.0196e-02, -2.3789e-02,  1.8405e-02],\n                        [ 2.4982e-02, -2.1030e-02,  4.2564e-03],\n                        [-1.2294e-03,  2.4036e-02, -8.1738e-03]],\n              \n                       [[-3.1414e-02, -2.4981e-03,  2.0297e-02],\n                        [ 2.0499e-02, -1.8001e-02,  2.9239e-02],\n                        [ 1.7697e-02, -2.7540e-02,  1.9326e-02]]],\n              \n              \n                      [[[ 1.8627e-02, -1.4412e-02,  2.8424e-02],\n                        [-3.8544e-02, -4.4871e-02,  1.8488e-02],\n                        [-2.9705e-02, -3.8571e-02, -1.2821e-02]],\n              \n                       [[-9.3543e-02, -2.7441e-02,  2.7219e-03],\n                        [ 3.1701e-02, -7.0709e-02, -3.5737e-02],\n                        [-2.2326e-03,  3.4855e-03,  1.7673e-02]],\n              \n                       [[-6.7120e-03,  1.3089e-02,  6.5178e-02],\n                        [-7.2822e-03,  3.7894e-02,  7.4916e-02],\n                        [-2.9759e-02,  4.2702e-02,  3.6531e-02]],\n              \n                       ...,\n              \n                       [[ 4.5360e-03, -1.0456e-02, -1.6534e-02],\n                        [-1.6209e-02, -9.6991e-03, -6.4648e-03],\n                        [ 1.3367e-02,  9.7034e-03,  1.0244e-02]],\n              \n                       [[ 3.0055e-02, -5.2668e-02,  7.5239e-03],\n                        [-5.8801e-03, -9.9698e-02,  6.8496e-03],\n                        [ 9.9607e-03, -2.6634e-02, -1.8909e-02]],\n              \n                       [[-4.3979e-02, -4.8898e-03,  9.3230e-03],\n                        [-4.3688e-02,  2.2788e-03, -4.8801e-02],\n                        [-2.1692e-02,  1.2632e-02, -1.0436e-02]]],\n              \n              \n                      [[[-2.9181e-02,  2.8140e-02,  8.5484e-03],\n                        [ 2.3086e-02,  4.0503e-03, -4.7424e-03],\n                        [-1.2256e-02, -1.6642e-02, -8.4309e-03]],\n              \n                       [[ 4.8100e-02, -2.7965e-02,  5.2080e-02],\n                        [-3.5124e-02, -7.4593e-02, -6.9843e-03],\n                        [ 1.0191e-02,  5.3191e-02,  1.5065e-02]],\n              \n                       [[-2.4772e-02,  1.2157e-02, -9.1935e-03],\n                        [-2.7732e-02,  3.3197e-02,  3.2929e-02],\n                        [-3.0214e-02,  5.6448e-02,  7.6554e-02]],\n              \n                       ...,\n              \n                       [[-1.0628e-02, -2.8308e-03, -1.2156e-02],\n                        [-5.2355e-03, -1.0563e-02, -1.4404e-02],\n                        [ 1.4102e-02,  2.6884e-03,  1.3855e-02]],\n              \n                       [[ 2.2316e-02, -2.6663e-02, -1.3098e-02],\n                        [ 2.4123e-03, -4.8099e-03,  3.1881e-02],\n                        [ 1.3338e-03, -1.3207e-02, -3.4821e-02]],\n              \n                       [[-3.5349e-02, -2.8991e-02, -4.6967e-02],\n                        [ 1.5775e-03,  1.5867e-02,  3.3464e-02],\n                        [-1.6207e-02,  4.8190e-02,  7.1273e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-3.4567e-02, -5.9790e-02, -4.4781e-02],\n                        [ 4.0921e-03,  1.4835e-02,  5.5226e-02],\n                        [-6.5791e-03,  2.3231e-03,  1.0126e-02]],\n              \n                       [[ 3.6538e-02,  3.7869e-02,  5.8395e-03],\n                        [-2.7710e-03,  9.9542e-03,  4.9271e-03],\n                        [ 8.6258e-02,  2.0145e-02,  2.7042e-02]],\n              \n                       [[-7.0696e-02, -1.4437e-02,  1.0114e-02],\n                        [-1.6771e-02,  1.6810e-02,  1.2421e-05],\n                        [-1.0842e-02, -2.3700e-02,  4.8324e-03]],\n              \n                       ...,\n              \n                       [[ 1.3026e-02,  4.9601e-03,  2.3477e-03],\n                        [ 5.3929e-03, -1.4038e-02, -1.8738e-02],\n                        [-3.1462e-03, -5.9858e-03,  4.8519e-04]],\n              \n                       [[-1.4591e-02,  1.3959e-02,  1.0364e-02],\n                        [-2.9933e-03,  7.9409e-03,  7.7190e-03],\n                        [-2.2363e-02, -1.7520e-02,  4.3059e-02]],\n              \n                       [[-1.0610e-02,  1.0154e-01,  6.6651e-02],\n                        [ 4.3443e-02,  1.7243e-02,  4.1126e-02],\n                        [ 6.1977e-02, -1.4455e-02,  1.8960e-02]]],\n              \n              \n                      [[[-2.0004e-02, -5.5264e-02, -1.3172e-02],\n                        [ 8.6095e-03, -3.5577e-02, -7.0178e-02],\n                        [-2.5239e-03,  6.4557e-02,  1.7095e-02]],\n              \n                       [[-5.1134e-02,  1.0713e-01, -6.0539e-02],\n                        [-8.4348e-03,  8.4549e-02,  2.7564e-02],\n                        [ 3.6788e-03, -3.7028e-02, -1.1086e-02]],\n              \n                       [[-1.3422e-02,  2.9258e-02,  7.8333e-03],\n                        [ 1.3726e-03,  3.7408e-03, -1.1167e-02],\n                        [ 2.8762e-04, -2.3810e-02,  4.7684e-02]],\n              \n                       ...,\n              \n                       [[-1.5273e-02, -2.2236e-02, -1.2039e-02],\n                        [ 2.6737e-02,  3.0896e-02,  4.3454e-03],\n                        [-1.3674e-02, -1.4807e-02,  3.9976e-03]],\n              \n                       [[-1.8016e-02,  2.4300e-02,  1.7545e-02],\n                        [ 1.3366e-02, -2.5081e-02,  3.2097e-03],\n                        [ 1.0455e-02,  8.5299e-03,  1.6866e-02]],\n              \n                       [[ 2.0472e-02,  1.1670e-01,  1.4779e-02],\n                        [ 3.5410e-04, -1.2710e-02,  5.2036e-02],\n                        [-3.2409e-02, -4.8351e-03, -1.2472e-02]]],\n              \n              \n                      [[[-2.0189e-02,  5.5396e-03, -1.5447e-02],\n                        [ 6.6999e-03,  1.2074e-03,  3.6471e-02],\n                        [ 1.9133e-02, -5.8943e-03,  4.2941e-02]],\n              \n                       [[-1.9236e-02, -1.9929e-02, -2.8338e-02],\n                        [ 9.0019e-03, -7.8500e-02, -2.1474e-02],\n                        [ 3.5718e-02, -2.8299e-03,  2.9863e-03]],\n              \n                       [[-2.2864e-02,  2.5614e-03, -1.1616e-02],\n                        [ 7.5001e-02, -8.6690e-03, -5.7975e-03],\n                        [ 1.3036e-02, -1.2662e-02,  3.3302e-03]],\n              \n                       ...,\n              \n                       [[-9.1956e-03, -1.3141e-03,  2.3808e-03],\n                        [ 5.1439e-03,  1.2185e-02,  1.3296e-02],\n                        [-7.6890e-03, -1.3789e-02, -1.2455e-02]],\n              \n                       [[-1.6207e-02,  3.4901e-02,  2.1012e-03],\n                        [ 7.9708e-03,  4.4545e-03, -6.2906e-04],\n                        [ 2.6397e-02, -3.4728e-02,  2.5756e-02]],\n              \n                       [[-4.2528e-02, -5.3167e-02,  6.6018e-02],\n                        [ 6.0819e-02,  4.5370e-02,  1.0569e-02],\n                        [ 2.0552e-02, -1.3681e-03,  1.5437e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv0.norm.weight',\n              tensor([0.7513, 0.6959, 1.0421, 0.8645, 1.6443, 1.0357, 0.7734, 1.0374, 1.1222,\n                      1.0699, 0.5284, 2.1367, 1.8206, 0.4953, 1.0315, 1.0741, 0.5063, 0.4559,\n                      0.6723, 0.4769, 0.9597, 1.4662, 1.7302, 1.2514, 0.8113, 0.4330, 2.2527,\n                      1.8721, 1.1480, 0.9534, 0.5750, 1.6038, 1.1683, 1.5115, 0.8781, 0.4082,\n                      1.0166, 0.9407, 1.3642, 1.6004, 1.2330, 2.0577, 0.7621, 1.0416, 0.8393,\n                      0.8519, 0.9332, 0.7204, 0.7239, 0.7532, 0.4919, 1.3182, 3.3593, 2.5510,\n                      0.5577, 0.8376, 0.9313, 0.7424, 0.7879, 0.8408, 1.0799, 0.6379, 0.5244,\n                      1.4737, 0.7278, 0.6261, 0.8387, 0.7754, 0.6795, 1.0289, 0.8041, 0.5801,\n                      1.2319, 1.3455, 1.2947, 0.4194, 0.5633, 0.8530, 1.0151, 1.3196, 0.6947,\n                      1.0440, 0.6455, 0.9698, 2.5837, 0.5846, 1.1399, 0.5178, 0.5530, 1.3469,\n                      1.3782, 0.4280, 0.6347, 0.4094, 0.7501, 0.7432, 0.7548, 2.7882, 1.0855,\n                      0.5875, 0.8272, 1.5668, 1.3443, 0.5149, 1.1081, 1.0311, 1.2089, 1.7452,\n                      1.0208, 0.4960, 0.8754, 1.1944, 0.6119, 1.1046, 0.9594, 0.1905, 0.5273,\n                      1.0246, 2.1479, 0.5892, 0.3953, 0.7257, 0.7580, 0.9585, 0.5905, 1.4181,\n                      0.7968, 1.1023, 0.5324, 0.6413, 0.9919, 0.5126, 0.3544, 0.8115, 1.2830,\n                      0.8373, 1.1749, 0.4806, 0.4433, 0.9402, 0.7424, 0.5224, 0.7146, 1.8679,\n                      1.0063, 1.7868, 2.5790, 1.3572, 1.1656, 1.0430, 0.2817, 0.7231, 0.8209,\n                      0.5926, 0.8093, 0.8007, 0.4240, 1.7533, 1.7454, 0.8323, 0.6753, 0.8684,\n                      1.5356, 1.0619, 1.1422, 1.0455, 0.5437, 0.4801, 0.6400, 1.1422, 0.8391,\n                      0.3780, 0.6982, 1.2235, 0.6013, 0.4976, 1.0439, 1.4277, 0.6080, 1.2235,\n                      1.3919, 1.3342, 1.1808, 1.3833, 1.2474, 1.7516, 0.5769, 0.5518, 0.4555,\n                      1.0821, 0.3338, 1.1121, 1.2893, 0.9634, 0.6752, 0.7986, 1.1893, 1.2320,\n                      1.1521, 0.9670, 1.1809, 1.0847, 0.7978, 0.7826, 0.7926, 1.2058, 1.1724,\n                      0.4464, 1.0989, 0.6971, 0.4253, 1.1154, 0.7978, 0.8538, 0.4798, 0.8425,\n                      0.8431, 0.6186, 1.2950, 0.6809, 0.8845, 0.3584, 0.6616, 0.6283, 1.1233,\n                      1.2243, 2.2339, 0.4533, 0.9151, 0.9919, 0.7962, 1.0030, 1.9415, 1.0462,\n                      3.0586, 0.4903, 0.6311, 0.9922, 1.0058, 1.0182, 1.1406, 0.5770, 0.8754,\n                      0.5161, 0.9924, 1.0529, 1.1241, 1.1589, 0.5563, 0.7089, 1.2692, 1.2938,\n                      0.8565, 1.1841, 1.3630, 1.0468], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv0.norm.bias',\n              tensor([ 0.1069,  0.0751,  0.3686,  0.1289,  0.7420,  0.3777, -0.0851,  0.3557,\n                       0.4067,  0.4935,  0.0246,  0.7302,  0.8630,  0.1021,  0.3987,  0.1998,\n                       0.0241, -0.6250, -0.1013, -0.1192,  0.6612,  0.7371,  0.6683,  0.2868,\n                       0.2530,  0.2164,  0.7261,  0.8738,  0.3373,  0.1669, -0.0954,  0.7075,\n                      -0.4287,  0.4500,  0.0618,  0.1690,  0.2390,  0.2105,  0.7484,  0.6628,\n                       0.4104,  0.1605, -0.2675,  0.3258, -0.2311,  0.0436,  0.2839, -0.1575,\n                       0.0206, -0.3284, -0.6652,  0.5515,  0.6328,  1.1701,  0.0653,  0.3246,\n                       0.2163,  0.2210, -0.3170,  0.0654,  0.1179,  0.2063, -0.3707,  0.6766,\n                      -0.3010,  0.0621,  0.1197, -0.0620,  0.0353,  0.3045,  0.2409, -0.2750,\n                       0.4830,  0.3981,  0.6653, -0.7976, -0.1799,  0.0178, -0.3497,  0.6333,\n                      -0.2910,  0.3043, -0.4969,  0.0974,  0.7819, -0.0309,  0.6672, -0.3127,\n                      -0.2281,  0.4878,  0.4544,  0.1474, -0.0921, -0.2095,  0.0565,  0.2014,\n                       0.0773,  1.0516,  0.3245, -0.3062, -0.0068,  0.5440,  0.5551, -0.4134,\n                       0.4512,  0.0625,  0.3081,  0.7633,  0.2573, -0.1676, -0.1003,  0.5967,\n                      -0.0755,  0.4937,  0.2143,  0.9569, -0.2183,  0.0582,  0.9205, -0.2456,\n                      -0.2790, -0.3304,  0.2437,  0.3878, -0.0416,  0.4830,  0.2121,  0.1771,\n                       0.3813, -0.4937,  0.0875, -0.7143, -0.6361,  0.2181,  0.5428,  0.3140,\n                       0.4377,  0.0110, -0.2413,  0.4453,  0.4664, -0.4752, -0.0345,  0.5229,\n                       0.1984,  0.8354,  1.3257,  0.4874,  0.2667,  0.4864, -0.5656, -0.1907,\n                       0.4985, -0.2363,  0.1483, -0.1999, -0.7360,  0.8284,  0.6966,  0.7192,\n                       0.1467,  0.1407,  0.6554,  0.3512,  0.0720,  0.2066, -0.9652,  0.0319,\n                      -0.0603,  0.3142,  0.2559, -0.0605, -0.6271, -0.4990, -0.0840, -0.5090,\n                       0.6317, -0.0424, -0.4097,  0.3377,  0.6030,  0.4328,  0.2988,  0.5913,\n                       0.3657, -0.1700, -0.6325,  0.0914, -0.2576,  0.2275, -0.2896,  0.8149,\n                       0.4659,  0.3158,  0.2561,  0.3655,  0.4424,  0.4749,  0.3963,  0.6200,\n                       0.4835,  0.2320, -0.1365,  0.1291,  0.1664,  0.4330,  0.3672, -0.2275,\n                       0.2195, -0.3340, -0.0368,  0.3000,  0.6083,  0.1723, -0.0880,  0.1764,\n                       0.3517,  0.0101,  0.5114,  0.1871,  0.1272, -0.3537, -0.5600, -0.1302,\n                       0.4362,  0.4895,  0.8819, -0.8084,  0.3141,  0.0054, -0.4514,  0.1316,\n                       0.5930, -0.2563,  1.5488, -0.3192, -0.5738,  0.1417,  0.4253,  0.2229,\n                       0.3933, -0.6861,  0.1720, -0.2743,  0.5764,  0.1642,  0.4502,  0.1737,\n                      -0.2689,  0.1289,  0.6452,  0.2317, -0.3716,  0.2513,  0.4530,  0.2326],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv0.layer.weight',\n              tensor([[[[ 8.3708e-03,  5.2836e-02,  5.8203e-02],\n                        [ 1.5749e-03,  2.4400e-02, -5.8394e-03],\n                        [-2.3719e-02, -4.2933e-02, -3.5814e-02]],\n              \n                       [[ 1.1614e-02,  5.4314e-02,  1.8356e-02],\n                        [ 3.1258e-03,  1.3420e-01, -3.5816e-02],\n                        [ 1.8228e-02,  6.2638e-02,  3.0372e-03]],\n              \n                       [[ 2.0003e-02, -1.3261e-02, -1.4655e-02],\n                        [ 2.3639e-02,  5.2051e-03,  4.8096e-02],\n                        [ 1.4287e-02,  3.4427e-03,  3.3757e-02]],\n              \n                       ...,\n              \n                       [[-5.4480e-02, -4.9110e-02, -1.3775e-02],\n                        [-2.5965e-02, -6.8677e-02, -2.5094e-02],\n                        [ 7.1773e-03, -8.0078e-03,  1.8946e-03]],\n              \n                       [[ 9.3608e-03,  6.3153e-04,  4.2234e-03],\n                        [ 5.3109e-02,  6.0689e-02,  3.4125e-02],\n                        [ 2.2425e-03, -7.7610e-02,  2.9027e-02]],\n              \n                       [[-5.3729e-02, -7.8423e-03,  9.7757e-04],\n                        [-1.4493e-02, -7.1962e-04, -2.2189e-02],\n                        [ 5.3202e-03, -5.8629e-03,  3.1929e-03]]],\n              \n              \n                      [[[-3.2538e-03,  1.5157e-02,  4.5038e-02],\n                        [ 2.9284e-02,  6.8263e-02,  2.6252e-02],\n                        [-2.3071e-02, -1.7559e-02,  2.1132e-02]],\n              \n                       [[-3.9408e-02,  4.7779e-02,  2.2569e-02],\n                        [ 8.6593e-03,  8.8374e-02,  7.2478e-03],\n                        [ 4.2282e-02,  5.4194e-02,  3.5262e-02]],\n              \n                       [[ 2.8490e-02,  7.6160e-03,  6.2847e-03],\n                        [ 6.2938e-02,  2.4006e-02,  1.6943e-02],\n                        [-6.7802e-02, -5.0947e-02, -3.0990e-02]],\n              \n                       ...,\n              \n                       [[ 6.4292e-02, -9.5720e-03,  1.3859e-02],\n                        [ 8.1720e-03, -9.1893e-03,  6.0243e-02],\n                        [-2.3959e-02, -1.3030e-02,  3.3371e-02]],\n              \n                       [[-6.9880e-03, -2.2001e-02, -3.0052e-02],\n                        [ 1.5747e-02, -3.8983e-02,  3.6236e-02],\n                        [-7.9237e-02, -5.2585e-02, -4.9812e-02]],\n              \n                       [[-3.5257e-02, -4.4969e-03, -1.2909e-02],\n                        [-5.5078e-02,  6.7889e-02, -1.6656e-02],\n                        [-2.7556e-03,  3.8470e-02, -3.5163e-02]]],\n              \n              \n                      [[[-4.0880e-02,  1.0030e-02,  1.1174e-02],\n                        [-2.2260e-02,  3.5016e-02,  6.4823e-03],\n                        [-2.1473e-02,  4.0426e-02,  3.5445e-02]],\n              \n                       [[ 2.1443e-02, -4.9850e-02,  4.8503e-02],\n                        [-3.4852e-02, -8.8302e-02,  5.3681e-02],\n                        [ 1.2783e-02,  6.8344e-02,  1.7724e-02]],\n              \n                       [[ 1.2882e-02,  5.1401e-02, -6.6510e-02],\n                        [-6.3119e-02, -3.4751e-02, -2.1622e-02],\n                        [-2.4898e-02, -5.1024e-02, -2.0333e-02]],\n              \n                       ...,\n              \n                       [[-5.3561e-02, -7.8956e-02, -1.1435e-01],\n                        [ 1.1206e-02, -1.6004e-02, -3.9848e-02],\n                        [-1.0174e-02, -6.6184e-02, -3.6440e-02]],\n              \n                       [[-3.8432e-04,  3.3388e-02, -2.0050e-02],\n                        [-2.9656e-02, -9.1699e-03,  1.5353e-02],\n                        [ 2.6593e-02, -1.5389e-02,  4.3555e-03]],\n              \n                       [[ 9.9595e-02, -6.1935e-03, -5.2919e-02],\n                        [ 1.8159e-02, -8.8811e-02, -9.6293e-02],\n                        [ 2.5198e-02,  5.4467e-02,  2.6854e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 2.7526e-02,  6.2815e-02,  3.6516e-02],\n                        [ 6.2356e-02,  2.9272e-02,  1.0794e-02],\n                        [-2.9173e-02, -8.8487e-03,  3.4593e-02]],\n              \n                       [[-6.4634e-02, -5.8697e-02, -2.4572e-02],\n                        [-5.4356e-02, -8.4788e-02, -1.2196e-02],\n                        [ 9.7606e-04, -8.1397e-02, -6.3952e-02]],\n              \n                       [[-8.2403e-02, -2.1654e-02,  9.4330e-03],\n                        [-7.8625e-02, -3.2569e-02, -1.5005e-02],\n                        [-1.0896e-02,  7.2356e-04, -3.1593e-02]],\n              \n                       ...,\n              \n                       [[-3.5483e-02, -7.9513e-02, -2.4993e-02],\n                        [-3.0131e-02, -5.8415e-02,  6.4158e-02],\n                        [ 6.4160e-02,  1.6810e-02, -1.4760e-03]],\n              \n                       [[-2.6504e-02, -8.8108e-02,  4.6741e-02],\n                        [ 3.1624e-02,  1.1092e-01,  1.8599e-02],\n                        [ 5.5746e-02, -1.6504e-03, -2.9063e-02]],\n              \n                       [[-4.6555e-02,  8.0756e-03,  1.2579e-02],\n                        [-3.4571e-02,  2.1302e-02,  3.6250e-03],\n                        [ 7.6295e-02,  9.8786e-03, -1.4174e-02]]],\n              \n              \n                      [[[-3.8537e-02,  5.1969e-02,  2.6418e-02],\n                        [ 1.5712e-02,  1.7140e-01,  3.8939e-02],\n                        [ 7.9008e-03,  9.3832e-02, -1.0696e-02]],\n              \n                       [[-1.1938e-02,  7.1763e-02, -5.5417e-02],\n                        [-1.0691e-02, -4.1856e-02, -7.1479e-02],\n                        [ 2.3848e-02, -7.4639e-04, -4.0570e-03]],\n              \n                       [[-3.6541e-02,  4.7951e-02, -2.8264e-02],\n                        [ 1.9842e-03, -1.1279e-01, -4.6982e-02],\n                        [-1.5942e-02,  8.1809e-02, -4.5120e-02]],\n              \n                       ...,\n              \n                       [[-2.6534e-02, -5.7817e-02, -7.0375e-02],\n                        [ 5.2824e-03,  2.0778e-02,  1.1581e-02],\n                        [ 1.9766e-02,  2.9606e-02, -1.5376e-02]],\n              \n                       [[ 1.6380e-04, -2.2149e-02,  1.2951e-02],\n                        [ 7.6982e-03, -3.2372e-02,  1.2841e-02],\n                        [-2.9426e-03,  5.9057e-02,  1.2743e-02]],\n              \n                       [[-1.4319e-02,  1.1044e-02,  5.7370e-02],\n                        [-1.6351e-02,  7.2609e-02, -2.0872e-02],\n                        [-1.8943e-02,  3.4771e-02, -5.4290e-02]]],\n              \n              \n                      [[[ 5.4050e-02,  6.3589e-02,  6.0744e-02],\n                        [ 5.5649e-03, -1.4266e-02,  4.0424e-02],\n                        [-5.2990e-04, -4.6470e-02, -1.0440e-02]],\n              \n                       [[ 1.3224e-02, -3.7785e-02, -8.3722e-04],\n                        [ 6.2606e-02,  2.9415e-02,  1.0273e-01],\n                        [ 4.0853e-03, -6.8253e-02, -3.4543e-03]],\n              \n                       [[-5.0786e-02, -3.9337e-02, -9.4685e-02],\n                        [ 5.4510e-02,  3.4241e-02, -6.6234e-02],\n                        [ 2.2720e-02,  3.6404e-02, -7.1122e-02]],\n              \n                       ...,\n              \n                       [[ 3.1033e-02,  2.0203e-02, -1.8717e-02],\n                        [ 1.1004e-01, -3.6173e-02, -9.0069e-02],\n                        [ 4.1337e-03,  5.9680e-02,  7.3671e-02]],\n              \n                       [[ 1.9636e-02,  2.3732e-02,  1.9650e-02],\n                        [-2.9795e-02, -3.0444e-02, -3.4332e-02],\n                        [ 4.3888e-03, -2.8398e-03, -2.0255e-02]],\n              \n                       [[ 3.0370e-02, -2.8578e-02, -3.2539e-02],\n                        [-3.6857e-02, -3.7234e-03,  6.5091e-02],\n                        [ 4.7717e-03, -4.4738e-02, -1.2756e-03]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv1.norm.weight',\n              tensor([1.7384, 1.5949, 3.9017, 3.0243, 2.4865, 3.0643, 1.2442, 1.3417, 1.3362,\n                      1.6526, 5.6678, 1.3936, 1.2557, 2.7394, 1.2732, 1.1535, 1.4071, 1.0216,\n                      1.3658, 1.5750, 1.5510, 1.4316, 1.9673, 1.1742, 1.8410, 1.3214, 1.1398,\n                      3.1571, 1.5914, 1.9658, 1.5782, 1.5244, 1.3025, 1.4392, 1.8431, 1.0854,\n                      1.4276, 2.0947, 0.8184, 2.8644, 1.3520, 1.2246, 1.8327, 1.6172, 1.6251,\n                      3.1858, 2.3808, 4.4237, 1.0530, 1.9014, 4.0642, 3.1218, 1.2837, 1.0808,\n                      2.1576, 1.0249, 2.0284, 1.3995, 1.5322, 2.6857, 3.7695, 1.2444, 1.7472,\n                      3.3451, 2.8132, 1.5378, 4.2377, 1.9223, 2.0626, 2.6081, 1.6965, 1.4512,\n                      1.9057, 1.9984, 1.0357, 1.9773, 1.6444, 1.4616, 1.2846, 2.2407, 3.1772,\n                      1.8516, 1.0955, 2.5556, 0.9676, 1.5050, 4.9700, 1.3041, 1.3936, 1.9022,\n                      1.4536, 1.0972, 2.6055, 1.8752, 5.7708, 1.5744, 3.4435, 1.5575, 1.6191,\n                      2.1791, 1.9519, 1.6453, 1.3562, 2.9885, 3.0298, 1.5244, 1.1351, 1.1840,\n                      2.8099, 1.4869, 1.1285, 2.2789, 3.2147, 1.7331, 2.4304, 1.3551, 3.6746,\n                      2.3213, 1.4764, 4.0534, 1.2260, 2.8865, 1.5418, 1.2126, 3.9384, 1.3003,\n                      1.1768, 1.2755, 3.6108, 1.6946, 2.0545, 1.7526, 2.6050, 1.5488, 2.0536,\n                      1.5111, 2.3892, 2.8900, 1.9025, 1.6724, 2.0458, 2.5588, 1.4707, 1.3102,\n                      1.4835, 1.1386, 1.3965, 1.3562, 4.9795, 1.9173, 1.4060, 2.6651, 1.1439,\n                      2.0707, 4.1846, 4.5625, 1.8760, 2.1381, 4.2636, 1.8665, 2.6131, 1.4495,\n                      1.9173, 2.7121, 1.2054, 1.2868, 2.1783, 1.0631, 1.4393, 0.9527, 1.7938,\n                      1.7528, 1.2059, 3.0743, 1.5346, 2.1762, 1.3748, 2.4389, 1.6125, 1.4898,\n                      1.5780, 1.2920, 2.2216, 1.2774, 2.5838, 1.5708, 1.3080, 1.0844, 2.0087,\n                      1.7420, 1.1675, 0.9778, 2.7982, 1.3045, 1.4204, 1.0054, 1.8988, 1.4460,\n                      1.4532, 3.1549, 2.6361, 1.1024, 1.7630, 1.5837, 1.3144, 3.0950, 2.0180,\n                      1.9919, 1.6746, 1.4868, 1.9130, 4.5587, 1.3261, 1.2450, 1.7945, 1.5665,\n                      1.3552, 1.5056, 1.6668, 1.6123, 1.4875, 2.6315, 1.2324, 1.0920, 1.2833,\n                      3.0152, 2.3260, 1.6291, 2.7769, 3.8219, 2.0571, 1.9444, 2.6496, 1.3229,\n                      3.8793, 1.0832, 1.3548, 1.6682, 1.9246, 1.6805, 1.9651, 2.3130, 1.5844,\n                      1.5610, 2.9322, 2.9910, 1.2816, 3.2845, 1.2878, 2.3737, 1.3981, 1.2142,\n                      1.7749, 1.7208, 2.7559, 1.4326], device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv1.norm.bias',\n              tensor([ 0.3739,  0.1125, -0.4915,  1.0718,  0.3042,  0.7189, -0.0207, -0.2114,\n                      -0.1273,  0.2076,  1.6654, -0.0302, -0.0050,  0.8172, -0.1558, -0.7189,\n                       0.0584,  0.0892, -0.0220,  0.1129, -0.0936, -0.0648,  0.3219, -0.9422,\n                       0.5069, -0.3327, -0.6820,  0.9794,  0.2296,  0.4107,  0.6212,  0.3283,\n                      -0.0108, -0.0116,  0.3201, -0.4753,  0.0135,  0.2620, -0.9756,  0.8322,\n                      -0.5086,  0.0752,  0.4088,  0.2396,  0.3631,  1.0634,  0.6256,  1.5414,\n                      -0.5266,  0.3593,  1.0620,  0.6593, -2.1164, -0.9170,  0.5865, -0.0997,\n                       0.4008, -1.6126,  0.3330,  0.8561,  1.0568, -0.1958, -0.0167,  0.9125,\n                       0.9192,  0.0670,  1.5481,  0.2711,  0.6014,  0.4517,  0.0503,  0.0325,\n                       0.4495,  0.1752,  0.0383,  0.5237,  0.2657, -1.0570,  0.1517,  0.5650,\n                       0.8883,  0.3412, -0.1655,  0.9490, -0.7977,  0.2415,  1.4113, -0.4052,\n                      -0.1461,  1.1650,  0.0548, -0.5368,  0.6298,  0.3894,  1.5139,  0.2346,\n                       1.0456,  0.1617,  0.0979,  0.5825,  0.4406,  0.4638, -0.3187,  0.8432,\n                       0.9231,  0.1009, -0.4169, -0.1162,  0.8940,  0.2413, -0.2691,  0.6660,\n                       1.0356,  0.3973,  0.7121,  0.0979,  1.4226,  0.9406, -0.1633,  1.1120,\n                      -0.2190,  0.9041,  0.2596,  0.4398,  1.1565, -0.0717, -0.7810,  0.0566,\n                       1.1039,  0.2719,  0.6311,  0.2765,  0.7785, -0.6221,  0.4918,  0.4364,\n                       0.6374,  0.9615,  0.4464,  0.3912,  0.6359,  0.5903,  0.2859, -0.0473,\n                       0.0883, -0.3320,  0.0327,  0.0660,  1.5396,  0.5342, -0.0456,  0.8477,\n                      -0.0753,  0.5753,  1.2108,  1.3125,  0.2604,  0.5911,  1.3170,  0.2289,\n                       0.8045,  0.0175,  0.5340,  0.3050, -0.2477, -0.4291,  0.6180, -0.3744,\n                      -0.1884, -0.5699,  0.0600,  0.2882, -0.4843,  0.9358,  0.0916,  0.5028,\n                       0.3630,  0.4706,  0.1404,  0.1188, -0.0069, -0.0083,  0.4855,  0.0208,\n                       0.5486,  0.2903,  0.3512, -0.6503,  0.2842,  0.3924, -0.4877, -1.4659,\n                       0.6966,  0.4898,  0.1528, -1.1884,  0.2569,  0.4771,  0.4873,  1.0183,\n                       0.6301, -0.6078,  0.5935,  0.0588,  0.2597,  1.0300,  0.4051,  0.5115,\n                       0.0678,  0.2527,  0.4912,  1.4947,  0.0493, -0.2970,  0.5070,  0.3336,\n                      -0.2890,  0.1560,  0.1257,  0.1246,  0.1370,  0.7733, -0.2759, -1.3956,\n                       0.2093,  0.6388,  0.7828,  0.3218,  0.8712,  1.0926,  0.4463,  0.2861,\n                       0.9609, -0.2193,  1.2466, -0.0872, -0.1128,  0.5683,  0.2711,  0.3597,\n                       0.5356,  0.5264,  0.2948,  0.9543,  0.7891,  1.0820, -0.0748,  0.8110,\n                      -0.0292,  0.4651,  0.2709, -1.2121,  0.2715,  0.2956, -0.1236,  0.5884],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.1.blocks.1.conv1.layer.weight',\n              tensor([[[[-2.0942e-02,  6.8128e-03, -1.6143e-02],\n                        [-5.4224e-03, -1.0644e-01, -9.7881e-02],\n                        [ 1.1441e-01,  5.3871e-02,  6.2778e-02]],\n              \n                       [[ 2.0225e-02, -2.0930e-02, -4.1361e-02],\n                        [ 2.4633e-02,  2.1282e-02,  2.3586e-03],\n                        [ 2.8164e-02,  3.2182e-02,  3.0186e-02]],\n              \n                       [[ 5.1867e-02,  2.3646e-02,  1.6160e-02],\n                        [ 4.0092e-02, -8.0873e-03,  1.8282e-03],\n                        [ 1.0622e-02, -4.9951e-03,  2.3835e-02]],\n              \n                       ...,\n              \n                       [[ 2.9013e-02,  2.1125e-02,  2.8850e-02],\n                        [ 2.0023e-02, -4.2326e-02, -1.3789e-03],\n                        [ 5.3363e-02,  2.5249e-02, -5.8083e-02]],\n              \n                       [[-8.1612e-03,  1.3641e-02, -1.7217e-02],\n                        [ 2.4895e-03, -7.7540e-02, -4.6154e-02],\n                        [ 3.1507e-02, -4.5505e-02, -5.9310e-02]],\n              \n                       [[ 1.9567e-03, -3.9958e-03, -4.6948e-03],\n                        [-7.8476e-02,  3.0670e-04, -3.5081e-03],\n                        [ 2.7861e-02,  4.4411e-02, -4.7150e-02]]],\n              \n              \n                      [[[ 1.7044e-02,  3.8323e-02,  1.1726e-02],\n                        [-8.3854e-02, -6.8918e-03,  1.6658e-02],\n                        [-3.9246e-02, -4.7881e-02,  7.5784e-02]],\n              \n                       [[ 3.4349e-03,  2.2591e-02,  3.8577e-02],\n                        [-2.6686e-03,  1.2452e-02,  2.0000e-02],\n                        [-1.2240e-03,  5.2449e-02,  9.6274e-03]],\n              \n                       [[ 5.4883e-02,  4.0387e-02,  4.8562e-02],\n                        [ 5.5825e-02,  3.7175e-02,  3.7396e-02],\n                        [ 3.5825e-02,  1.7315e-02,  4.2729e-02]],\n              \n                       ...,\n              \n                       [[ 3.0697e-02,  8.3355e-02,  2.1892e-02],\n                        [-3.3159e-02, -1.2959e-02, -1.0887e-02],\n                        [-1.0186e-01, -8.6175e-02, -5.3371e-02]],\n              \n                       [[-9.6772e-03,  2.7921e-02,  2.7307e-02],\n                        [ 1.8477e-03,  3.9144e-02,  2.4613e-02],\n                        [ 4.0752e-03,  2.9453e-02,  3.5958e-02]],\n              \n                       [[-3.1993e-02, -3.5685e-02,  4.0038e-03],\n                        [ 1.1207e-02, -6.0988e-02, -2.2362e-02],\n                        [ 1.0872e-01, -1.6082e-02,  7.0541e-03]]],\n              \n              \n                      [[[ 7.4831e-03,  1.0824e-01,  5.7597e-02],\n                        [ 1.9094e-02,  4.2247e-02,  1.6858e-02],\n                        [-6.4645e-02, -6.2002e-02, -1.4620e-01]],\n              \n                       [[-1.0050e-02,  5.5552e-02,  3.3663e-02],\n                        [-2.6596e-02,  4.2904e-02, -4.7263e-02],\n                        [ 2.8508e-02,  3.4649e-02, -8.8428e-03]],\n              \n                       [[ 5.1099e-02,  2.3780e-02,  2.0139e-02],\n                        [ 8.6548e-03,  3.8898e-02,  4.5625e-02],\n                        [ 1.9430e-02,  3.0749e-02,  3.2642e-02]],\n              \n                       ...,\n              \n                       [[-2.1073e-02,  8.5341e-02, -4.5076e-03],\n                        [ 9.1197e-03,  7.2356e-02,  7.9580e-03],\n                        [ 5.7433e-02,  6.1525e-02,  2.8734e-02]],\n              \n                       [[ 1.9224e-02,  2.1349e-02,  2.4139e-02],\n                        [ 1.2565e-04,  8.9327e-03,  2.0989e-02],\n                        [ 4.0214e-02,  8.4049e-02,  1.2201e-02]],\n              \n                       [[-8.0438e-02, -8.2511e-02,  2.1362e-02],\n                        [-4.6812e-02, -3.4605e-02,  3.9656e-02],\n                        [-2.9139e-02, -1.7027e-02,  5.4935e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-5.1675e-02, -2.0451e-02, -5.7919e-02],\n                        [-5.5135e-02, -7.9605e-02,  8.3411e-03],\n                        [-5.5917e-02, -5.2695e-03, -2.1989e-02]],\n              \n                       [[ 9.7222e-03,  7.1779e-02,  4.7658e-02],\n                        [-4.6411e-02,  6.4958e-03,  8.8722e-02],\n                        [-3.8342e-02,  1.3488e-02,  8.2441e-02]],\n              \n                       [[ 3.1758e-02,  3.3979e-02,  3.5623e-02],\n                        [-2.3349e-02,  6.4228e-03,  1.8399e-02],\n                        [ 1.9396e-02,  3.3679e-02,  1.8564e-02]],\n              \n                       ...,\n              \n                       [[ 1.3863e-02, -2.0445e-04,  2.8711e-02],\n                        [-2.5969e-02, -3.5782e-02,  2.8738e-02],\n                        [-5.4535e-02,  5.8667e-02,  1.1077e-02]],\n              \n                       [[ 2.1724e-02, -1.7921e-03,  3.9043e-02],\n                        [ 3.2302e-02,  1.1059e-02,  4.5047e-02],\n                        [ 3.0444e-02,  4.7810e-02,  4.6136e-02]],\n              \n                       [[ 2.1512e-02,  4.2505e-02,  4.8625e-02],\n                        [ 9.7712e-02,  8.3531e-02,  5.6736e-02],\n                        [ 3.5301e-02,  9.9376e-03, -5.1624e-02]]],\n              \n              \n                      [[[ 4.1787e-02,  1.7333e-02,  8.3353e-02],\n                        [-8.0452e-03,  1.3563e-01,  1.3219e-01],\n                        [ 1.9114e-02, -3.9916e-04,  5.9859e-02]],\n              \n                       [[-3.5995e-03,  2.8385e-02, -9.4653e-03],\n                        [-4.0818e-02, -8.4465e-03, -1.5075e-02],\n                        [-1.2075e-02, -7.5625e-02, -7.3192e-02]],\n              \n                       [[-3.4962e-03, -8.9742e-03,  2.8873e-03],\n                        [ 8.7702e-03,  1.6218e-02,  4.2061e-03],\n                        [ 4.7606e-02,  4.6440e-02, -2.5215e-03]],\n              \n                       ...,\n              \n                       [[-3.9270e-02, -9.4821e-03, -3.5116e-02],\n                        [-4.4947e-02, -1.6434e-02,  1.3298e-02],\n                        [-4.1582e-02, -1.3878e-02,  2.2542e-02]],\n              \n                       [[ 1.2605e-02, -2.8789e-03,  1.3708e-02],\n                        [ 4.2011e-02,  5.2319e-02,  2.2173e-02],\n                        [ 1.8698e-02,  3.8546e-02,  3.7520e-02]],\n              \n                       [[-1.7202e-02, -2.8681e-02, -4.4350e-02],\n                        [-3.0669e-02, -2.1346e-03, -2.7241e-03],\n                        [-4.4703e-02, -6.0087e-02, -5.2830e-02]]],\n              \n              \n                      [[[ 2.2093e-02, -2.5781e-03, -4.2517e-02],\n                        [-1.7525e-02, -2.5870e-02, -2.0487e-02],\n                        [-4.1640e-02, -8.4706e-02, -5.1386e-02]],\n              \n                       [[ 3.0642e-02,  6.3868e-03, -3.4023e-02],\n                        [ 2.6873e-02, -6.6607e-03,  3.7906e-02],\n                        [ 5.1085e-02, -2.2920e-02,  2.4468e-02]],\n              \n                       [[ 4.2641e-02,  7.8185e-02,  4.0993e-02],\n                        [ 1.7886e-02,  3.3843e-04,  6.5762e-02],\n                        [-6.8569e-02, -6.1880e-02, -3.8140e-04]],\n              \n                       ...,\n              \n                       [[ 4.0044e-02,  7.5865e-02,  5.3693e-02],\n                        [ 6.0047e-02, -3.3574e-02,  4.4757e-02],\n                        [ 2.8886e-02, -4.4176e-02,  1.0204e-01]],\n              \n                       [[ 4.2015e-02,  5.5561e-02,  3.7042e-02],\n                        [ 1.6162e-02,  3.4761e-02, -2.6696e-02],\n                        [-7.7602e-03, -4.2057e-03,  2.7879e-03]],\n              \n                       [[-3.0981e-04, -5.3800e-02, -3.8755e-03],\n                        [-5.1744e-02, -1.2202e-01, -5.3193e-02],\n                        [-1.8893e-02, -9.7623e-02, -8.7577e-02]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.firstconv.norm.weight',\n              tensor([0.8158, 0.7957, 0.7860, 0.9028, 0.8823, 1.3674, 0.8046, 0.8692, 0.9465,\n                      0.7926, 0.9951, 2.3662, 1.0537, 0.9768, 1.0121, 0.8062, 1.1868, 1.0677,\n                      0.7700, 1.0604, 0.7006, 0.8940, 0.6730, 1.0426, 1.2029, 0.7293, 2.3118,\n                      1.4839, 0.8781, 1.1754, 1.0961, 1.2757, 0.7034, 0.9353, 0.7783, 0.8299,\n                      0.7624, 0.9976, 0.5908, 1.0716, 1.0080, 1.1117, 1.0541, 0.7907, 0.6487,\n                      1.0129, 0.7346, 0.7335, 1.0423, 0.9866, 0.7608, 0.9324, 2.4033, 0.9352,\n                      0.9719, 0.9967, 1.4315, 0.8914, 0.7752, 0.7914, 1.2934, 1.0050, 0.9204,\n                      0.9214, 1.4693, 0.7638, 1.7016, 1.6449, 1.2546, 0.5935, 0.7679, 0.8286,\n                      0.9078, 1.3301, 0.8192, 0.7144, 0.6655, 0.6853, 1.4042, 1.0988, 0.8330,\n                      0.6403, 1.0192, 0.6148, 2.9623, 0.8771, 1.3868, 0.7809, 0.7385, 1.0466,\n                      1.1375, 0.6980, 0.7979, 0.9660, 0.8308, 1.2422, 0.8125, 1.4392, 0.9433,\n                      0.8167, 0.7744, 0.8248, 0.6998, 0.8460, 1.1541, 0.8516, 0.8924, 1.2166,\n                      0.8229, 0.7866, 0.8013, 0.7134, 0.8838, 1.1903, 0.8334, 0.8833, 1.3213,\n                      0.7231, 0.8319, 0.8411, 0.7926, 0.7465, 1.0755, 1.0789, 0.9259, 0.7156,\n                      0.6425, 0.6572, 1.0054, 1.0270, 0.8652, 0.8765, 0.8288, 0.6891, 0.7850,\n                      1.0900, 0.9675, 1.0886, 0.7960, 0.6964, 0.9849, 0.9545, 0.8640, 1.3245,\n                      0.8467, 0.7882, 1.7135, 0.7694, 1.1364, 0.8315, 0.6377, 0.6069, 0.7470,\n                      0.9060, 0.7175, 0.7144, 0.8396, 0.7676, 1.2009, 0.7358, 1.0056, 1.0058,\n                      0.6941, 0.7049, 0.8389, 0.6050, 0.9204, 1.4165, 0.9069, 1.2465, 1.0408,\n                      0.9880, 1.0544, 2.2330, 0.8059, 0.7372, 0.8874, 1.4770, 0.4961, 0.9380,\n                      0.8616, 0.7233, 1.2141, 0.6772, 0.6986, 1.3528, 1.0253, 0.7801, 0.6946,\n                      1.1151, 1.0207, 0.9141, 1.0763, 0.8030, 0.8732, 0.8202, 0.8882, 1.0777,\n                      0.6518, 0.8057, 0.6896, 0.8083, 0.6811, 0.9267, 1.0200, 1.3142, 0.8464,\n                      1.0620, 0.7925, 0.8647, 0.9148, 1.0842, 1.1612, 0.6989, 1.2385, 0.9893,\n                      1.0522, 0.9324, 0.8841, 0.8057, 0.7414, 1.0683, 0.8521, 0.8758, 1.0075,\n                      0.6252, 1.0208, 0.9249, 0.7269, 1.1821, 0.9965, 1.1815, 1.0032, 1.1398,\n                      1.7084, 0.7831, 1.1230, 0.8962, 0.8527, 0.7657, 1.3111, 0.9227, 1.4215,\n                      1.0398, 0.8977, 0.6735, 1.6581, 0.9140, 0.8710, 0.8235, 1.3157, 0.9375,\n                      1.1228, 0.8486, 0.9423, 0.8350], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.firstconv.norm.bias',\n              tensor([ 0.1097,  0.0313,  0.1596,  0.1883,  0.2783,  0.5600, -0.0506,  0.1268,\n                       0.3472,  0.1039,  0.2537,  1.1598,  0.3988,  0.0944,  0.3090,  0.1357,\n                       0.1554, -0.2739, -0.0893,  0.2493, -0.2578,  0.2254, -0.2385,  0.4715,\n                       0.4883, -0.4370,  1.1451,  0.7899,  0.2789,  0.3805,  0.2525,  0.7190,\n                       0.0189,  0.3559, -0.0477,  0.0392, -0.1085,  0.3714, -0.6567,  0.4016,\n                       0.1821,  0.3814,  0.0442,  0.2722, -0.6845,  0.2015, -0.0042, -0.3742,\n                       0.2117, -0.2425, -0.6389,  0.3023,  1.0396,  0.1217,  0.4201,  0.2595,\n                       0.7112,  0.1226, -0.3813,  0.0310,  0.4015,  0.4476, -0.1216,  0.1566,\n                       0.3560, -0.0992,  0.4830,  0.5716,  0.4057, -0.8732,  0.0444, -0.4204,\n                       0.1202,  0.6241, -0.1247, -0.9044, -0.2070, -0.3998,  0.3472,  0.5681,\n                      -0.0291, -0.3025, -0.0719, -0.3292,  1.5374,  0.1481,  0.5410, -0.1514,\n                       0.0392,  0.4616,  0.3914,  0.1323,  0.1285, -0.4236,  0.0801,  0.4963,\n                      -0.8740,  0.6470,  0.3170, -0.0397, -0.0549,  0.2079,  0.0361, -0.1003,\n                       0.3485,  0.1522,  0.2508,  0.4686,  0.0392, -0.0161, -0.0397, -0.4571,\n                       0.1497,  0.5880,  0.0073, -0.7040,  0.1590,  0.1496, -0.3223,  0.0204,\n                       0.2055, -0.2171,  0.3942,  0.2804, -0.0782, -0.0972, -0.2115, -0.1305,\n                       0.3897,  0.0035,  0.2402, -0.3681, -0.6973, -0.1956,  0.0334,  0.5096,\n                       0.2713,  0.1290, -0.2658,  0.1327,  0.3026, -0.2752,  0.0577,  0.6085,\n                       0.1703, -0.0786, -1.7113, -0.0263,  0.4300,  0.0774, -0.5964, -0.3469,\n                      -0.4012, -0.2639, -0.2026, -0.3598, -0.5341, -0.0030,  0.3438, -0.3034,\n                       0.2573,  0.3335, -0.4635,  0.0910,  0.0764, -0.5510, -0.7334,  0.4299,\n                       0.1439,  0.4001,  0.4208, -0.2543, -0.1000,  0.4504, -0.0907, -0.5849,\n                      -0.0108,  0.4753, -0.9626,  0.2650,  0.0990, -0.0890,  0.4731, -0.0730,\n                       0.0247, -0.0847, -0.2318,  0.1591, -0.2026,  0.5031, -0.0494,  0.3027,\n                       0.3706, -0.1491,  0.3167,  0.1924,  0.2180,  0.5535, -0.0472,  0.0690,\n                       0.2146,  0.0759, -0.5251,  0.2097,  0.2726,  0.5175,  0.2784,  0.0658,\n                       0.0774, -0.1802,  0.1805,  0.4058,  0.7444, -0.7206,  0.1682,  0.3633,\n                       0.5140,  0.1963,  0.2691, -0.0130, -0.2234, -0.1890, -0.1675, -0.0378,\n                       0.4060, -1.3057,  0.3311, -0.4907, -0.4189,  0.3728,  0.0028,  0.4109,\n                       0.4135,  0.1670,  1.0342, -0.1761, -0.2078,  0.1465,  0.2219, -0.4157,\n                       0.5993, -0.3208,  0.4677, -0.1060,  0.4330, -0.4151,  0.9146,  0.1049,\n                      -0.0251, -0.2337,  0.1809,  0.2297,  0.0972,  0.2523,  0.2313,  0.1159],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.firstconv.layer.weight',\n              tensor([[[[ 0.0138, -0.0060,  0.0052],\n                        [ 0.0027,  0.0104,  0.0139],\n                        [ 0.0148, -0.0107, -0.0176]],\n              \n                       [[ 0.0130, -0.0034, -0.0079],\n                        [ 0.0066, -0.0151, -0.0159],\n                        [ 0.0011,  0.0050, -0.0164]],\n              \n                       [[ 0.0149,  0.0085,  0.0046],\n                        [-0.0059, -0.0029, -0.0017],\n                        [-0.0062,  0.0133,  0.0085]],\n              \n                       ...,\n              \n                       [[ 0.0216, -0.0161, -0.0050],\n                        [-0.0212, -0.0077,  0.0218],\n                        [ 0.0110,  0.0269,  0.0161]],\n              \n                       [[ 0.0188,  0.0164,  0.0051],\n                        [-0.0005,  0.0118, -0.0012],\n                        [ 0.0110,  0.0021,  0.0034]],\n              \n                       [[ 0.0027, -0.0112, -0.0159],\n                        [ 0.0040,  0.0221, -0.0025],\n                        [ 0.0053, -0.0132, -0.0133]]],\n              \n              \n                      [[[ 0.0503,  0.1155,  0.0510],\n                        [ 0.0133,  0.0682,  0.0603],\n                        [-0.0018, -0.0004,  0.0056]],\n              \n                       [[ 0.0640,  0.0195,  0.0449],\n                        [ 0.0243, -0.0041,  0.0510],\n                        [ 0.0329, -0.0443, -0.0430]],\n              \n                       [[-0.0177, -0.0009, -0.0217],\n                        [-0.0375, -0.0391, -0.0819],\n                        [-0.0072, -0.0295, -0.0209]],\n              \n                       ...,\n              \n                       [[ 0.0167, -0.0918, -0.1188],\n                        [ 0.0141, -0.0603, -0.0600],\n                        [-0.0038, -0.0435, -0.0490]],\n              \n                       [[-0.0531, -0.0526, -0.0024],\n                        [-0.0155, -0.0790, -0.0122],\n                        [-0.0012, -0.0401, -0.0294]],\n              \n                       [[ 0.0602, -0.0425, -0.0023],\n                        [ 0.0372,  0.0481,  0.0238],\n                        [-0.0292, -0.0114, -0.0151]]],\n              \n              \n                      [[[ 0.0266,  0.0558,  0.0374],\n                        [-0.0114,  0.0035, -0.0086],\n                        [ 0.0108,  0.0193,  0.0101]],\n              \n                       [[ 0.0224,  0.0185,  0.0364],\n                        [-0.0047,  0.0195,  0.0456],\n                        [ 0.0102,  0.0423,  0.0248]],\n              \n                       [[-0.0043, -0.0010, -0.0066],\n                        [ 0.0122,  0.0093, -0.0174],\n                        [ 0.0231,  0.0117,  0.0312]],\n              \n                       ...,\n              \n                       [[-0.0221, -0.0053,  0.0009],\n                        [ 0.0028,  0.0123, -0.0067],\n                        [-0.0096,  0.0414,  0.0003]],\n              \n                       [[-0.0269, -0.0091, -0.0215],\n                        [ 0.0044,  0.0142, -0.0033],\n                        [-0.0305, -0.0245, -0.0457]],\n              \n                       [[-0.0288, -0.0488, -0.0512],\n                        [-0.0018,  0.0103,  0.0168],\n                        [-0.0131, -0.0069, -0.0638]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0331, -0.0605, -0.0511],\n                        [-0.0217, -0.0788, -0.0717],\n                        [-0.0364, -0.0283, -0.0228]],\n              \n                       [[-0.0116,  0.0821,  0.0672],\n                        [-0.0420,  0.0146,  0.0250],\n                        [ 0.0053,  0.0172,  0.0627]],\n              \n                       [[-0.0536, -0.0694, -0.0991],\n                        [-0.0024, -0.0140, -0.0204],\n                        [ 0.0577,  0.0234,  0.0094]],\n              \n                       ...,\n              \n                       [[-0.0287, -0.0262, -0.0464],\n                        [-0.0239, -0.0679, -0.0773],\n                        [-0.0517, -0.0472, -0.0619]],\n              \n                       [[ 0.0290,  0.0377,  0.0188],\n                        [ 0.0029,  0.0421,  0.0361],\n                        [ 0.0067, -0.0015,  0.0389]],\n              \n                       [[-0.0399, -0.0217, -0.0821],\n                        [-0.0291,  0.0078, -0.0147],\n                        [-0.0490, -0.0256, -0.0136]]],\n              \n              \n                      [[[-0.0059, -0.0686, -0.0426],\n                        [ 0.0016, -0.0091, -0.0190],\n                        [ 0.0161,  0.0210, -0.0559]],\n              \n                       [[ 0.0368,  0.0217, -0.0167],\n                        [ 0.0321,  0.0056,  0.0077],\n                        [ 0.0421,  0.0140, -0.0329]],\n              \n                       [[-0.0871, -0.0347, -0.0152],\n                        [-0.0247, -0.0615, -0.0492],\n                        [ 0.0162,  0.0434,  0.0059]],\n              \n                       ...,\n              \n                       [[-0.0481,  0.0263,  0.0575],\n                        [-0.0714,  0.0163,  0.0357],\n                        [-0.0110,  0.0770,  0.0273]],\n              \n                       [[ 0.0043, -0.0296,  0.0122],\n                        [ 0.0223, -0.0307, -0.0672],\n                        [-0.0385, -0.0658,  0.0209]],\n              \n                       [[ 0.0271,  0.0149,  0.0237],\n                        [ 0.0020, -0.0329, -0.0086],\n                        [-0.0027, -0.0473, -0.0114]]],\n              \n              \n                      [[[ 0.0094,  0.0034,  0.0149],\n                        [ 0.0252, -0.0237,  0.0150],\n                        [ 0.1031,  0.0165,  0.0369]],\n              \n                       [[-0.0275,  0.0700,  0.0260],\n                        [-0.0660,  0.0156,  0.0141],\n                        [-0.0970, -0.0775,  0.0151]],\n              \n                       [[ 0.0700,  0.0344,  0.0744],\n                        [-0.1110, -0.0841,  0.0028],\n                        [-0.2180, -0.0844,  0.0499]],\n              \n                       ...,\n              \n                       [[ 0.0133, -0.0054, -0.0060],\n                        [ 0.0241, -0.0331,  0.0044],\n                        [ 0.0047, -0.0221,  0.0109]],\n              \n                       [[-0.0193,  0.0058,  0.0106],\n                        [-0.0443, -0.0155, -0.0127],\n                        [ 0.0362,  0.0310,  0.0096]],\n              \n                       [[ 0.0263, -0.0173, -0.0629],\n                        [-0.0418, -0.0333,  0.0099],\n                        [-0.0188,  0.0515,  0.0209]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.n.weight',\n              tensor([1.1920, 0.8423, 0.1876, 0.2106, 0.1341, 0.2714, 0.9813, 0.6085, 0.7037,\n                      0.2429, 0.2166, 0.5280, 1.0967, 1.0307, 0.4051, 0.7435, 1.2567, 0.1071,\n                      0.5654, 1.7555, 0.1565, 0.0689, 0.7268, 0.2518, 0.5960, 0.1936, 0.1299,\n                      0.2131, 1.3218, 0.1718, 0.5856, 0.4399, 0.2142, 0.2109, 0.4453, 1.0487,\n                      0.3060, 0.1760, 1.6629, 0.2414, 0.5115, 0.1294, 0.6136, 0.1324, 0.4566,\n                      1.7000, 0.4598, 0.2608, 1.5553, 0.2633, 0.9472, 0.2846, 0.2719, 0.2666,\n                      0.4275, 0.9359, 0.4715, 1.1090, 0.8228, 0.1977, 0.2363, 0.7446, 0.4630,\n                      1.1218, 0.9514, 0.7030, 0.1443, 0.3694, 0.5771, 0.9986, 1.4973, 0.0995,\n                      0.0991, 0.3422, 0.3118, 0.9272, 0.3517, 1.0762, 0.2480, 3.0043, 0.2267,\n                      0.2164, 0.3454, 0.2432, 0.1791, 0.4060, 0.4075, 1.5053, 1.2024, 1.8704,\n                      0.4454, 0.8509, 0.7154, 0.9406, 0.4476, 0.3716, 0.7766, 0.5335, 0.1790,\n                      0.3311, 0.3776, 0.1897, 0.2519, 1.3505, 1.6464, 1.7434, 0.4982, 1.1327,\n                      0.5724, 2.6944, 0.6740, 0.2234, 1.2501, 0.2211, 1.3479, 1.6099, 1.7143,\n                      0.3465, 0.2516, 1.0888, 0.2791, 0.2776, 0.1752, 1.2587, 0.2808, 1.5273,\n                      1.6369, 0.5346, 0.7193, 0.2860, 0.2823, 1.2816, 0.4902, 1.3826, 0.4465,\n                      0.7602, 0.2898, 1.2045, 0.3050, 0.2999, 0.4856, 0.1899, 0.7315, 1.1902,\n                      0.7424, 0.6865, 1.6830, 0.8828, 0.3126, 0.9882, 0.3677, 0.1674, 0.3883,\n                      0.5942, 0.2441, 0.3749, 0.4771, 0.5006, 1.7424, 0.8892, 0.9492, 0.2936,\n                      1.6500, 0.2350, 0.2146, 0.2479, 0.5877, 0.8330, 0.1865, 0.7198, 0.1555,\n                      0.3141, 0.3135, 0.1453, 1.7644, 0.3544, 0.3932, 0.6794, 0.3311, 0.2872,\n                      0.8106, 0.1884, 1.0085, 0.4722, 0.8718, 0.7695, 0.3359, 0.9392, 0.7732,\n                      0.1609, 1.9435, 0.1276, 0.2176, 1.9188, 0.2825, 0.4186, 0.6978, 1.2552,\n                      0.5120, 0.2438, 0.1577, 0.3321, 1.5814, 1.5295, 0.2069, 0.5041, 0.9266,\n                      1.0881, 1.6087, 0.9592, 1.4462, 0.6560, 0.5472, 0.4985, 0.4157, 1.3640,\n                      0.3857, 1.6082, 0.5439, 0.2474, 0.3539, 0.2334, 0.0926, 1.1583, 0.2588,\n                      1.3723, 0.2268, 1.5166, 0.1790, 0.7198, 0.2930, 0.3194, 1.3737, 0.4657,\n                      0.3673, 1.5464, 0.3960, 0.8255, 2.8208, 0.4037, 0.2640, 1.4754, 1.6758,\n                      1.1275, 0.7222, 0.2553, 0.2713, 0.1926, 0.3693, 0.3773, 2.0364, 0.2320,\n                      1.3111, 0.3831, 0.1895, 0.7688], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.n.bias',\n              tensor([-8.5849e-02, -2.7775e-01, -2.4511e-01,  2.3250e-01, -2.0551e-01,\n                       2.0396e-02,  2.1248e-01,  1.9109e-02, -2.8905e-02,  1.3190e-02,\n                       1.5649e-01,  1.2270e-01, -4.8306e-01,  6.2502e-01,  1.7566e-01,\n                      -9.4559e-02, -1.2288e+00,  4.1278e-02,  2.7872e-02, -6.2543e-01,\n                       1.2229e-01,  1.7603e-01,  1.4485e-01, -3.3234e-01, -3.4712e-02,\n                       1.2002e-02,  1.0176e-01, -3.3469e-01, -3.3614e-01,  1.1960e-01,\n                       2.1819e-01,  2.0627e-01,  6.1828e-02,  2.2932e-01, -5.3388e-02,\n                      -1.1159e-01,  1.2657e-01, -3.4002e-01, -8.7831e-01,  2.4685e-01,\n                       1.9333e-01, -5.5820e-02, -3.8604e-02, -1.9129e-01,  1.7698e-02,\n                      -7.0333e-01,  1.7737e-01,  1.2718e-01, -6.1304e-01,  1.7449e-01,\n                       5.2632e-01, -9.1550e-02, -7.0518e-01,  8.0105e-02,  4.2452e-01,\n                       8.8530e-03, -2.4733e-01, -4.4798e-02, -5.7316e-02,  8.4476e-04,\n                      -5.2776e-03,  4.6451e-01, -2.4496e-01,  3.6445e-03,  2.8589e-01,\n                       3.3225e-01,  1.5490e-02,  7.1960e-02, -4.0212e-02,  1.1878e-01,\n                       5.3192e-01, -9.5934e-02, -3.0034e-02,  5.7639e-02,  1.9154e-01,\n                       8.4541e-02,  1.4433e-01,  1.1418e-01,  7.6084e-02,  2.3717e-01,\n                       3.8047e-02,  1.2307e-01, -6.2752e-02,  7.7592e-02, -3.1708e-01,\n                       3.2542e-02,  4.0952e-04, -4.9150e-01, -2.2639e-01,  5.3025e-01,\n                       2.8949e-01,  1.7916e-01,  6.7002e-02, -8.3817e-02,  1.1999e-01,\n                       8.5657e-02,  1.8915e-01,  3.3333e-01,  1.4433e-01,  6.5878e-03,\n                       2.1610e-01, -8.3157e-02,  1.1463e-01, -1.1958e-01, -1.5678e+00,\n                       5.2131e-01, -3.4640e-02,  3.3080e-01, -9.5014e-02,  1.8131e+00,\n                       2.1457e-01, -6.3011e-02,  2.0083e-01,  1.4626e-01, -1.4144e-01,\n                       6.0544e-01, -5.4308e-02,  1.7522e-01, -2.9154e-02,  5.8731e-01,\n                      -6.5970e-02, -5.8891e-03, -8.2146e-02, -4.5186e-01, -1.4398e-01,\n                      -2.0216e-02, -2.8875e-01,  1.2467e-01, -2.0401e-02, -2.1955e-01,\n                       1.3114e-01, -1.4654e-01,  4.5586e-01, -9.4108e-03, -7.3981e-01,\n                       4.8978e-01,  9.5623e-02,  1.6215e-01,  1.2158e-02,  5.5477e-02,\n                      -1.0702e-01,  5.5227e-03, -1.1030e-01, -4.5852e-01, -3.2337e-01,\n                      -1.9408e-01, -7.5579e-01,  4.6482e-01, -6.6044e-01, -6.0214e-02,\n                       1.4520e-01, -3.7378e-01, -9.5850e-02, -7.9382e-02,  1.6761e-01,\n                       1.9585e-01,  8.6665e-03,  3.1386e-01, -8.2345e-01,  2.0882e-01,\n                      -1.0899e+00,  3.2754e-01, -5.7159e-01, -2.4879e-01,  8.6537e-02,\n                       1.7131e-02,  1.9146e-01,  4.0435e-01,  2.0557e-01,  9.6261e-02,\n                      -4.4109e-02, -2.0514e-01, -1.9219e-01, -9.9595e-02, -1.5896e-01,\n                       1.7668e-01,  3.7077e-01, -2.7194e-01,  8.8887e-02, -2.7500e-03,\n                      -1.9503e-01,  1.2761e-01,  1.1916e-01,  1.9490e-01,  4.4981e-01,\n                      -4.5271e-02,  1.5479e-01,  2.2091e-01,  4.4135e-03,  8.2044e-02,\n                      -1.1732e+00, -1.6718e-01,  1.9637e-01, -4.7833e-01, -1.0068e-01,\n                       1.0620e-01,  1.7978e-01,  4.1735e-02,  1.4505e-01, -5.6429e-01,\n                      -1.1723e-01, -4.3021e-01, -7.2935e-01, -5.8073e-02, -1.8628e-01,\n                      -7.0570e-01, -4.7934e-01,  1.5184e-02, -1.1293e+00,  8.7597e-02,\n                      -7.6128e-01,  1.6217e-01, -3.8745e-01, -3.3346e-01,  5.4051e-02,\n                       3.0960e-01, -9.9041e-02, -1.5045e+00,  2.6981e-01,  6.0357e-02,\n                       3.9534e-01,  2.6454e-01, -6.1810e-02,  1.8376e-02,  3.8226e-02,\n                      -7.6073e-01,  2.6335e-01,  4.5439e-01,  1.4378e-02,  3.1359e-01,\n                       8.3076e-02,  1.1623e-01,  2.4394e-01,  4.0309e-02,  3.5867e-01,\n                       5.4482e-01, -7.3796e-01, -1.2153e+00,  3.9524e-01,  1.7775e-01,\n                      -2.2892e-01, -1.7867e-01, -4.3899e-01,  5.2869e-01, -4.8353e-01,\n                       4.3734e-02,  1.3740e-01,  1.3039e-01,  2.1258e-01,  1.6715e-02,\n                      -3.2915e-02, -1.3121e-01,  5.0652e-01,  9.0878e-02,  1.9254e-01,\n                       6.2618e-02], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv0.norm.weight',\n              tensor([0.1609, 0.6334, 1.6826, 2.7577, 3.1939, 1.8640, 0.3331, 0.5111, 0.4229,\n                      2.2030, 2.4460, 0.7246, 0.2304, 0.7063, 1.0756, 0.6917, 0.1770, 2.9703,\n                      0.9183, 0.1244, 2.5343, 1.6660, 0.3355, 1.2469, 0.7603, 3.0403, 2.1595,\n                      1.4816, 0.1643, 2.2336, 0.6606, 1.4799, 1.6708, 2.5542, 1.1707, 0.1481,\n                      1.3851, 2.2667, 0.1304, 1.7207, 0.7585, 3.0537, 0.5973, 2.9265, 1.2663,\n                      0.1300, 0.7696, 2.4737, 0.1567, 2.4745, 0.3965, 1.6375, 1.4285, 1.5194,\n                      1.2144, 0.4656, 1.1360, 0.2231, 0.4420, 1.9838, 1.7259, 0.4644, 0.8708,\n                      0.3577, 0.2816, 0.8408, 2.3786, 0.9850, 0.8851, 0.7668, 0.3231, 3.3413,\n                      3.0848, 0.7470, 1.3791, 0.3866, 2.0459, 0.1859, 1.7592, 0.1709, 1.7115,\n                      1.7455, 1.0326, 3.0158, 1.7082, 1.0795, 1.6363, 0.1476, 0.1650, 0.2035,\n                      1.2901, 0.5195, 0.5398, 0.4731, 0.9569, 1.7941, 0.4648, 1.9253, 2.4007,\n                      1.2994, 1.3673, 1.4992, 2.9670, 0.1588, 0.1150, 0.3187, 0.8470, 1.5606,\n                      0.9711, 0.1319, 0.4503, 2.3221, 0.2738, 2.8165, 0.1743, 0.2985, 0.1563,\n                      1.6894, 2.2540, 0.2353, 1.0597, 1.7798, 2.1916, 0.2524, 1.3793, 0.1587,\n                      0.1713, 0.4662, 0.6310, 1.6445, 1.8024, 0.1958, 1.8256, 0.1452, 0.7689,\n                      0.8555, 1.2603, 0.3116, 1.5843, 2.1952, 0.9802, 2.8793, 0.4391, 0.2359,\n                      0.3412, 0.4780, 0.1185, 0.4843, 0.9444, 0.2698, 1.2959, 1.7099, 1.0367,\n                      0.6349, 2.0306, 1.5086, 1.1763, 0.7730, 0.1134, 0.3477, 0.2765, 1.5636,\n                      0.1559, 1.4669, 1.6465, 1.7040, 1.1789, 1.0086, 1.8918, 0.6852, 1.8962,\n                      1.5945, 1.3613, 2.7697, 0.1472, 1.4873, 1.0349, 0.6271, 0.9981, 1.6327,\n                      0.3992, 2.3886, 0.2989, 0.6273, 0.8570, 0.5726, 1.9186, 0.4415, 1.0052,\n                      2.3602, 0.1132, 2.3617, 2.0816, 0.1408, 1.3081, 1.5839, 0.6992, 0.6580,\n                      0.7934, 1.4318, 2.5092, 1.0594, 0.1160, 0.1633, 1.4038, 0.6688, 0.2724,\n                      0.5502, 0.1168, 0.6698, 0.1059, 0.5952, 0.7048, 0.7307, 1.0294, 0.1718,\n                      1.1048, 0.1208, 0.9052, 2.5981, 0.8403, 1.9239, 4.2988, 0.1743, 1.8185,\n                      0.1376, 2.3819, 0.2368, 2.2920, 0.4270, 1.5415, 1.5547, 0.6458, 1.1094,\n                      2.2159, 0.2728, 0.8186, 0.3807, 0.2173, 1.0075, 1.5153, 0.1475, 0.1568,\n                      0.4188, 0.4856, 2.1224, 1.6298, 2.7775, 2.1553, 0.8596, 0.1337, 1.5413,\n                      0.3220, 1.1421, 3.4466, 0.5632], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv0.norm.bias',\n              tensor([-0.0055,  0.6829,  0.4220, -0.4150,  0.3778,  0.3389, -0.0285, -0.1399,\n                      -0.0877,  0.2999, -0.1961, -0.0471,  0.0149,  0.1234, -0.0069,  0.4796,\n                      -0.1955, -0.2201,  0.2978, -0.0627, -0.3586,  0.2091, -0.0129, -0.0405,\n                       0.3887,  0.4298, -0.7430,  0.1977, -0.0727, -0.2805, -0.1079,  0.1229,\n                      -0.4562, -0.3234,  0.3047, -0.0380, -0.0989,  0.8169, -0.1006, -0.3810,\n                      -0.0823,  0.0094,  0.1325,  0.4902,  0.3747,  0.0312, -0.0566,  0.1613,\n                      -0.0741, -0.0143, -0.1004,  0.3926,  0.9155,  0.0312, -0.2611,  0.3063,\n                       0.7183, -0.1757,  0.1680, -0.3873, -0.3289, -0.1541,  0.3019,  0.1175,\n                      -0.1235,  0.0922, -0.0575, -0.0482,  0.4551,  0.5391,  0.1375,  0.1563,\n                      -0.3108, -0.2860, -0.1013,  0.1580,  0.3042, -0.1293,  0.0572,  0.4497,\n                      -0.0999, -0.2870, -0.2185,  0.2387,  0.4145,  0.0551,  0.5555,  0.0079,\n                      -0.0929,  0.1178, -0.0183,  0.1258,  0.1230,  0.3622,  0.0828,  0.3459,\n                       0.0139,  0.1857, -0.3471,  0.2126,  0.0178, -0.0314,  0.2090, -0.0816,\n                      -0.1327,  0.2673,  0.3093,  0.0495,  0.5947,  0.0275,  0.0057,  0.4585,\n                       0.1087, -0.0239, -0.0143,  0.1485, -0.0318,  0.0682,  0.3914, -0.1624,\n                      -0.2361,  0.3378, -0.0680,  0.0288,  0.1932,  0.0229,  0.0535, -0.0080,\n                       0.2793,  0.4303, -0.0705, -0.2615, -0.2153, -0.1237,  0.2303,  0.0389,\n                      -0.0224,  0.0555,  0.3304,  0.3443,  0.3167,  0.4033,  0.0495, -0.1078,\n                      -0.1165, -0.1669, -0.2155, -0.0673,  0.0644, -0.0666, -0.0098,  0.3585,\n                       0.2967,  0.1373, -0.1087, -0.0173,  0.3183, -0.1476, -0.0541,  0.0467,\n                       0.0245, -0.3231, -0.0396,  0.1179, -0.2247,  0.0971,  0.3268,  0.3079,\n                      -0.4558,  0.2806, -0.5267,  0.7107,  0.1353,  0.0623, -0.0810,  0.0112,\n                      -0.2694,  0.3677, -0.2590,  0.1825,  0.0854, -0.1959,  0.0543, -0.1291,\n                       0.2526,  0.2760,  0.1755,  0.1475,  0.7047, -0.2029, -0.1758,  0.3750,\n                      -0.3857, -0.1554, -0.1276,  0.3395,  0.1775,  0.7582, -0.0214,  0.3012,\n                       0.1948,  0.4265, -0.1059, -0.1758,  0.0608,  0.3051, -0.1974,  0.4791,\n                      -0.0374,  0.5001, -0.2396, -0.1413,  0.2383,  0.2230,  0.1980, -0.0961,\n                       0.2340, -0.2386,  0.0575,  0.3383, -0.4470, -0.4127,  0.1579, -0.0362,\n                       0.1928, -0.1103, -0.3477,  0.0273,  0.1043, -0.1474,  0.2198,  0.1285,\n                       0.6385,  0.3933, -0.2535,  0.1487,  0.4087,  0.0683,  0.4219, -0.0398,\n                       0.2865, -0.2362, -0.1477,  0.0469,  0.3171,  0.2238, -0.0370, -0.0366,\n                       0.0945, -0.4094, -0.0964,  0.0092,  0.1390,  0.0555, -0.2375,  0.1738],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv0.layer.weight',\n              tensor([[[[-0.0046,  0.0044,  0.0157],\n                        [ 0.0081,  0.0261,  0.0372],\n                        [-0.0156,  0.0108,  0.0072]],\n              \n                       [[ 0.0347, -0.0094, -0.0264],\n                        [-0.0077, -0.0336, -0.0301],\n                        [ 0.0188,  0.0531,  0.0178]],\n              \n                       [[-0.0185, -0.0118,  0.0193],\n                        [-0.0196, -0.0133,  0.0220],\n                        [-0.0367, -0.0085, -0.0101]],\n              \n                       ...,\n              \n                       [[ 0.0658,  0.0476, -0.0320],\n                        [ 0.0230,  0.0475, -0.0283],\n                        [-0.0140, -0.0785, -0.0061]],\n              \n                       [[-0.0457,  0.0873, -0.0018],\n                        [-0.0582, -0.0127, -0.0095],\n                        [-0.0202, -0.0212,  0.0109]],\n              \n                       [[-0.0114,  0.0235, -0.0140],\n                        [-0.0562, -0.0208, -0.0017],\n                        [-0.0156, -0.0131, -0.0092]]],\n              \n              \n                      [[[ 0.0022, -0.0197, -0.0178],\n                        [ 0.0059,  0.0005,  0.0070],\n                        [ 0.0187, -0.0094, -0.0020]],\n              \n                       [[ 0.0212, -0.0359,  0.0305],\n                        [-0.0134,  0.0113,  0.0181],\n                        [ 0.0086, -0.0165, -0.0581]],\n              \n                       [[-0.0031,  0.0179,  0.0155],\n                        [ 0.0086, -0.0084,  0.0377],\n                        [ 0.0089, -0.0144,  0.0027]],\n              \n                       ...,\n              \n                       [[-0.0044,  0.0094, -0.0173],\n                        [ 0.0066,  0.0045,  0.0129],\n                        [ 0.0071,  0.0180,  0.0060]],\n              \n                       [[ 0.0062,  0.0386,  0.0532],\n                        [-0.0256, -0.0247, -0.0016],\n                        [ 0.0135, -0.0161, -0.0085]],\n              \n                       [[ 0.0172, -0.0037, -0.0203],\n                        [ 0.0074, -0.0181, -0.0007],\n                        [ 0.0086,  0.0005,  0.0260]]],\n              \n              \n                      [[[-0.0186,  0.0094, -0.0109],\n                        [-0.0094,  0.0022,  0.0062],\n                        [ 0.0095, -0.0288, -0.0024]],\n              \n                       [[ 0.0525,  0.0456, -0.0041],\n                        [-0.0153, -0.0139, -0.0169],\n                        [-0.0137, -0.0241,  0.0127]],\n              \n                       [[ 0.0087,  0.0053,  0.0291],\n                        [-0.0199,  0.0059,  0.0129],\n                        [-0.0118,  0.0133,  0.0079]],\n              \n                       ...,\n              \n                       [[ 0.0412, -0.0022, -0.0241],\n                        [ 0.0175, -0.0238,  0.0273],\n                        [-0.0134,  0.0106, -0.0407]],\n              \n                       [[-0.0282, -0.0071,  0.0045],\n                        [ 0.0240,  0.0011,  0.0059],\n                        [-0.0457, -0.0018, -0.0112]],\n              \n                       [[ 0.0027,  0.0013,  0.0217],\n                        [ 0.0097,  0.0089,  0.0120],\n                        [-0.0115, -0.0102,  0.0013]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-0.0021,  0.0012,  0.0168],\n                        [ 0.0032, -0.0017, -0.0040],\n                        [ 0.0096,  0.0192, -0.0034]],\n              \n                       [[ 0.0743,  0.0143, -0.0611],\n                        [ 0.0385, -0.0152, -0.0316],\n                        [-0.0175,  0.0360,  0.0152]],\n              \n                       [[-0.0100,  0.0189,  0.0018],\n                        [-0.0271,  0.0141,  0.0141],\n                        [-0.0275,  0.0185,  0.0385]],\n              \n                       ...,\n              \n                       [[-0.0798, -0.0470,  0.0010],\n                        [-0.0558, -0.0432, -0.0046],\n                        [-0.0933, -0.0765,  0.0082]],\n              \n                       [[-0.0402, -0.0041,  0.0170],\n                        [ 0.0741,  0.0424, -0.0462],\n                        [-0.0119, -0.0703, -0.0296]],\n              \n                       [[-0.0260, -0.0249, -0.0396],\n                        [ 0.0002, -0.0768, -0.0618],\n                        [ 0.0168, -0.0231,  0.0233]]],\n              \n              \n                      [[[-0.0170, -0.0225, -0.0399],\n                        [-0.0125, -0.0141, -0.0115],\n                        [-0.0170, -0.0004, -0.0165]],\n              \n                       [[ 0.0244,  0.0507, -0.0006],\n                        [ 0.0057,  0.0552,  0.0600],\n                        [-0.0096,  0.0066, -0.0178]],\n              \n                       [[ 0.0673,  0.0219, -0.0341],\n                        [-0.0613, -0.0056,  0.0244],\n                        [ 0.0163,  0.0227,  0.0166]],\n              \n                       ...,\n              \n                       [[ 0.0047,  0.0058, -0.0209],\n                        [-0.0227,  0.0128, -0.0335],\n                        [-0.0310, -0.0008,  0.0120]],\n              \n                       [[-0.0287, -0.0267,  0.0077],\n                        [ 0.0028,  0.0177, -0.0254],\n                        [ 0.0209, -0.0498, -0.0075]],\n              \n                       [[-0.0190,  0.0147, -0.0324],\n                        [-0.0176,  0.0040, -0.0049],\n                        [-0.0066,  0.0212, -0.0043]]],\n              \n              \n                      [[[ 0.0101,  0.0049,  0.0172],\n                        [ 0.0057, -0.0102,  0.0085],\n                        [ 0.0091,  0.0100,  0.0301]],\n              \n                       [[-0.0319, -0.0237,  0.0102],\n                        [-0.0055, -0.0146,  0.0056],\n                        [-0.0326, -0.0133,  0.0295]],\n              \n                       [[-0.0438, -0.0078,  0.0266],\n                        [-0.0197,  0.0045,  0.0089],\n                        [ 0.0115,  0.0501,  0.0517]],\n              \n                       ...,\n              \n                       [[-0.0390, -0.0155, -0.0361],\n                        [-0.0522, -0.0411, -0.0747],\n                        [-0.0715, -0.0340, -0.0888]],\n              \n                       [[ 0.0387, -0.0407,  0.0458],\n                        [ 0.0159, -0.0335,  0.0342],\n                        [ 0.0020, -0.0553, -0.0124]],\n              \n                       [[-0.0430, -0.0072, -0.0427],\n                        [ 0.0079,  0.0014, -0.0019],\n                        [ 0.0439,  0.0099, -0.0199]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv1.norm.weight',\n              tensor([0.8205, 0.7553, 0.7165, 0.6487, 0.5620, 0.7984, 0.6657, 0.7871, 0.6039,\n                      0.9445, 0.5417, 0.3704, 1.0855, 0.8396, 0.9030, 0.7175, 0.7616, 0.4163,\n                      0.7754, 0.6330, 0.4863, 1.3305, 0.6542, 0.4853, 0.4364, 0.8148, 0.5652,\n                      1.0581, 0.8560, 0.7040, 0.5453, 0.5712, 1.1008, 0.4859, 0.5712, 0.5550,\n                      0.4190, 0.8989, 0.7131, 0.6505, 1.0805, 0.6768, 0.2796, 0.5901, 0.7872,\n                      0.5515, 0.5582, 0.6003, 0.6297, 0.6808, 0.4543, 1.4890, 0.5213, 0.5552,\n                      0.1012, 0.6989, 0.6430, 0.5738, 0.4311, 0.7659, 1.0577, 0.5765, 0.9109,\n                      0.8346, 0.5856, 0.5195, 0.8889, 2.5654, 0.8530, 0.4674, 1.0109, 0.7440,\n                      0.6062, 0.5689, 0.9383, 1.5565, 0.5845, 0.9699, 0.4777, 1.6183, 0.1596,\n                      0.5352, 0.4882, 0.4675, 0.5994, 0.9315, 0.5443, 0.6601, 0.5298, 1.1827,\n                      0.6414, 0.8575, 0.5618, 0.9363, 1.3183, 0.9585, 0.5529, 0.6633, 0.7159,\n                      0.6042, 1.1161, 1.1500, 0.6386, 0.9360, 0.4534, 0.8987, 0.5815, 0.5532,\n                      0.6456, 1.1323, 0.4447, 0.6620, 1.0102, 0.4212, 0.6022, 0.4498, 1.0867,\n                      0.5462, 0.5243, 0.6438, 0.5631, 0.5423, 0.8540, 0.6988, 0.7370, 0.7803,\n                      1.1606, 2.3083, 0.5398, 0.6250, 1.0582, 0.7780, 1.1112, 0.7092, 0.7281,\n                      0.9580, 0.8692, 0.5815, 1.3628, 1.0027, 0.8500, 1.0497, 0.5077, 0.6235,\n                      0.5909, 1.2404, 0.7016, 0.3879, 0.6145, 0.6090, 0.5512, 0.6270, 0.9813,\n                      0.7477, 0.7406, 0.9782, 0.7975, 0.5167, 0.5790, 0.4616, 0.7570, 0.4753,\n                      0.5650, 0.8631, 1.3011, 0.4111, 0.7115, 0.8187, 0.7214, 0.7080, 1.1652,\n                      0.6853, 0.7543, 0.6089, 0.8984, 1.4622, 1.0929, 0.6623, 0.8440, 1.6132,\n                      0.6068, 0.4656, 0.8728, 0.5603, 0.8523, 0.5488, 0.8357, 0.9482, 0.5705,\n                      1.5955, 0.6596, 0.8424, 0.4451, 0.7407, 0.6973, 2.5692, 1.5872, 1.5474,\n                      0.4214, 0.9341, 0.9355, 0.5523, 0.9142, 0.9339, 0.4264, 0.4133, 0.6310,\n                      1.0139, 0.5359, 0.4536, 0.5130, 0.8001, 0.7361, 0.5759, 1.9709, 0.8893,\n                      0.4888, 1.2866, 0.7937, 0.7015, 1.5198, 1.0701, 0.5671, 0.6951, 1.6390,\n                      0.4836, 0.4641, 0.8483, 0.4887, 0.4653, 0.9978, 3.0156, 0.4267, 2.8206,\n                      0.6022, 0.4120, 0.6724, 1.3814, 0.8952, 0.3655, 3.5724, 0.8973, 2.4042,\n                      1.0687, 0.4632, 0.9455, 1.2388, 0.6626, 0.6148, 2.6503, 1.2217, 0.9089,\n                      0.5283, 0.8254, 0.5662, 0.5135], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv1.norm.bias',\n              tensor([ 0.2106,  0.1315,  0.0899,  0.0445,  0.0241,  0.2102,  0.1134,  0.1952,\n                       0.0465,  0.2984,  0.0194, -0.3448,  0.3396,  0.1527,  0.2884,  0.1660,\n                       0.1674, -0.3712,  0.1630,  0.0259, -0.1071,  0.4526,  0.0960, -0.3018,\n                      -0.3824,  0.1707, -0.1579,  0.3278,  0.1884,  0.1016, -0.0183,  0.0587,\n                       0.4020, -0.8095,  0.0329,  0.0348, -0.6082,  0.2634,  0.0781,  0.1127,\n                       0.3321,  0.1532, -1.3496,  0.0857,  0.1558, -0.0220,  0.0074,  0.0953,\n                      -0.0055,  0.1359, -0.5487,  0.5486, -0.0385,  0.0440, -0.4746,  0.1381,\n                       0.0911, -0.0714, -0.2952,  0.1610,  0.3333,  0.0611,  0.2204,  0.1904,\n                       0.0581, -0.1518,  0.2962,  0.9945,  0.2196, -0.1246,  0.2917,  0.1295,\n                       0.0883, -0.0266,  0.2604,  0.5359,  0.0200,  0.2706, -0.1028,  0.6598,\n                      -0.7685, -0.0045, -0.2555, -0.5703,  0.0381,  0.2661,  0.0208,  0.1170,\n                       0.0149,  0.3892,  0.0866,  0.2274,  0.0186,  0.2237,  0.4804,  0.2777,\n                      -0.1773,  0.1186,  0.1048,  0.0768,  0.3823,  0.3795,  0.0833,  0.2815,\n                      -0.2108,  0.2007, -0.0176,  0.0538, -0.0982,  0.3687,  0.0069,  0.0860,\n                       0.2958, -0.2799, -0.1308, -0.0883,  0.3752,  0.0091, -0.1383,  0.1408,\n                       0.0357,  0.0346,  0.1756,  0.1294,  0.1715,  0.2188,  0.3621,  0.8842,\n                       0.0137,  0.0433,  0.3734,  0.2059,  0.3451,  0.1101,  0.1698,  0.3179,\n                       0.2036, -0.0568,  0.4746,  0.3441,  0.2133,  0.3061, -0.0950,  0.0424,\n                      -0.0171,  0.4053,  0.1537, -0.2404,  0.0900,  0.0877,  0.0358,  0.0721,\n                       0.3143,  0.1813,  0.1876,  0.3244,  0.1946, -0.1062, -0.1288, -0.2451,\n                       0.1487, -0.3264,  0.0155,  0.2489,  0.4806, -0.6839,  0.0530,  0.2489,\n                       0.1251,  0.1540,  0.3968,  0.1929,  0.1817,  0.0449,  0.2495,  0.5237,\n                       0.3216,  0.0681,  0.2049,  0.6010,  0.0783, -0.1398,  0.2073,  0.0457,\n                       0.2060,  0.0528,  0.2327,  0.2737, -0.1327,  0.6135,  0.1206,  0.2353,\n                      -0.3406,  0.2478,  0.1537, -0.2473,  0.5441,  0.6155, -0.0639,  0.2559,\n                       0.2779, -0.0320,  0.2413,  0.2618, -0.2099, -0.2220,  0.1088,  0.3275,\n                      -0.0717, -0.1594, -0.4549,  0.1587,  0.1328,  0.0508,  0.8010,  0.2365,\n                      -0.0971,  0.4776,  0.1536,  0.1463,  0.5713,  0.3375,  0.0525,  0.1213,\n                       0.5847, -0.0233, -1.3684,  0.2155, -0.3317, -0.0871,  0.3151,  1.1706,\n                      -0.1107,  1.0735,  0.0064, -0.0843,  0.0848,  0.4927,  0.2410, -0.1025,\n                       1.4032,  0.3048,  0.9074,  0.2863, -0.0911,  0.2411,  0.4268,  0.0081,\n                       0.0334,  1.0126,  0.4041,  0.2987, -0.0478,  0.2340, -0.0287,  0.1163],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.0.conv1.layer.weight',\n              tensor([[[[-2.0253e-02,  1.7369e-03,  7.7937e-03],\n                        [-7.0086e-03,  1.0263e-02, -9.3761e-03],\n                        [ 1.1094e-03, -2.4432e-02,  9.0966e-04]],\n              \n                       [[-1.4175e-03, -8.5452e-03, -8.1810e-03],\n                        [ 1.4308e-02,  1.1422e-02,  3.2677e-03],\n                        [ 4.1674e-03,  2.2645e-02, -4.4123e-03]],\n              \n                       [[-2.5451e-02, -5.3480e-02, -2.5949e-04],\n                        [-5.3900e-03,  8.9319e-04,  1.7790e-02],\n                        [ 9.0416e-04,  2.3764e-02, -1.0164e-02]],\n              \n                       ...,\n              \n                       [[ 1.2069e-02,  1.7487e-02,  7.1203e-03],\n                        [ 9.4278e-03,  4.1644e-02, -5.7696e-03],\n                        [-2.7347e-02,  1.8091e-02,  4.0789e-02]],\n              \n                       [[ 3.1521e-02,  4.1807e-02,  4.9451e-02],\n                        [ 9.8758e-03,  2.8312e-02,  1.9976e-03],\n                        [-1.6623e-02,  4.5492e-03, -1.0364e-02]],\n              \n                       [[-2.2958e-03, -1.5197e-03, -1.8377e-02],\n                        [ 4.9895e-03,  1.7089e-02,  3.7865e-03],\n                        [-1.9423e-02,  1.2943e-02,  1.1638e-02]]],\n              \n              \n                      [[[-2.2066e-02,  9.5175e-03, -3.2440e-02],\n                        [-2.6552e-03, -1.1589e-02, -2.0984e-02],\n                        [-3.1011e-02, -1.2185e-02,  1.8707e-02]],\n              \n                       [[-3.0958e-02, -1.5942e-02, -2.1791e-02],\n                        [-3.6742e-02, -8.8420e-03, -1.3594e-02],\n                        [-1.8443e-02, -4.7709e-02, -2.5851e-02]],\n              \n                       [[ 3.8976e-02, -1.5236e-02, -3.3333e-02],\n                        [-1.0823e-03,  5.5866e-03, -2.3730e-02],\n                        [-9.6585e-03, -1.5075e-02, -8.9349e-03]],\n              \n                       ...,\n              \n                       [[ 1.1919e-02, -5.6306e-02, -2.6102e-02],\n                        [ 5.2814e-03, -7.0852e-02,  9.9425e-03],\n                        [-7.6856e-03,  5.7903e-03,  3.7050e-02]],\n              \n                       [[ 1.0543e-02,  3.0146e-02, -1.8345e-03],\n                        [ 3.1766e-02, -5.9226e-03,  2.9089e-02],\n                        [ 2.0537e-02,  3.2639e-02, -2.2833e-02]],\n              \n                       [[ 7.3133e-03, -1.0447e-02, -1.5732e-02],\n                        [-2.7463e-03,  3.0554e-03,  1.1797e-02],\n                        [-4.3275e-02, -8.6987e-03,  1.4444e-02]]],\n              \n              \n                      [[[-4.7270e-02,  7.9368e-03, -1.8784e-02],\n                        [-8.4125e-03, -7.7375e-03, -3.9970e-02],\n                        [ 5.3391e-03, -1.3834e-02, -9.9815e-04]],\n              \n                       [[-2.5253e-03,  1.9083e-02,  1.4878e-05],\n                        [ 3.6387e-03,  1.1032e-02, -3.3545e-03],\n                        [-2.2349e-02, -2.5566e-02, -8.4748e-03]],\n              \n                       [[ 6.0080e-03, -2.0656e-02, -1.2714e-02],\n                        [-1.3704e-03, -1.0684e-02,  2.3972e-02],\n                        [-4.0508e-02, -1.0115e-02, -1.5475e-02]],\n              \n                       ...,\n              \n                       [[-4.2276e-02,  3.8677e-03,  4.0910e-02],\n                        [ 7.6901e-03,  3.3167e-03,  1.5844e-03],\n                        [ 3.4445e-02, -3.9440e-03, -2.6661e-03]],\n              \n                       [[-9.6582e-03,  1.1172e-02, -3.9958e-03],\n                        [-2.6155e-02, -2.0923e-02,  6.1700e-03],\n                        [ 7.6368e-03, -2.3447e-02,  1.3937e-03]],\n              \n                       [[ 2.6015e-03,  6.3468e-04,  4.4964e-02],\n                        [ 2.0382e-02,  8.2320e-03,  2.3631e-02],\n                        [-2.2071e-02, -2.1075e-02,  1.2562e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-1.4004e-02, -7.9707e-02, -3.4141e-02],\n                        [ 4.2356e-02, -4.6520e-02, -4.3261e-03],\n                        [ 1.3802e-03, -7.6926e-03,  8.0721e-03]],\n              \n                       [[-5.2536e-02,  3.6889e-02, -2.4812e-02],\n                        [-5.0086e-02, -6.5430e-03, -4.9835e-02],\n                        [-3.2430e-02, -1.5708e-02, -8.6764e-04]],\n              \n                       [[-6.7617e-02,  2.7522e-02,  6.0873e-03],\n                        [ 3.1297e-02, -2.2918e-02,  2.7619e-02],\n                        [-1.8215e-02,  3.3410e-03, -2.4793e-02]],\n              \n                       ...,\n              \n                       [[-3.3361e-02, -1.1256e-02, -3.4420e-02],\n                        [ 3.7209e-02, -4.4699e-02, -1.3754e-02],\n                        [-9.7885e-03, -5.7088e-02, -5.1095e-03]],\n              \n                       [[-6.1380e-03, -6.2388e-02,  7.0285e-02],\n                        [-7.1813e-03,  1.8827e-02,  4.7660e-02],\n                        [-1.7244e-02,  7.1649e-02,  3.7182e-02]],\n              \n                       [[-1.7039e-01, -8.0998e-02, -4.1146e-02],\n                        [-6.1713e-02, -4.7245e-02, -2.8050e-02],\n                        [-6.7584e-02, -1.6260e-02, -1.5086e-02]]],\n              \n              \n                      [[[ 8.6455e-03,  2.3151e-02, -6.9288e-03],\n                        [ 1.7380e-02,  1.2662e-02,  3.8856e-02],\n                        [ 3.5724e-02,  2.9818e-02,  3.2096e-03]],\n              \n                       [[-1.3323e-02,  2.9836e-02, -2.1313e-03],\n                        [ 2.4003e-04,  5.1336e-02,  2.6239e-02],\n                        [ 2.8577e-02, -8.7777e-02,  5.5660e-02]],\n              \n                       [[ 1.7096e-02, -2.2978e-02,  9.1973e-02],\n                        [ 1.8896e-02,  7.6185e-03,  4.0899e-02],\n                        [ 1.7913e-03, -2.1862e-02,  2.2480e-03]],\n              \n                       ...,\n              \n                       [[-3.1139e-02, -3.8878e-02, -4.8837e-02],\n                        [-2.1440e-02, -6.0301e-03,  2.5794e-02],\n                        [-4.2571e-02, -1.5358e-02, -6.7211e-02]],\n              \n                       [[-2.1249e-02, -6.1985e-02, -8.7892e-02],\n                        [-9.2922e-02,  3.3984e-02,  5.5421e-04],\n                        [ 1.0803e-02,  3.5109e-02,  5.6181e-03]],\n              \n                       [[-3.1066e-02,  1.9595e-02,  5.5665e-02],\n                        [ 2.3948e-02,  4.1145e-02,  1.8416e-02],\n                        [-1.5967e-02,  1.3431e-02, -5.0493e-03]]],\n              \n              \n                      [[[-3.7987e-03,  1.5522e-02, -1.7304e-02],\n                        [ 5.7597e-02, -1.0822e-02,  1.1567e-02],\n                        [-1.2322e-02, -6.6309e-02,  4.0137e-02]],\n              \n                       [[ 1.0641e-02, -1.3476e-02,  1.3777e-02],\n                        [-1.0844e-02, -9.3141e-03,  2.5215e-02],\n                        [-1.6978e-02,  3.9269e-03, -3.3871e-03]],\n              \n                       [[ 4.1284e-03,  1.7798e-02,  4.1104e-02],\n                        [-1.0232e-02, -2.8400e-02, -3.4562e-02],\n                        [ 8.4986e-03, -3.2366e-02,  1.8763e-02]],\n              \n                       ...,\n              \n                       [[-9.4938e-02, -6.7958e-02, -3.9259e-02],\n                        [-1.2702e-02, -2.9338e-02,  1.1381e-02],\n                        [-5.8238e-02,  5.7710e-05,  1.9903e-02]],\n              \n                       [[-3.7004e-02,  1.7965e-02,  2.4371e-02],\n                        [-7.8810e-03,  3.6085e-03,  6.4904e-03],\n                        [ 9.2352e-03,  8.4215e-04, -6.4986e-03]],\n              \n                       [[ 2.2553e-04, -4.3349e-02, -2.3943e-02],\n                        [ 1.2119e-03, -3.6985e-02,  3.6225e-03],\n                        [ 3.4296e-02,  1.0720e-02,  6.6161e-03]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv0.norm.weight',\n              tensor([0.8736, 0.7357, 1.2559, 1.7519, 1.1769, 1.6241, 0.5987, 1.1787, 1.0914,\n                      1.3370, 1.8214, 1.1459, 0.4328, 1.1358, 1.1690, 0.8115, 0.3007, 3.0018,\n                      1.1789, 0.3795, 1.9481, 4.9334, 0.7123, 1.1182, 0.7826, 2.0797, 1.8543,\n                      1.4009, 0.6526, 1.5619, 0.9406, 0.7140, 1.5762, 1.7796, 1.0294, 0.7662,\n                      1.3088, 1.1560, 0.3892, 2.0170, 1.1186, 1.3114, 0.9857, 1.3130, 1.2174,\n                      0.4336, 1.1275, 1.9775, 0.3841, 1.4346, 0.6933, 1.0632, 0.8942, 1.2459,\n                      1.5859, 0.7131, 0.9400, 0.5109, 0.6094, 1.6338, 1.2975, 0.7076, 1.0178,\n                      0.5596, 0.5648, 1.4671, 1.3202, 0.9558, 0.8854, 0.5967, 0.6631, 2.3439,\n                      1.4289, 1.1004, 1.1335, 0.6423, 1.2098, 0.7817, 1.7496, 0.3085, 1.6022,\n                      1.6609, 1.0292, 1.8848, 1.3521, 1.1571, 1.0722, 0.5408, 0.5006, 0.3736,\n                      1.3738, 0.8325, 0.7985, 0.6699, 1.0877, 1.4239, 0.7270, 1.2234, 1.7842,\n                      0.8724, 1.4540, 1.1012, 1.3431, 0.5909, 0.2470, 0.6416, 1.1084, 1.1121,\n                      0.8240, 0.2939, 1.3360, 1.2644, 0.5455, 1.6487, 0.7280, 0.5354, 0.4797,\n                      1.5427, 0.8490, 0.5525, 1.4635, 1.2245, 1.2891, 0.6304, 1.2733, 0.6661,\n                      0.3535, 1.4709, 0.6534, 1.3567, 1.6521, 0.3949, 1.6130, 0.7045, 0.8793,\n                      1.0767, 1.3490, 0.4810, 1.0182, 1.5115, 0.8781, 1.4959, 0.7488, 0.4713,\n                      0.7771, 0.8269, 0.3305, 0.6772, 1.2660, 0.8785, 1.0474, 1.4140, 1.0377,\n                      0.8149, 0.9684, 1.0437, 1.0136, 1.1519, 0.3192, 0.7073, 0.4711, 1.4348,\n                      0.4282, 1.0863, 1.8686, 1.1390, 0.8761, 1.6144, 1.7155, 0.9534, 1.7362,\n                      0.8646, 1.1110, 1.0809, 0.5729, 1.4073, 1.4892, 0.7465, 1.3574, 0.8366,\n                      0.8763, 1.9187, 0.5064, 1.1376, 1.1828, 0.7842, 1.4968, 0.9275, 1.0082,\n                      2.9437, 0.3206, 2.3819, 1.5937, 0.5901, 1.2227, 1.3239, 0.7519, 0.8455,\n                      0.9368, 1.2538, 1.5519, 0.8276, 0.3532, 0.3516, 1.3822, 0.8902, 0.5792,\n                      0.7008, 0.3450, 0.8500, 0.2530, 0.9584, 0.9762, 0.6418, 0.9763, 0.3926,\n                      1.2297, 0.3715, 1.0176, 1.5763, 1.3258, 1.5665, 2.6316, 0.7352, 1.3151,\n                      0.4569, 2.8025, 0.4535, 1.5026, 0.7056, 1.8999, 1.5680, 0.7406, 1.1038,\n                      1.3517, 0.5866, 0.9022, 0.5467, 0.5940, 1.5367, 1.0068, 0.3132, 0.4753,\n                      0.8081, 0.8566, 1.5250, 1.7887, 2.1827, 1.0631, 1.4247, 0.4760, 1.9702,\n                      0.5915, 1.3837, 1.8283, 0.8844], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv0.norm.bias',\n              tensor([-5.9032e-02, -1.2085e-01,  1.8616e-01,  1.4971e-01,  2.2288e-01,\n                       5.2080e-01, -1.6889e-02,  1.6576e-01,  8.1027e-03,  3.1601e-01,\n                       3.3079e-01,  2.8953e-02, -3.5112e-02,  3.5704e-01, -7.1453e-02,\n                       1.7642e-01, -4.4990e-01,  7.5278e-01,  3.8719e-01, -1.1837e-01,\n                       2.5897e-01,  3.8300e-01, -6.4933e-02, -1.1850e-01, -6.8051e-02,\n                       7.8190e-01,  3.5741e-02,  4.2651e-01, -2.0309e-01,  1.6234e-01,\n                      -7.8858e-02,  1.0423e-01, -1.0544e-01,  2.6307e-01,  3.7143e-01,\n                       5.3449e-03,  9.8677e-02,  3.8224e-01, -1.8140e-01,  7.8208e-02,\n                      -6.9727e-02,  1.9334e-01,  1.8349e-01,  4.2041e-01,  4.3749e-01,\n                      -2.1114e-02,  1.3669e-01,  3.2681e-01, -2.6974e-01,  3.0996e-01,\n                      -6.5679e-02,  1.2834e-01, -1.1140e-01,  9.8222e-01,  7.2392e-02,\n                       5.0199e-01, -1.7041e-02, -1.5184e-01, -6.7707e-02,  3.4838e-02,\n                      -1.3207e-01, -1.6666e-01,  2.2429e-01,  5.7744e-03, -1.4172e-01,\n                       5.3354e-01,  1.2255e-01, -1.5353e-01,  2.5665e-01,  6.2161e-02,\n                       1.5642e-01,  6.6899e-01,  1.4996e-01, -1.5188e-01, -6.6928e-02,\n                       1.9362e-01,  1.9684e-01, -4.3281e-01,  4.6448e-01,  5.3343e-01,\n                       3.4534e-01,  1.4972e-01, -1.6275e-01,  4.9286e-01,  4.4038e-01,\n                       1.5322e-02, -6.7056e-01, -9.2200e-02, -2.2659e-01,  1.9733e-01,\n                      -1.1364e-02,  2.8469e-01,  1.2381e-01,  2.5684e-01,  4.8617e-02,\n                       3.9595e-01,  4.7396e-02, -6.0763e-02,  2.1017e-01,  2.4775e-01,\n                       2.4562e-01, -4.2593e-02,  3.6088e-01, -1.7163e-01, -1.4501e-01,\n                       3.4172e-01,  5.3697e-01,  4.5584e-01, -7.0782e-01,  5.9137e-02,\n                       3.3998e-01,  5.4766e-01,  1.6062e-01,  3.5715e-01, -2.7935e-01,\n                       1.1157e-01, -1.6075e-01,  3.0912e-01,  2.1153e-01, -4.9053e-01,\n                      -2.1636e-03,  4.3988e-01, -1.3520e-01, -1.7742e-03,  1.0081e-01,\n                      -4.3077e-02,  1.2365e-01,  1.4936e-01, -1.3123e-01,  4.8821e-01,\n                       2.6282e-01, -2.0316e-01,  1.1940e-01, -2.3921e-01,  1.3297e-01,\n                       2.2299e-01,  2.4156e-01,  3.7011e-02,  2.6470e-01,  3.9446e-01,\n                       1.2472e-01,  6.0961e-01,  1.8154e-01, -1.7444e-01, -1.8159e-01,\n                      -2.1777e-01, -4.7899e-01, -4.0149e-01,  2.8718e-01, -7.7485e-02,\n                      -5.1687e-04,  4.3823e-01,  1.8654e-01,  7.6141e-02, -1.7559e-01,\n                       2.1559e-03,  3.9665e-01, -3.5558e-02, -1.2053e-01,  1.1282e-01,\n                      -2.5677e-01, -2.6964e-02, -2.7359e-01,  2.1826e-01,  2.0643e-01,\n                       3.0161e-01, -7.5114e-01,  6.6093e-01,  5.8047e-02,  5.5041e-01,\n                      -2.5306e-02,  3.0746e-01,  1.4946e-01,  2.8863e-01, -1.9851e-01,\n                       2.1496e-01,  1.2624e-02,  6.9109e-02, -4.0263e-02, -4.5424e-01,\n                       4.9327e-01,  3.7138e-01, -3.0591e-02,  3.0501e-02,  4.2375e-01,\n                       2.3557e-01,  4.1232e-01,  2.7289e-01,  7.3822e-01,  4.9949e-01,\n                      -4.5392e-01,  2.4363e-01,  5.2250e-02, -3.5964e-01, -5.3250e-02,\n                       3.8453e-01, -7.4435e-01,  4.8685e-01,  5.8177e-02,  6.4792e-02,\n                       3.9428e-01, -8.8337e-03, -1.8071e-01, -2.3688e-01,  2.4531e-01,\n                       2.4503e-01, -3.9648e-01, -1.3465e-01, -1.5581e-01,  4.6475e-01,\n                      -6.3672e-02, -2.8237e-01,  2.1803e-01,  3.1688e-01,  2.2028e-01,\n                      -2.2439e-01,  2.2357e-01, -5.4245e-01, -8.6723e-02,  3.3119e-01,\n                      -1.5770e-01,  1.2511e-01,  8.2385e-01, -1.0146e-01,  3.9839e-01,\n                      -4.2155e-01,  4.8042e-01,  6.1987e-02,  3.5706e-01, -1.1106e-01,\n                       7.4127e-01,  4.4482e-01,  2.7609e-01,  1.4156e-01,  3.8456e-02,\n                       3.0655e-01,  2.7905e-01, -3.0460e-02,  3.7332e-01,  3.4489e-01,\n                      -1.5690e-01, -1.9911e-01, -5.3949e-01,  5.4538e-02,  5.5015e-01,\n                       3.9159e-01,  3.8488e-01,  5.4712e-01, -3.9484e-01, -3.9367e-01,\n                      -1.4527e-01,  3.6018e-01,  4.5532e-02,  5.0566e-01,  3.0880e-01,\n                       2.4208e-01], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv0.layer.weight',\n              tensor([[[[-2.3761e-02, -2.3405e-02, -1.9878e-02],\n                        [-8.0576e-03, -2.2404e-04, -8.7287e-03],\n                        [ 2.7706e-03, -1.5838e-03,  2.2205e-02]],\n              \n                       [[ 7.1067e-02,  4.1234e-03, -9.3109e-03],\n                        [ 5.2261e-03, -1.5330e-02, -1.7249e-02],\n                        [ 7.4738e-03, -2.8144e-02, -7.2970e-02]],\n              \n                       [[-2.5948e-02, -3.5987e-02,  6.0599e-05],\n                        [-6.0986e-03, -4.8913e-03, -1.6679e-02],\n                        [ 2.0612e-02,  1.6859e-02,  5.9370e-02]],\n              \n                       ...,\n              \n                       [[-2.6495e-02,  3.5557e-02,  2.7873e-02],\n                        [ 5.0922e-02,  8.8568e-03,  4.6675e-02],\n                        [ 1.9376e-02, -2.2054e-02, -3.3679e-02]],\n              \n                       [[-2.4609e-02, -6.7577e-03,  2.2299e-02],\n                        [-2.5583e-02, -1.8657e-02, -2.5419e-02],\n                        [-3.6479e-02,  8.7544e-03, -1.7130e-03]],\n              \n                       [[-7.5427e-03, -2.0237e-03,  1.4430e-02],\n                        [-2.8401e-03,  1.8072e-02,  2.4764e-03],\n                        [ 2.1645e-02,  2.9968e-02, -4.9525e-03]]],\n              \n              \n                      [[[ 9.4125e-03, -1.4238e-02,  2.3084e-02],\n                        [-2.7681e-04, -3.9063e-02,  1.5702e-02],\n                        [-2.7438e-02, -1.4934e-02,  2.6668e-02]],\n              \n                       [[-1.7052e-02, -2.5037e-02, -5.6936e-02],\n                        [-3.9554e-03, -4.6381e-02, -3.0826e-02],\n                        [ 3.1364e-02, -4.5835e-02, -3.3105e-02]],\n              \n                       [[-6.8119e-02, -3.2595e-02,  4.5449e-03],\n                        [-2.6225e-02,  6.0373e-03, -3.0067e-02],\n                        [ 1.4044e-02, -1.9669e-02,  4.3553e-02]],\n              \n                       ...,\n              \n                       [[-1.4679e-03, -4.9994e-02, -1.0051e-01],\n                        [ 3.4950e-02,  7.2631e-03, -6.6138e-02],\n                        [ 9.6919e-02,  5.3097e-02, -6.5275e-03]],\n              \n                       [[-5.5491e-02, -2.7472e-02, -6.8328e-02],\n                        [-6.0978e-02,  2.6183e-02, -4.8573e-02],\n                        [-6.4824e-02, -4.6692e-02, -2.4457e-02]],\n              \n                       [[-2.6815e-03, -6.3262e-03,  2.7915e-02],\n                        [ 3.6144e-02, -3.9211e-02,  6.4521e-03],\n                        [ 4.0425e-02, -1.5653e-02,  3.8388e-02]]],\n              \n              \n                      [[[-2.0934e-02,  1.4393e-03, -2.2466e-02],\n                        [-2.1737e-03,  5.0344e-02,  1.2680e-02],\n                        [-5.0632e-02,  2.0189e-03, -3.4842e-02]],\n              \n                       [[ 8.2760e-02,  8.6983e-03,  4.1776e-02],\n                        [-2.9572e-02, -5.3252e-02, -1.4050e-02],\n                        [-1.1650e-02, -4.5758e-03, -4.1186e-03]],\n              \n                       [[-7.5205e-04, -4.9720e-02, -1.4479e-02],\n                        [ 4.9345e-03, -2.9058e-02, -3.3293e-02],\n                        [ 9.3988e-03, -1.4974e-03,  6.5105e-03]],\n              \n                       ...,\n              \n                       [[ 1.3695e-02, -6.5503e-02,  1.9066e-03],\n                        [-3.3793e-02, -6.8201e-02, -7.8110e-02],\n                        [-4.9524e-02, -6.7891e-02, -5.1332e-02]],\n              \n                       [[ 1.1186e-02,  1.2462e-02,  2.6042e-02],\n                        [ 2.7295e-02, -2.3175e-02,  1.1858e-02],\n                        [-2.5959e-02, -1.4133e-02,  3.6185e-03]],\n              \n                       [[ 3.3324e-02, -1.0588e-02,  1.1613e-02],\n                        [ 1.5953e-02, -5.1867e-02, -3.2394e-02],\n                        [ 3.6347e-02, -1.0162e-02,  1.1624e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-3.4264e-02,  1.3595e-02, -5.3183e-03],\n                        [-1.8862e-02,  4.5629e-02,  8.0147e-02],\n                        [-4.2024e-02,  7.3111e-03,  4.8210e-02]],\n              \n                       [[-7.1944e-03, -8.0850e-03,  3.6907e-02],\n                        [ 1.0323e-02, -1.9765e-02,  3.2129e-03],\n                        [ 1.4962e-02,  5.0481e-02,  9.7735e-02]],\n              \n                       [[-3.5083e-02,  3.4607e-03, -4.6287e-02],\n                        [-1.3865e-03, -2.0128e-02, -2.5696e-02],\n                        [-5.0332e-03,  1.5321e-02, -2.3096e-02]],\n              \n                       ...,\n              \n                       [[-1.5066e-02, -1.3673e-02, -1.4199e-02],\n                        [-2.4264e-02, -1.1851e-02, -1.8427e-02],\n                        [ 3.6893e-03, -5.9459e-03, -2.5289e-02]],\n              \n                       [[ 6.4076e-03,  1.5795e-02,  2.0352e-03],\n                        [-2.6856e-02, -1.0429e-02,  2.2923e-03],\n                        [-1.9940e-02, -7.0419e-03,  1.9752e-02]],\n              \n                       [[ 2.6542e-02,  4.0588e-03, -6.5117e-03],\n                        [-2.1545e-02,  4.8146e-03, -1.0407e-02],\n                        [ 3.4930e-03,  2.0498e-02, -6.0335e-04]]],\n              \n              \n                      [[[-7.5291e-03,  2.3858e-03,  1.8887e-02],\n                        [-1.2338e-02, -1.0524e-02, -2.2584e-03],\n                        [ 1.4564e-02,  1.6376e-02,  3.1039e-02]],\n              \n                       [[-2.0585e-02,  4.4314e-02,  2.5638e-03],\n                        [-1.9846e-02,  4.9289e-02, -3.9487e-02],\n                        [-1.5266e-02,  2.8241e-02, -5.1521e-02]],\n              \n                       [[ 2.2050e-02, -1.2990e-02,  3.6877e-03],\n                        [-5.6326e-04, -2.3745e-02, -9.1832e-03],\n                        [ 4.5255e-02,  4.2816e-02,  7.4760e-02]],\n              \n                       ...,\n              \n                       [[-2.7240e-02,  1.1106e-02,  6.7226e-03],\n                        [ 6.2818e-03, -3.6252e-03, -1.3899e-02],\n                        [ 7.1090e-03,  3.4836e-02,  9.2794e-03]],\n              \n                       [[ 2.7276e-03, -1.0052e-02, -4.2779e-02],\n                        [ 6.5540e-03,  5.8058e-03,  2.1026e-02],\n                        [-1.4388e-02, -2.3595e-02, -2.6469e-02]],\n              \n                       [[-1.2710e-02,  2.9462e-02,  2.2440e-02],\n                        [-1.6973e-02,  6.0634e-02,  1.0205e-02],\n                        [-1.1890e-02,  1.1704e-02, -1.5780e-02]]],\n              \n              \n                      [[[-3.1543e-03,  1.0933e-03,  3.6332e-03],\n                        [-6.0016e-03, -1.6807e-02, -3.3873e-02],\n                        [-1.1694e-02,  2.8189e-02, -1.2803e-02]],\n              \n                       [[ 2.6609e-02,  2.6169e-02, -2.8077e-03],\n                        [ 2.0287e-02, -2.1376e-02,  3.6396e-02],\n                        [-1.7638e-02, -2.2724e-04, -1.8859e-03]],\n              \n                       [[ 1.6709e-02,  1.8805e-03,  2.1611e-02],\n                        [-1.1634e-02, -4.0620e-03, -2.2342e-02],\n                        [ 2.5998e-02, -5.3001e-02, -6.1026e-02]],\n              \n                       ...,\n              \n                       [[-1.8684e-02,  4.1103e-02,  7.8622e-02],\n                        [-3.2850e-02,  4.6469e-02, -1.7106e-02],\n                        [ 1.2618e-02,  4.7640e-02, -1.0989e-01]],\n              \n                       [[ 6.1681e-03,  5.7009e-02,  5.4590e-02],\n                        [-6.6280e-02, -5.1457e-02,  1.4428e-04],\n                        [ 2.4181e-02, -2.6459e-02, -4.7659e-03]],\n              \n                       [[-1.0968e-01,  2.0516e-02,  1.8490e-01],\n                        [-1.1679e-01,  1.8024e-01,  4.6077e-01],\n                        [-1.6907e-01,  4.0857e-03,  2.2627e-01]]]], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv1.norm.weight',\n              tensor([1.3319, 1.3834, 1.3947, 1.2958, 1.3078, 1.5730, 1.6132, 1.2144, 1.0056,\n                      1.3844, 1.8960, 1.1330, 1.6290, 1.1410, 2.1715, 1.8379, 2.0623, 1.1695,\n                      0.9791, 2.0318, 1.8055, 1.9227, 1.4296, 1.5452, 1.4242, 1.3751, 1.7470,\n                      3.1023, 2.0127, 2.1465, 1.3269, 2.1920, 1.3897, 1.4633, 1.3442, 1.7624,\n                      2.8271, 1.2963, 2.0873, 1.8228, 1.1129, 1.5277, 1.2432, 2.0919, 3.2710,\n                      0.9821, 1.7117, 1.0544, 1.8029, 2.8170, 1.6787, 1.3347, 1.8722, 2.7093,\n                      1.9075, 1.6227, 1.9913, 1.7852, 3.0453, 1.4909, 1.3115, 1.2855, 2.0916,\n                      1.5553, 1.6677, 1.0593, 1.3748, 1.6201, 1.3237, 1.7050, 1.1540, 1.9999,\n                      1.2518, 1.4416, 1.0835, 1.5184, 2.7060, 1.3694, 2.0974, 1.6433, 1.4063,\n                      0.8807, 1.3175, 2.0663, 1.2808, 1.3121, 1.1300, 1.3116, 1.3569, 1.7609,\n                      2.3622, 1.5800, 2.6611, 1.3617, 1.8832, 1.2264, 1.3235, 1.5215, 2.3648,\n                      1.7289, 1.1437, 1.5229, 2.3320, 1.5471, 1.7608, 1.6991, 1.2649, 0.7866,\n                      1.0482, 2.0091, 1.6304, 0.8767, 1.7268, 1.6462, 1.5833, 1.0439, 2.3473,\n                      1.2884, 1.4118, 1.6299, 1.6177, 1.8147, 2.4540, 1.2924, 1.4431, 3.8123,\n                      1.8030, 2.1598, 1.2401, 1.0752, 1.2079, 1.6233, 1.6190, 0.9624, 0.8606,\n                      1.6728, 2.2153, 1.9499, 2.0701, 2.3890, 2.6545, 1.3247, 1.0842, 1.6128,\n                      1.8549, 2.1577, 2.1609, 1.6579, 2.2394, 1.3998, 1.9774, 1.5341, 1.5173,\n                      1.4774, 1.2137, 1.1339, 2.3074, 1.4450, 1.8588, 1.2664, 2.5597, 1.3119,\n                      1.2674, 2.9134, 1.0410, 1.3965, 2.6078, 1.8028, 1.8178, 1.3913, 1.1251,\n                      1.7895, 1.2222, 1.7343, 2.1587, 1.1355, 1.0023, 1.1457, 1.7209, 1.6570,\n                      1.6121, 1.3372, 1.1357, 2.0411, 0.8948, 1.4490, 1.6819, 1.4326, 0.5784,\n                      1.0886, 2.1444, 1.0929, 0.9008, 1.5639, 2.1757, 1.0717, 1.2256, 1.4848,\n                      1.4457, 1.1031, 1.4283, 1.1465, 1.3112, 1.9819, 1.0974, 1.3263, 1.2305,\n                      1.1419, 2.9167, 3.4527, 1.3172, 1.3664, 1.9846, 0.9473, 1.1899, 1.3170,\n                      1.4388, 1.4578, 1.6704, 0.9524, 1.7197, 1.6875, 1.4741, 1.3259, 0.9818,\n                      1.1791, 2.0669, 1.3738, 1.2356, 1.3308, 1.9551, 2.1694, 1.9371, 1.0916,\n                      1.6209, 1.2625, 1.2734, 2.3918, 2.0194, 2.1411, 1.9943, 2.7128, 3.2298,\n                      1.1775, 1.9812, 1.9702, 0.9015, 1.4299, 1.6318, 2.1775, 1.5653, 1.9463,\n                      1.5683, 1.5799, 1.0612, 2.9559], device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv1.norm.bias',\n              tensor([ 0.0552,  0.2663,  0.2858, -0.0491, -0.0762,  0.3768,  0.1910, -0.0796,\n                      -0.5692, -0.0632,  0.2992, -0.2824,  0.2477, -0.0879,  0.4758,  0.3973,\n                       0.5527, -0.4930, -0.6185,  0.5710,  0.3908,  0.4752,  0.0247,  0.3262,\n                      -0.0853, -0.3563,  0.4211,  1.1416,  0.3640,  0.6106, -0.6059,  0.6981,\n                       0.1867,  0.1097,  0.0383,  0.4648,  0.9460,  0.1524,  0.8077,  0.5005,\n                       0.0326,  0.2362,  0.1697,  0.5502,  1.1586, -0.2537,  0.4433, -1.2490,\n                       0.6640,  0.9852,  0.2291,  0.0753,  0.5236,  0.7635,  0.4405,  0.0726,\n                       0.6096,  0.3748,  1.0761,  0.3917, -0.2400, -0.1563,  0.6915,  0.1376,\n                       0.1364, -0.4761,  0.1821,  0.2641,  0.0305,  0.4082, -0.4964,  0.4338,\n                       0.0579,  0.1408, -0.7539,  0.2960,  0.9805, -0.0841,  0.3722, -0.0208,\n                      -0.0242, -0.7099, -0.0957,  0.5745, -0.0488, -0.3041, -0.2457, -0.1449,\n                      -0.0417,  0.4911,  0.7783,  0.3740,  0.9990, -0.0796,  0.5901,  0.1125,\n                      -1.1394,  0.3652,  0.7817,  0.4793,  0.0429,  0.2965,  0.5567, -0.0745,\n                       0.4450,  1.0339, -0.4131, -1.2238,  0.2295,  0.4905,  0.2663, -0.7779,\n                       0.3150,  0.4499, -0.0537, -0.2255,  0.6765, -0.1565,  0.2886,  0.4677,\n                       0.1969,  0.1966,  0.7700, -0.3465, -0.0667,  1.4316,  0.3337,  0.8708,\n                       0.1944, -0.5859, -0.2772,  0.5320,  0.1635, -0.6968, -0.8373,  0.3934,\n                       0.5188,  0.4786,  0.6075,  0.7407,  0.7464, -0.2706, -0.3279, -0.0849,\n                       0.2699,  0.8266,  0.4618,  0.2085,  0.7082, -0.0843,  0.5687,  0.1017,\n                       0.0195,  0.1020,  0.1444, -0.4201,  0.7935,  0.2016,  0.3715,  0.0529,\n                       0.8838, -0.2150,  0.1057,  0.1989, -0.6256, -0.3911,  0.8337,  0.3691,\n                       0.2501,  0.2307, -0.2987,  0.1962,  0.0043,  0.2886,  0.4032, -0.4570,\n                      -0.1794, -0.0113,  0.4064,  0.2442,  0.5680,  0.2878, -0.6325,  0.9868,\n                       0.6745, -0.0161,  0.6112,  0.2136, -1.0269, -0.5105,  0.7350, -0.4072,\n                      -0.3398,  0.4047,  0.7216, -0.2168, -0.1264, -0.1127,  0.1121, -0.5959,\n                       0.1432, -0.6723, -0.0015,  0.5402, -0.4234, -0.3389,  0.0123, -0.0837,\n                       1.1017,  1.2646, -0.1290,  0.0935,  0.6225, -1.3655, -0.0774, -0.1539,\n                       0.2061,  0.3864,  0.1217, -1.0770,  0.3006,  0.2481,  0.0502, -0.1064,\n                      -0.6839, -0.3205,  0.5506,  0.1442, -0.5492,  0.0647,  0.3305,  0.6579,\n                       0.2593, -0.4725, -0.0269, -0.3482, -0.0531, -1.2765,  0.3685,  0.5827,\n                       0.5541,  0.9741,  1.1137, -0.0083,  0.4487,  0.3200, -0.1427, -0.2225,\n                       0.1878,  0.5896,  0.2262,  0.3975,  0.2592,  0.0867, -0.4341,  1.0701],\n                     device='cuda:0')),\n             ('net.img_process.cnn.stacks.2.blocks.1.conv1.layer.weight',\n              tensor([[[[ 1.9452e-02,  2.2752e-02,  4.5778e-02],\n                        [-5.0320e-03, -4.0755e-03,  2.2271e-02],\n                        [ 6.1569e-03, -8.7428e-03, -4.2869e-03]],\n              \n                       [[ 6.5420e-03, -6.7173e-03, -1.3181e-02],\n                        [ 1.4751e-02, -2.3182e-03, -5.0675e-03],\n                        [ 8.6177e-04, -4.6708e-03, -1.7741e-02]],\n              \n                       [[ 9.2403e-03, -6.8107e-03,  6.3229e-03],\n                        [ 5.2279e-02,  2.4610e-02, -5.4163e-03],\n                        [-2.9512e-02, -2.5718e-02, -1.5082e-02]],\n              \n                       ...,\n              \n                       [[ 2.9070e-02,  3.2560e-02,  1.4131e-02],\n                        [-7.5998e-02, -4.5440e-02,  9.9199e-03],\n                        [ 3.2070e-03, -3.5948e-03,  2.2453e-02]],\n              \n                       [[-1.5986e-02, -1.7911e-03, -2.3907e-02],\n                        [ 3.5505e-03,  3.0717e-02, -1.3545e-02],\n                        [-1.0152e-02, -1.5648e-02, -4.2352e-02]],\n              \n                       [[ 1.9249e-02,  2.7676e-05,  8.6600e-03],\n                        [-6.1883e-03, -5.0114e-03,  8.9504e-03],\n                        [-1.7120e-03,  9.7162e-03, -2.9884e-03]]],\n              \n              \n                      [[[ 9.7170e-04, -1.1800e-02, -4.7297e-02],\n                        [ 2.3610e-02, -8.2625e-03, -4.9063e-02],\n                        [ 1.4424e-02,  1.5789e-02,  8.1719e-03]],\n              \n                       [[ 1.3856e-02,  1.0792e-02, -6.9544e-03],\n                        [ 2.8373e-02,  5.8813e-03, -4.1040e-02],\n                        [ 8.7543e-03,  5.8850e-03, -1.8744e-02]],\n              \n                       [[ 1.8973e-02, -2.7394e-02, -7.6748e-03],\n                        [-1.5647e-02,  9.4028e-03, -1.2749e-02],\n                        [ 1.8548e-02, -2.1757e-02, -4.3952e-02]],\n              \n                       ...,\n              \n                       [[ 7.1505e-03,  3.0766e-03, -1.4876e-02],\n                        [ 1.2684e-02, -8.4658e-03,  2.6248e-03],\n                        [ 9.4894e-03,  1.2941e-02, -2.6079e-03]],\n              \n                       [[-8.5275e-03, -5.9211e-02, -4.8957e-02],\n                        [ 2.1136e-03, -1.2836e-02,  4.7749e-02],\n                        [-7.5458e-03, -9.3328e-04,  2.1849e-02]],\n              \n                       [[-2.8614e-02,  7.1886e-03,  1.8674e-03],\n                        [-6.5134e-03, -1.1672e-03,  1.2838e-03],\n                        [-1.4849e-02,  2.3655e-02, -1.0103e-02]]],\n              \n              \n                      [[[ 9.4430e-03,  9.8045e-03,  3.6549e-02],\n                        [-1.5595e-03, -4.4741e-03,  9.4300e-03],\n                        [ 1.9430e-02,  2.1964e-02,  2.7516e-02]],\n              \n                       [[-4.3365e-03,  1.6802e-02, -2.9897e-03],\n                        [-3.5215e-02, -4.3032e-02, -4.0476e-02],\n                        [-2.3580e-02,  5.2383e-04,  1.0052e-02]],\n              \n                       [[-2.4885e-02,  4.6994e-02,  3.6116e-02],\n                        [ 4.4578e-03,  1.2688e-02, -7.8344e-03],\n                        [-1.3133e-02,  2.6578e-03,  2.6407e-02]],\n              \n                       ...,\n              \n                       [[-1.5468e-03, -2.1857e-02, -2.7710e-02],\n                        [ 6.2595e-03,  9.7228e-03, -1.2063e-02],\n                        [ 6.4902e-03,  1.3014e-03,  3.4061e-03]],\n              \n                       [[-3.7071e-02, -4.6706e-02, -2.6522e-02],\n                        [-9.5258e-03, -4.7063e-02, -2.4464e-02],\n                        [-1.0327e-02, -3.3492e-02, -4.2013e-02]],\n              \n                       [[ 8.1159e-03, -5.3598e-03, -1.0330e-02],\n                        [-5.1960e-04,  6.2162e-03,  2.4151e-02],\n                        [-8.3304e-04, -3.7289e-02, -1.5746e-02]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-2.4620e-02, -5.0801e-02, -1.9165e-03],\n                        [ 2.1875e-02,  7.9228e-04,  1.3893e-02],\n                        [ 4.0541e-02,  2.2557e-02,  6.6233e-02]],\n              \n                       [[-9.6119e-03,  1.0821e-02,  2.0559e-03],\n                        [-1.2155e-02,  1.3538e-03, -3.0248e-02],\n                        [ 6.6628e-03,  9.9455e-03, -8.9909e-03]],\n              \n                       [[ 6.3655e-02,  6.3462e-02,  4.9276e-02],\n                        [ 6.5810e-02,  9.3877e-02,  6.2181e-02],\n                        [ 1.7832e-02,  3.3597e-02,  7.6130e-03]],\n              \n                       ...,\n              \n                       [[-1.4113e-02, -1.1663e-02,  5.1030e-03],\n                        [ 2.9163e-03,  1.8424e-02, -1.9690e-02],\n                        [ 1.9129e-02,  1.3442e-02, -1.8799e-02]],\n              \n                       [[-1.6528e-03, -9.9045e-03,  1.3090e-02],\n                        [-3.3681e-02, -4.5891e-02, -2.4811e-02],\n                        [-4.9196e-02, -5.7493e-02, -3.9101e-02]],\n              \n                       [[-4.3279e-02, -2.4232e-02, -2.5572e-02],\n                        [ 1.0546e-02,  3.9228e-02, -2.0065e-02],\n                        [-3.2817e-02, -2.6606e-02, -1.9527e-02]]],\n              \n              \n                      [[[ 2.9466e-02,  4.7602e-02,  9.4382e-02],\n                        [-1.4664e-02, -3.6712e-02, -2.2110e-03],\n                        [-8.0918e-03, -1.8835e-02,  3.3810e-02]],\n              \n                       [[ 4.0978e-02,  4.6334e-02,  9.7522e-03],\n                        [ 1.0106e-01,  1.2397e-01,  1.2608e-01],\n                        [-6.0243e-02, -5.6856e-02, -4.4959e-02]],\n              \n                       [[-1.4478e-03, -4.0494e-02, -9.7690e-03],\n                        [ 9.3449e-04, -2.5337e-02, -1.0965e-02],\n                        [-7.4591e-03, -6.8969e-03,  1.0487e-02]],\n              \n                       ...,\n              \n                       [[-1.1827e-02,  7.2632e-03, -1.7528e-02],\n                        [-1.0477e-02,  8.0537e-03, -1.9574e-02],\n                        [ 6.2502e-03,  2.0845e-02,  1.9186e-03]],\n              \n                       [[ 3.8315e-03,  9.2490e-03,  2.9620e-03],\n                        [ 4.9647e-03,  1.6490e-03, -6.5481e-03],\n                        [ 3.0966e-02,  2.4877e-02,  4.8125e-02]],\n              \n                       [[ 3.2847e-02, -1.7498e-03,  1.0875e-02],\n                        [ 7.4500e-03,  1.7075e-02, -2.6615e-03],\n                        [ 4.4771e-02,  6.6500e-03,  8.7685e-03]]],\n              \n              \n                      [[[-3.7286e-02, -2.9301e-02, -2.8730e-02],\n                        [-3.5718e-03, -2.5405e-02, -4.1866e-02],\n                        [ 2.6064e-02,  2.8831e-02, -2.5200e-03]],\n              \n                       [[-1.6614e-03, -9.8810e-03, -2.0039e-02],\n                        [-2.4125e-02,  1.3953e-02, -2.4649e-02],\n                        [-9.9274e-03,  3.4298e-02,  2.3195e-02]],\n              \n                       [[-2.5318e-02, -1.0902e-02,  6.5895e-03],\n                        [ 3.6811e-02,  1.3193e-02,  3.9624e-02],\n                        [ 3.4808e-02,  3.7130e-03,  1.8085e-02]],\n              \n                       ...,\n              \n                       [[-2.2358e-04, -3.9937e-03,  4.5795e-03],\n                        [ 7.3894e-03,  2.8595e-02,  4.0971e-03],\n                        [ 4.5581e-03,  6.2260e-03, -6.8152e-03]],\n              \n                       [[-1.8369e-02, -4.0835e-02, -7.2612e-02],\n                        [ 5.6975e-03, -4.2009e-02,  3.4275e-02],\n                        [-5.8781e-03, -2.3149e-02,  3.5548e-02]],\n              \n                       [[ 3.4572e-01,  3.8345e-01,  3.5518e-01],\n                        [ 8.2103e-02,  1.9385e-01,  1.3169e-01],\n                        [-2.6472e-01, -1.2459e-01, -1.3281e-01]]]], device='cuda:0')),\n             ('net.img_process.cnn.dense.norm.weight',\n              tensor([1.1149, 1.0181, 0.9581,  ..., 1.2505, 1.2372, 1.2125], device='cuda:0')),\n             ('net.img_process.cnn.dense.norm.bias',\n              tensor([-0.0120,  0.0399,  0.0202,  ...,  0.0335, -0.0151, -0.0407],\n                     device='cuda:0')),\n             ('net.img_process.cnn.dense.layer.weight',\n              tensor([[-3.8752e-03, -1.3627e-02, -2.3952e-03,  ..., -1.2792e-03,\n                       -1.7554e-02, -1.5783e-02],\n                      [-6.8453e-03, -6.0212e-03, -5.4031e-03,  ...,  3.6299e-02,\n                        2.4568e-02,  2.5342e-02],\n                      [-7.2755e-03, -4.6890e-03, -1.5917e-02,  ...,  8.4896e-03,\n                        5.1825e-03,  1.9158e-03],\n                      ...,\n                      [ 1.8141e-02,  1.0152e-02,  8.3386e-03,  ..., -7.6103e-04,\n                        6.5709e-03,  2.0613e-03],\n                      [ 2.1509e-04,  6.7692e-05,  8.5174e-03,  ..., -1.2590e-02,\n                       -1.3490e-02, -8.0512e-03],\n                      [-8.4022e-03, -5.9111e-03, -4.6117e-03,  ...,  3.4430e-03,\n                       -9.4684e-03, -1.9172e-02]], device='cuda:0')),\n             ('net.img_process.linear.norm.weight',\n              tensor([0.8721, 1.2020, 0.8887, 1.2104, 1.1002, 1.5195, 1.0177, 1.0677, 0.8873,\n                      0.9983, 0.9168, 0.9214, 1.5977, 1.1271, 0.9959, 0.9706, 1.0313, 1.9556,\n                      1.1835, 0.9124, 0.9508, 1.0783, 1.0660, 0.9217, 0.7648, 0.9442, 0.8546,\n                      0.8933, 0.9142, 0.9389, 0.9351, 0.9699, 0.8488, 0.9022, 0.8715, 1.4614,\n                      0.6659, 0.9770, 1.0385, 1.3791, 0.9461, 0.9708, 0.8616, 1.0090, 0.8831,\n                      0.9862, 0.9803, 0.8815, 0.9506, 0.9321, 0.9404, 0.9061, 0.9151, 0.9077,\n                      0.9997, 0.6924, 0.8400, 0.9109, 1.0079, 0.9386, 1.1368, 0.7858, 0.8624,\n                      0.8823, 1.0378, 0.6593, 0.6293, 0.9784, 0.9747, 0.8503, 0.9864, 0.9045,\n                      1.1447, 0.9577, 0.9078, 1.1811, 0.9337, 1.3312, 1.0714, 1.2785, 0.9279,\n                      0.8215, 0.9150, 0.8860, 0.8366, 1.0186, 1.2753, 0.9740, 0.9517, 1.2596,\n                      1.3470, 0.9205, 0.9535, 0.9071, 1.0264, 0.8644, 1.1719, 1.5275, 0.9277,\n                      1.6239, 0.7925, 1.0269, 0.7758, 0.8521, 0.8768, 0.9440, 1.0638, 0.9257,\n                      0.8829, 1.0796, 1.2240, 0.9489, 0.9591, 0.9125, 1.0685, 0.9598, 0.9307,\n                      0.8460, 1.1515, 1.2256, 0.7520, 0.9518, 1.3155, 0.9172, 0.9892, 0.9026,\n                      1.0363, 0.9393, 1.4119, 0.9976, 0.8514, 0.6588, 1.3737, 0.8974, 0.9117,\n                      1.1548, 0.9702, 1.0339, 0.8549, 0.9003, 1.0090, 0.8847, 0.9622, 1.1351,\n                      1.0006, 0.8901, 1.0290, 1.2124, 0.8426, 1.5066, 0.8764, 1.0332, 0.9505,\n                      0.9863, 0.9234, 1.0401, 0.8669, 0.8992, 0.9580, 0.9509, 0.9104, 0.8541,\n                      0.9550, 0.8372, 0.8504, 0.9569, 0.9062, 0.7343, 1.0370, 0.9591, 0.9222,\n                      0.9567, 0.8916, 1.1477, 0.9883, 1.0281, 0.9594, 1.3528, 0.8718, 0.8595,\n                      0.9079, 0.9402, 0.8334, 0.7770, 0.9271, 1.6260, 1.4558, 1.0048, 1.0493,\n                      1.6039, 0.8520, 0.8929, 1.1022, 0.9300, 0.8897, 0.9076, 1.1273, 0.9208,\n                      0.9303, 0.7728, 0.8857, 0.7683, 0.9803, 1.0371, 0.9612, 1.0840, 1.0638,\n                      1.4297, 1.2173, 1.3540, 0.9299, 0.8815, 0.7763, 1.1204, 1.2633, 0.7869,\n                      0.6735, 0.9034, 0.9351, 1.0847, 0.9505, 0.9672, 1.0277, 1.0966, 0.9656,\n                      0.9418, 1.0160, 0.9654, 0.8637, 0.9053, 1.1868, 0.8892, 0.8466, 0.9473,\n                      1.0172, 0.8683, 0.9480, 0.9520, 1.2826, 0.9705, 0.7719, 1.0447, 0.9439,\n                      0.9444, 0.9804, 0.9201, 1.0066, 0.9263, 0.7062, 0.8650, 1.5564, 0.8308,\n                      1.1905, 0.9596, 0.9017, 0.9704], device='cuda:0')),\n             ('net.img_process.linear.norm.bias',\n              tensor([-1.8886e-01,  1.1200e+00, -1.4145e-01,  8.6280e-01,  4.9682e-01,\n                       2.3658e+00,  4.4291e-01,  4.9568e-01, -1.2529e-01,  2.0624e-01,\n                       9.0580e-04, -7.1647e-02,  1.5967e+00,  8.0628e-01,  2.7064e-01,\n                       1.0808e-01,  3.2753e-01,  1.9727e+00,  6.0781e-01, -1.1247e-01,\n                       9.9656e-02,  4.6460e-01,  5.3388e-01, -1.3341e-01, -5.0411e-01,\n                       6.9377e-02, -2.7735e-01, -7.9694e-02, -3.2262e-03,  4.8746e-02,\n                       5.3066e-02,  2.0868e-02, -5.6945e-01, -4.7346e-02, -1.2216e-01,\n                       1.5538e+00, -3.4643e-01,  1.4248e+00,  3.0875e-01,  2.2773e+00,\n                       1.2473e-02,  6.1269e-02, -9.0917e-02,  2.7053e-01, -1.9607e-01,\n                       7.9671e-02,  1.7697e-01, -2.1231e-02,  1.9867e-01, -1.6438e-02,\n                       4.8439e-04, -9.9744e-02, -1.4503e-01, -2.1718e-01,  9.5223e-02,\n                      -1.0737e+00, -1.1751e-01, -6.8484e-02,  1.4665e-01,  4.5319e-02,\n                       8.7965e-01, -6.2651e-01, -2.9335e-01, -1.0422e-01,  4.9556e-01,\n                      -8.1953e-01, -5.5047e-01,  9.8411e-02,  6.1801e-02, -1.5884e-01,\n                       4.6470e-02, -2.2985e-01,  5.6515e-01,  1.1620e-01, -1.3698e-01,\n                       1.6103e+00,  1.8919e-01,  1.3790e+00,  8.3397e-01,  1.6854e+00,\n                      -2.2719e-02, -3.6598e-01, -1.4396e-01, -2.5513e-01, -4.3128e-01,\n                       1.9245e-01,  9.2890e-01,  1.4922e-01,  9.9201e-02,  1.1978e+00,\n                       1.0590e+00, -1.4008e-01, -3.1291e-02,  1.5542e-01,  1.3018e-01,\n                      -1.5262e-01,  1.0253e+00,  1.7983e+00,  2.4349e-01,  2.5270e+00,\n                      -3.7790e-01,  3.7862e-01, -2.1047e-01, -1.2057e-01, -1.1291e-01,\n                      -1.3465e-02,  2.2794e-01, -3.6062e-02,  4.5096e-03,  2.9119e-01,\n                       1.5192e+00,  6.0650e-02,  1.2182e-01, -1.9290e-01,  5.0438e-01,\n                      -9.3538e-02,  5.8576e-02, -2.6990e-01,  5.5647e-01,  8.4337e-01,\n                      -5.7580e-01,  1.6111e-02,  2.2225e+00, -1.1181e-01,  9.5648e-02,\n                      -2.9348e-01,  2.7869e-01, -3.6145e-02,  2.0581e+00,  2.7206e-01,\n                      -1.8259e-01, -7.4744e-01,  2.1052e+00, -2.1854e-01, -7.3345e-02,\n                       6.5236e-01, -5.7063e-02,  2.6927e-01, -1.7878e-01, -1.6402e-01,\n                       4.9111e-01,  2.1701e-02,  8.8614e-02,  1.5647e+00,  1.7747e-01,\n                      -1.9607e-01,  3.2652e-01,  1.1548e+00, -2.6356e-01,  2.4390e+00,\n                      -1.3418e-02,  6.3086e-01,  1.2375e-01,  3.5641e-01, -6.7471e-02,\n                       3.7524e-01, -1.1251e-01, -9.2224e-02, -7.2554e-02,  1.1212e-01,\n                       3.2934e-01, -3.8822e-01, -1.7070e-02, -3.9075e-01, -3.4081e-01,\n                       2.7272e-02, -6.9832e-02,  5.8655e-01,  6.0452e-01,  1.2033e-01,\n                      -5.1059e-02,  8.7384e-02,  4.8342e-01,  5.7073e-01,  1.7633e-01,\n                       2.0353e-01,  4.8685e-02,  2.1453e+00, -1.0038e-01, -4.3717e-02,\n                      -9.9923e-02,  1.1608e-01, -1.8689e-01, -2.9711e-01,  9.1413e-03,\n                       2.2080e+00,  1.9860e+00,  1.1212e-01,  6.4661e-01,  2.2400e+00,\n                      -1.2519e-01, -8.4637e-02,  4.6036e-01, -1.8331e-01, -1.4916e-01,\n                      -9.8533e-02,  8.8961e-01, -7.7513e-02,  3.0339e-04, -4.4720e-01,\n                      -2.0115e-01, -6.6114e-01,  8.0386e-02,  3.0490e-01,  3.6931e-01,\n                       6.6808e-01,  3.0539e-01,  2.0248e+00,  1.8458e+00,  1.8757e+00,\n                      -1.4897e-01, -2.2592e-01, -9.5344e-01,  3.0051e-01,  9.6172e-01,\n                      -2.2636e-01, -4.5023e-01, -2.0259e-02, -7.8208e-02,  8.7538e-01,\n                       4.2933e-02,  7.8789e-03,  3.2009e-01,  5.0810e-01,  7.4768e-02,\n                       6.3969e-02,  4.2482e-01,  4.9939e-02, -1.5085e-01, -1.9676e-02,\n                       9.3316e-01, -1.3268e-01, -2.9743e-01,  7.5474e-02,  2.1260e-01,\n                      -2.4534e-01,  1.5806e-01, -8.9093e-02,  1.5901e+00,  2.2181e-01,\n                       8.6075e-02,  3.4319e-01,  1.1367e-01, -1.2606e-02,  6.9852e-02,\n                      -3.0770e-02,  1.2036e-01,  3.7865e-01, -1.0853e+00, -9.1264e-02,\n                       2.4444e+00, -6.8575e-01,  1.6625e+00,  1.3882e-01,  9.6159e-04,\n                       7.3805e-02], device='cuda:0')),\n             ('net.img_process.linear.layer.weight',\n              tensor([[ 0.0116,  0.1088, -0.0187,  ..., -0.0347, -0.0917,  0.0552],\n                      [-0.0019,  0.0020,  0.0094,  ...,  0.0114,  0.0100,  0.0061],\n                      [ 0.0271,  0.0079,  0.0136,  ...,  0.0047,  0.0019, -0.0031],\n                      ...,\n                      [-0.0176,  0.0403,  0.0082,  ...,  0.0038, -0.0009,  0.0189],\n                      [ 0.0100,  0.0955, -0.0119,  ...,  0.0231,  0.0193, -0.0100],\n                      [ 0.0046,  0.0375,  0.0327,  ...,  0.0053, -0.0137,  0.0050]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.mlp0.norm.weight',\n              tensor([2.4212, 1.2190, 1.6792,  ..., 1.6354, 3.0727, 2.2137], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.mlp0.norm.bias',\n              tensor([-0.1612,  0.2921, -0.0180,  ...,  0.0568, -0.0038, -0.3224],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.mlp0.layer.weight',\n              tensor([[ 0.0155, -0.0077, -0.0072,  ...,  0.0063, -0.0010, -0.0026],\n                      [-0.0071,  0.0077, -0.0182,  ..., -0.0081,  0.0123, -0.0018],\n                      [ 0.0078,  0.0008,  0.0050,  ..., -0.0075, -0.0202, -0.0147],\n                      ...,\n                      [ 0.0019, -0.0066,  0.0035,  ...,  0.0014, -0.0052,  0.0047],\n                      [ 0.0009,  0.0062,  0.0030,  ..., -0.0097, -0.0073,  0.0230],\n                      [ 0.0075, -0.0037, -0.0156,  ...,  0.0053,  0.0104, -0.0153]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.mlp1.layer.weight',\n              tensor([[-0.0303,  0.0281,  0.0012,  ..., -0.0024, -0.0021, -0.0219],\n                      [-0.0010, -0.0038,  0.0036,  ...,  0.0121, -0.0013,  0.0040],\n                      [-0.0016,  0.0038, -0.0044,  ..., -0.0121, -0.0110,  0.0120],\n                      ...,\n                      [ 0.0074, -0.0018,  0.0123,  ..., -0.0146,  0.0027, -0.0037],\n                      [ 0.0108, -0.0177,  0.0215,  ..., -0.0067,  0.0214,  0.0122],\n                      [ 0.0068,  0.0072,  0.0107,  ...,  0.0122,  0.0002,  0.0106]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.mlp1.layer.bias',\n              tensor([ 0.0512, -0.5490,  0.3932,  ...,  0.2716, -0.3185,  0.0253],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.pre_r_ln.weight',\n              tensor([2.5369, 0.3847, 1.1848,  ..., 1.3565, 2.1369, 2.0305], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.pre_r_ln.bias',\n              tensor([-0.1464,  0.0602,  0.1955,  ...,  0.2900, -0.7534, -0.1285],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.b_nd',\n              tensor([[-0.0293, -0.0270, -0.0244,  ..., -0.0053, -0.0022,  0.0199],\n                      [ 0.0072, -0.0076, -0.0058,  ...,  0.0203,  0.0436,  0.2055],\n                      [-0.0633, -0.0555, -0.0404,  ...,  0.0309,  0.0320,  0.0237],\n                      ...,\n                      [-0.0212, -0.0091, -0.0155,  ..., -0.0155,  0.0049,  0.0391],\n                      [ 0.0159,  0.0628,  0.0031,  ..., -0.0988, -0.0921, -0.0671],\n                      [ 0.0697,  0.0524,  0.0486,  ..., -0.0766, -0.0568, -0.0127]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.q_layer.weight',\n              tensor([[-9.7730e-03, -2.6714e-05,  7.0852e-04,  ..., -5.2313e-04,\n                        6.7122e-04, -1.2025e-03],\n                      [-9.2767e-03,  1.0574e-04, -8.5173e-04,  ..., -1.2305e-03,\n                       -9.0127e-03, -4.1638e-03],\n                      [-3.4770e-03,  3.2482e-05,  3.8111e-05,  ..., -7.5134e-04,\n                       -1.0003e-02,  4.1757e-04],\n                      ...,\n                      [ 1.4070e-03, -9.9383e-05, -3.5279e-04,  ..., -3.3181e-04,\n                       -3.4998e-03, -3.2480e-04],\n                      [-4.8872e-04,  2.1165e-06,  3.9234e-04,  ...,  2.8793e-04,\n                        4.3841e-03,  5.5261e-04],\n                      [ 1.9164e-03, -1.0641e-04, -7.0247e-05,  ..., -6.4552e-05,\n                        5.1282e-04, -4.1643e-04]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.q_layer.bias',\n              tensor([-0.0064,  0.0023,  0.0087,  ...,  0.0389, -0.0185,  0.0240],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.k_layer.weight',\n              tensor([[-1.3939e-02, -4.0314e-04,  2.6465e-03,  ..., -1.7836e-04,\n                        1.7717e-02, -1.6752e-03],\n                      [-1.8057e-02,  5.6422e-04, -9.9097e-04,  ..., -4.0953e-04,\n                       -2.1719e-02, -3.7310e-03],\n                      [-4.9624e-03,  5.7769e-05,  1.9813e-03,  ...,  1.3296e-04,\n                       -4.3896e-03,  6.3796e-03],\n                      ...,\n                      [ 1.5152e-03, -6.3277e-05, -5.2158e-04,  ..., -1.7693e-04,\n                        2.4759e-03,  1.0218e-03],\n                      [-1.5918e-03, -1.2930e-04, -2.2567e-04,  ..., -6.0635e-04,\n                       -1.4912e-03, -1.8417e-03],\n                      [-1.0553e-03, -3.2904e-04, -9.7016e-04,  ..., -7.0011e-04,\n                        2.3172e-03, -1.1374e-03]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.v_layer.weight',\n              tensor([[ 1.1208e-02, -2.2348e-03, -1.6770e-03,  ..., -5.5146e-03,\n                       -1.2768e-02,  9.5792e-03],\n                      [-3.0890e-02, -2.5207e-03,  5.1537e-03,  ...,  1.9049e-03,\n                       -3.4791e-02,  1.4036e-02],\n                      [ 1.7952e-02, -4.5622e-04,  2.0148e-03,  ..., -4.0884e-03,\n                       -1.3338e-02,  1.8476e-04],\n                      ...,\n                      [-4.5342e-03,  1.3089e-04,  5.4486e-04,  ...,  1.5664e-03,\n                       -2.0487e-02,  1.7105e-03],\n                      [-6.9795e-04, -1.4786e-05, -2.8918e-04,  ...,  1.0605e-03,\n                        9.5711e-04, -7.6975e-03],\n                      [ 4.6665e-04, -1.1364e-04,  2.2989e-05,  ...,  2.8981e-03,\n                       -5.5302e-03, -2.2091e-03]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.proj_layer.weight',\n              tensor([[ 0.0011, -0.0205, -0.0090,  ..., -0.0080,  0.0021, -0.0019],\n                      [-0.0158,  0.0287, -0.0094,  ..., -0.0034, -0.0020,  0.0003],\n                      [-0.0215, -0.0091, -0.0214,  ..., -0.0037, -0.0118,  0.0024],\n                      ...,\n                      [-0.0253, -0.0031, -0.0162,  ..., -0.0018, -0.0093,  0.0043],\n                      [ 0.0140, -0.0167, -0.0121,  ...,  0.0141, -0.0094,  0.0116],\n                      [-0.0430, -0.0027, -0.0256,  ..., -0.0081,  0.0092, -0.0045]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.proj_layer.bias',\n              tensor([-0.1061, -0.3191,  0.4209,  ...,  0.3422, -0.5989, -0.2396],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.r_layer.weight',\n              tensor([[ 8.7254e-03,  1.7422e-04,  5.4396e-04,  ...,  3.4168e-03,\n                        1.0191e-03, -6.5512e-03],\n                      [ 5.1723e-03, -1.4175e-04, -1.9993e-03,  ...,  3.2856e-05,\n                        1.1912e-03, -1.3003e-03],\n                      [-1.0419e-02, -1.6864e-03, -9.2822e-04,  ..., -2.9948e-03,\n                        3.9241e-02,  3.5778e-03],\n                      ...,\n                      [ 4.2685e-03,  6.7057e-06, -3.0868e-04,  ...,  1.3850e-03,\n                        1.7087e-03, -2.5913e-03],\n                      [ 4.6679e-03, -2.1593e-04,  5.1049e-04,  ...,  1.2524e-03,\n                       -4.4432e-03, -8.4428e-03],\n                      [-2.6647e-03, -2.0384e-04,  2.2730e-03,  ...,  4.9242e-04,\n                       -1.0724e-02, -6.3924e-04]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.0.r.orc_block.r_layer.bias',\n              tensor([-4.6222e-01, -5.4916e-01, -1.1139e+00, -1.1014e-01,  1.0535e+00,\n                       1.4623e+00,  3.5431e-01, -2.2997e-01,  9.1647e-01,  6.1271e-01,\n                      -4.5574e-02,  9.0482e-03,  4.3559e-02,  2.2961e-02, -6.8419e-02,\n                       7.3444e-02,  8.8126e-03, -7.6009e-02, -8.7431e-02, -2.9139e-02,\n                      -1.1738e-01, -3.6596e-02, -5.5385e-02,  7.0580e-02,  1.0452e-01,\n                       2.0677e-01,  7.5294e-02, -3.3470e-02,  5.5614e-02, -6.7548e-02,\n                      -1.5291e-01, -1.4147e-01, -2.3937e-01, -1.1537e-01,  1.4637e-01,\n                       3.0585e-01,  4.2686e-02, -1.0528e-01,  1.5654e-01,  1.3402e-01,\n                      -4.2681e-01, -3.9485e-01, -6.1441e-01, -1.0425e-01,  4.3588e-01,\n                       8.2655e-01,  2.3301e-01, -8.7938e-02,  4.1195e-01,  2.8079e-01,\n                      -6.9772e-02, -4.0181e-02, -1.1546e-01, -1.1219e-01, -2.2196e-03,\n                       1.5635e-01, -1.6666e-02, -1.0698e-01,  3.4373e-03,  1.5299e-01,\n                      -5.7510e-02, -9.3803e-02, -1.2503e-01, -1.2845e-01, -6.0468e-02,\n                       2.2870e-01,  2.7282e-02, -1.2489e-01, -3.6189e-02,  1.0339e-01,\n                      -7.5550e-02, -3.2259e-03, -3.9576e-02,  8.7623e-02,  3.5763e-02,\n                       1.3421e-01,  1.1950e-01, -9.9160e-04,  3.7075e-02, -1.0425e-01,\n                      -8.2960e-02,  2.3297e-02,  5.6170e-02,  4.1265e-02,  3.1549e-02,\n                       8.5119e-02,  3.8193e-02, -2.0437e-02,  6.5459e-02, -6.9482e-02,\n                      -1.5291e+00, -5.5969e-01, -1.1163e+00,  1.2147e-01,  2.4611e+00,\n                       1.4833e+00,  5.0693e-01,  3.3194e-01,  3.7619e+00,  3.2514e-01,\n                      -2.7382e-02, -2.9642e-04, -1.3124e-02,  4.1651e-02, -3.9127e-02,\n                       6.5907e-02,  6.6070e-02, -2.0279e-02, -7.1489e-02, -6.4148e-02,\n                      -6.7205e-03,  3.3916e-02,  4.3465e-02,  6.6205e-02, -7.5967e-02,\n                       9.4624e-03,  6.9961e-02,  2.0203e-02, -9.2669e-02, -1.2172e-01,\n                       2.9558e-02,  4.6661e-02,  9.1146e-02,  8.3082e-02, -9.4576e-02,\n                      -3.2989e-02,  5.0995e-02,  2.7352e-02, -1.1134e-01, -1.3190e-01,\n                      -6.1230e-02, -2.8756e-02, -2.4869e-02, -4.5159e-02, -4.3883e-02,\n                       9.9217e-02, -1.5486e-02, -5.8006e-02, -2.9138e-02,  2.8374e-02,\n                      -3.7258e-02, -1.0432e-02, -7.5735e-02, -5.5172e-02, -5.6798e-02,\n                       1.1177e-01,  4.2027e-02, -3.4462e-02, -5.7017e-02,  5.1567e-02,\n                      -1.3024e-01, -1.0942e-01, -1.5549e-01, -1.4721e-01, -2.4170e-02,\n                       2.7621e-01,  1.9800e-02, -1.6074e-01, -3.3205e-03,  1.7973e-01],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.mlp0.norm.weight',\n              tensor([2.8476, 2.3439, 2.6354,  ..., 2.1627, 2.3535, 2.5762], device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.mlp0.norm.bias',\n              tensor([-0.0650,  0.3201, -0.1280,  ..., -0.2373, -0.1555, -0.1279],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.mlp0.layer.weight',\n              tensor([[-0.0019,  0.0117,  0.0123,  ..., -0.0058, -0.0024, -0.0025],\n                      [-0.0312,  0.0208,  0.0138,  ...,  0.0110,  0.0022, -0.0145],\n                      [-0.0096, -0.0030, -0.0229,  ...,  0.0006,  0.0615, -0.0114],\n                      ...,\n                      [-0.0190, -0.0186,  0.0030,  ..., -0.0074,  0.0398, -0.0227],\n                      [-0.0077, -0.0079, -0.0010,  ..., -0.0058, -0.0148,  0.0113],\n                      [-0.0118, -0.0176, -0.0118,  ...,  0.0020,  0.0345, -0.0005]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.mlp1.layer.weight',\n              tensor([[-0.0076,  0.0147,  0.0118,  ..., -0.0098,  0.0031,  0.0032],\n                      [-0.0048, -0.0456, -0.0071,  ..., -0.0112, -0.0067,  0.0091],\n                      [-0.0383, -0.0061, -0.0145,  ...,  0.0207, -0.0169,  0.0095],\n                      ...,\n                      [-0.0167, -0.0103,  0.0064,  ..., -0.0097, -0.0108, -0.0108],\n                      [-0.0041,  0.0107, -0.0343,  ..., -0.0027,  0.0029,  0.0072],\n                      [ 0.0094,  0.0065, -0.0021,  ..., -0.0095,  0.0183,  0.0102]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.mlp1.layer.bias',\n              tensor([ 0.0908, -0.1588,  0.0682,  ...,  0.3015,  0.0434,  0.0913],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.pre_r_ln.weight',\n              tensor([1.8315, 0.9714, 1.3735,  ..., 0.9400, 2.4194, 1.4948], device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.pre_r_ln.bias',\n              tensor([ 0.2120,  0.4294, -0.2640,  ..., -0.0918,  0.0175, -0.1348],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.b_nd',\n              tensor([[ 0.0119, -0.0405,  0.0330,  ...,  0.1689,  0.1833,  0.1952],\n                      [ 0.0859,  0.0521,  0.0004,  ..., -0.0432, -0.0411, -0.0439],\n                      [ 0.0822,  0.0277, -0.0052,  ..., -0.0304, -0.0583, -0.0697],\n                      ...,\n                      [-0.0487,  0.0460,  0.0816,  ..., -0.1626, -0.1614, -0.1752],\n                      [ 0.0901,  0.0054, -0.0039,  ..., -0.0137, -0.0098, -0.0240],\n                      [-0.0707,  0.0923, -0.0123,  ...,  0.0671,  0.0662,  0.0803]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.q_layer.weight',\n              tensor([[-3.7179e-03,  2.9129e-03,  4.2811e-04,  ..., -1.6013e-03,\n                       -1.6004e-02,  2.6525e-03],\n                      [ 3.2850e-03,  3.0451e-03,  6.2180e-04,  ..., -1.1693e-03,\n                        8.3075e-03,  5.5904e-04],\n                      [-1.1913e-02, -8.6790e-03,  1.3843e-03,  ...,  1.0031e-02,\n                        8.6719e-03,  1.5714e-03],\n                      ...,\n                      [ 8.7957e-03,  1.9339e-03, -4.4278e-03,  ...,  2.3910e-03,\n                       -8.1474e-03, -2.2514e-03],\n                      [-6.7652e-04, -7.8054e-04,  1.1712e-03,  ..., -1.2574e-03,\n                        8.9916e-03,  7.8833e-06],\n                      [-4.9998e-04,  6.3168e-04,  1.1852e-03,  ...,  7.8308e-04,\n                       -6.2094e-03, -5.5047e-03]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.q_layer.bias',\n              tensor([-0.0427,  0.0272, -0.0103,  ...,  0.0901, -0.0479, -0.0347],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.k_layer.weight',\n              tensor([[-1.7301e-02,  3.4485e-03,  2.1337e-03,  ..., -4.3306e-03,\n                        7.7964e-03,  2.9220e-03],\n                      [ 6.4063e-03,  1.0645e-03,  4.2657e-03,  ...,  2.2215e-04,\n                        1.4548e-02,  1.8163e-03],\n                      [ 1.3934e-03, -1.3807e-03, -3.8534e-04,  ...,  1.9474e-03,\n                       -3.6121e-02,  4.1079e-03],\n                      ...,\n                      [ 1.7432e-03,  3.9247e-03, -8.8883e-05,  ..., -1.6020e-03,\n                        3.6886e-02, -1.7930e-03],\n                      [ 4.2643e-05,  5.3541e-05, -1.6891e-03,  ..., -1.1228e-03,\n                        7.6301e-03, -3.9559e-03],\n                      [ 4.8594e-03, -1.1158e-03,  4.7153e-03,  ...,  1.3359e-03,\n                        5.9555e-03, -4.4363e-03]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.v_layer.weight',\n              tensor([[-0.0101, -0.0059,  0.0062,  ..., -0.0008, -0.0055, -0.0291],\n                      [-0.0118, -0.0010,  0.0031,  ...,  0.0106, -0.0065, -0.0136],\n                      [ 0.0047,  0.0011, -0.0150,  ..., -0.0086, -0.0027,  0.0024],\n                      ...,\n                      [-0.0273,  0.0026,  0.0004,  ..., -0.0026, -0.0076, -0.0010],\n                      [-0.0157,  0.0088, -0.0035,  ..., -0.0078, -0.0319, -0.0034],\n                      [-0.0143, -0.0007,  0.0094,  ...,  0.0041, -0.0173,  0.0002]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.proj_layer.weight',\n              tensor([[-0.0003,  0.0136,  0.0008,  ...,  0.0156,  0.0053,  0.0090],\n                      [-0.0104,  0.0153, -0.0090,  ..., -0.0075, -0.0101,  0.0149],\n                      [ 0.0170,  0.0037,  0.0083,  ...,  0.0003, -0.0053, -0.0059],\n                      ...,\n                      [ 0.0040, -0.0070,  0.0200,  ..., -0.0060,  0.0008, -0.0126],\n                      [ 0.0042,  0.0016, -0.0167,  ...,  0.0126,  0.0053,  0.0079],\n                      [ 0.0127,  0.0013,  0.0001,  ...,  0.0062,  0.0064, -0.0219]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.proj_layer.bias',\n              tensor([ 0.0804, -0.3177,  0.2635,  ...,  0.1214,  0.0517,  0.0495],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.r_layer.weight',\n              tensor([[-0.0107,  0.0096, -0.0052,  ..., -0.0052,  0.0235, -0.0035],\n                      [ 0.0123,  0.0010,  0.0028,  ...,  0.0143,  0.0012,  0.0013],\n                      [ 0.0141,  0.0004,  0.0126,  ...,  0.0097,  0.0076,  0.0045],\n                      ...,\n                      [-0.0021,  0.0047, -0.0025,  ..., -0.0065, -0.0434,  0.0047],\n                      [-0.0058,  0.0018, -0.0040,  ..., -0.0071,  0.0521,  0.0300],\n                      [-0.0199,  0.0044, -0.0090,  ..., -0.0106, -0.0113,  0.0116]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.1.r.orc_block.r_layer.bias',\n              tensor([-1.2039,  1.9137,  1.1195,  1.6584, -2.1141, -0.2072, -1.4004,  1.6835,\n                       1.3656,  2.4353, -1.3570,  2.1304,  0.7968,  1.3091, -1.5208, -0.3097,\n                      -0.9571,  0.9998,  1.3536,  3.0562, -0.1190, -0.2267, -0.2808,  0.4282,\n                      -0.4281,  0.6068,  0.0039,  0.3743,  0.0633, -0.1312, -0.6475,  1.7325,\n                       1.1729,  1.4567, -1.3787, -0.3064, -1.2140,  0.7183,  1.3365,  1.5950,\n                       0.1513, -0.1178, -0.2428, -0.1441,  0.0426,  0.0049,  0.0260, -0.1286,\n                      -0.1623,  0.0453,  0.3996, -0.0989, -0.0915,  0.0491, -0.3110,  0.2475,\n                      -0.0847,  0.1816, -0.1345,  0.0885, -0.2694, -0.1431, -0.1324, -0.0942,\n                      -0.0869,  0.1470, -0.0132,  0.2435, -0.2242, -0.2048, -0.2916,  0.2053,\n                       0.1890,  0.3637, -0.4888,  0.2717, -0.2522,  0.4946, -0.1318,  0.2931,\n                      -0.6049,  0.9206,  0.2710,  0.8457, -1.0798,  0.1744, -0.4807,  0.9379,\n                       0.3537,  1.6999, -0.2508,  0.5409,  0.1455,  0.5804, -0.9476,  0.2247,\n                      -0.4123,  0.8364,  0.2078,  1.4708, -0.3889, -0.1512, -0.2216, -0.1062,\n                      -0.0383, -0.0146,  0.0135,  0.2293, -0.2794, -0.3178, -0.0864, -0.0571,\n                      -0.0958, -0.1395,  0.0460, -0.1069,  0.0431,  0.0131, -0.0296, -0.2318,\n                      -0.0938,  0.3387,  0.4724,  0.1755,  0.1380, -0.3184, -0.3353, -0.3560,\n                       0.4878, -0.5987,  0.2464,  0.1321,  0.1950, -0.0853,  0.1457, -0.1413,\n                       0.0636, -0.2937,  0.2061, -0.1844, -0.1825, -0.1065,  0.2683,  0.3338,\n                      -0.4196,  0.5324, -0.2146,  0.8008, -0.2353, -0.0525, -0.1264, -0.0108,\n                       0.0354,  0.3206, -0.3515,  0.2598, -0.2061,  0.4135, -0.0833,  0.0987],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.mlp0.norm.weight',\n              tensor([3.3840, 2.7711, 3.5302,  ..., 2.8213, 2.5680, 3.0578], device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.mlp0.norm.bias',\n              tensor([-0.0468,  0.0710,  0.0912,  ..., -0.3249, -0.1015,  0.0675],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.mlp0.layer.weight',\n              tensor([[-0.0023,  0.0052, -0.0084,  ...,  0.0037,  0.0105, -0.0062],\n                      [-0.0062, -0.0175,  0.0057,  ..., -0.0089, -0.0372,  0.0175],\n                      [ 0.0189,  0.0030,  0.0073,  ...,  0.0119, -0.0484,  0.0193],\n                      ...,\n                      [-0.0272,  0.0186,  0.0017,  ...,  0.0069, -0.0118, -0.0525],\n                      [ 0.0244, -0.0265,  0.0100,  ..., -0.0012,  0.0344, -0.0032],\n                      [ 0.0144, -0.0176, -0.0227,  ..., -0.0100,  0.0111,  0.0111]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.mlp1.layer.weight',\n              tensor([[-0.0010, -0.0011, -0.0069,  ...,  0.0335,  0.0065, -0.0174],\n                      [ 0.0066, -0.0068,  0.0016,  ...,  0.0153, -0.0033, -0.0059],\n                      [-0.0007,  0.0124, -0.0156,  ..., -0.0174, -0.0110,  0.0006],\n                      ...,\n                      [-0.0081,  0.0260,  0.0237,  ...,  0.0179,  0.0175,  0.0254],\n                      [ 0.0221,  0.0094, -0.0449,  ..., -0.0477, -0.0022, -0.0080],\n                      [ 0.0228,  0.0093,  0.0074,  ...,  0.0038,  0.0031, -0.0145]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.mlp1.layer.bias',\n              tensor([ 0.1217, -0.2700, -0.1845,  ...,  0.3319,  0.1265,  0.0236],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.pre_r_ln.weight',\n              tensor([1.0975, 1.1229, 0.8679,  ..., 1.1938, 1.1878, 1.0880], device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.pre_r_ln.bias',\n              tensor([ 0.4141,  0.0775, -0.1672,  ..., -0.2260,  0.0157,  0.2572],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.b_nd',\n              tensor([[-0.0367, -0.1477, -0.0930,  ...,  0.2185,  0.2211,  0.2325],\n                      [ 0.0861,  0.1847,  0.2289,  ...,  0.0423,  0.0649,  0.1407],\n                      [-0.1580, -0.1206,  0.1445,  ...,  0.1129,  0.1229,  0.1509],\n                      ...,\n                      [-0.3097,  0.0793,  0.2012,  ...,  0.0064, -0.0232, -0.0554],\n                      [-0.1001, -0.1489, -0.1116,  ...,  0.0781,  0.0444, -0.0215],\n                      [ 0.1696,  0.1667,  0.2112,  ..., -0.1125, -0.1527, -0.1973]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.q_layer.weight',\n              tensor([[-4.1280e-03,  3.9300e-03,  9.1228e-04,  ...,  2.4050e-03,\n                        1.1090e-02, -1.4396e-03],\n                      [-2.1825e-03, -1.5881e-03,  1.2108e-03,  ...,  6.5750e-04,\n                       -5.1445e-03, -3.1526e-03],\n                      [-2.3673e-03,  1.6427e-03,  2.8946e-03,  ...,  3.6648e-04,\n                       -1.2029e-03, -1.1279e-03],\n                      ...,\n                      [-3.0431e-03,  8.1133e-04,  1.8614e-03,  ...,  3.4269e-03,\n                        1.2509e-02, -3.3647e-04],\n                      [ 4.3409e-05,  2.1153e-03, -1.4053e-03,  ..., -4.3860e-04,\n                        2.0719e-02, -6.0453e-04],\n                      [-1.2275e-03, -6.4864e-04, -2.7279e-04,  ...,  1.8740e-03,\n                        2.3469e-03,  1.1988e-04]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.q_layer.bias',\n              tensor([-0.0044,  0.0247,  0.0928,  ..., -0.0831,  0.0048,  0.0390],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.k_layer.weight',\n              tensor([[ 0.0059,  0.0017, -0.0022,  ..., -0.0021, -0.0155,  0.0002],\n                      [ 0.0041,  0.0071, -0.0015,  ..., -0.0012,  0.0018,  0.0012],\n                      [ 0.0066,  0.0086, -0.0039,  ..., -0.0024,  0.0101, -0.0002],\n                      ...,\n                      [-0.0009,  0.0033,  0.0011,  ..., -0.0011, -0.0150, -0.0010],\n                      [ 0.0023, -0.0012,  0.0013,  ...,  0.0047, -0.0024, -0.0013],\n                      [-0.0020,  0.0008,  0.0017,  ..., -0.0029, -0.0012, -0.0011]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.v_layer.weight',\n              tensor([[ 0.0312,  0.0098, -0.0087,  ..., -0.0272, -0.0159, -0.0120],\n                      [ 0.0226,  0.0166, -0.0052,  ...,  0.0001,  0.0167, -0.0177],\n                      [-0.0112, -0.0104,  0.0181,  ..., -0.0027,  0.0293,  0.0273],\n                      ...,\n                      [-0.0139, -0.0103, -0.0248,  ..., -0.0125,  0.0094, -0.0026],\n                      [ 0.0413, -0.0050, -0.0165,  ...,  0.0043,  0.0216, -0.0207],\n                      [-0.0152, -0.0026, -0.0090,  ..., -0.0135, -0.0067,  0.0033]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.proj_layer.weight',\n              tensor([[-1.0577e-02, -1.2099e-02,  2.9528e-02,  ...,  4.1036e-02,\n                       -1.6226e-02,  1.3887e-02],\n                      [ 2.2640e-02, -2.9516e-03,  1.2236e-02,  ..., -1.2431e-02,\n                        2.0762e-02, -3.4519e-02],\n                      [ 9.8195e-05, -5.6464e-03, -8.9039e-03,  ...,  6.1400e-03,\n                       -1.0963e-02,  1.4338e-02],\n                      ...,\n                      [-1.0849e-03,  8.5541e-03,  1.7962e-03,  ...,  1.0250e-02,\n                        2.0080e-03,  5.4907e-03],\n                      [-1.1940e-03, -3.6965e-02, -2.3883e-03,  ...,  1.2252e-02,\n                       -8.3432e-03, -8.0218e-03],\n                      [ 2.8599e-02,  1.1449e-02, -9.6420e-03,  ..., -1.2992e-02,\n                        5.0019e-02, -1.9117e-02]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.proj_layer.bias',\n              tensor([ 0.1254, -0.2171,  0.0146,  ...,  0.0143,  0.1408,  0.0972],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.r_layer.weight',\n              tensor([[-0.0055,  0.0142,  0.0059,  ...,  0.0061,  0.0193, -0.0057],\n                      [ 0.0191, -0.0145, -0.0085,  ..., -0.0115, -0.0096,  0.0071],\n                      [-0.0119,  0.0324,  0.0002,  ..., -0.0109,  0.0359,  0.0124],\n                      ...,\n                      [-0.0108, -0.0192,  0.0136,  ..., -0.0056, -0.0041,  0.0027],\n                      [-0.0090,  0.0203,  0.0092,  ...,  0.0051, -0.0049,  0.0009],\n                      [-0.0062, -0.0239,  0.0037,  ..., -0.0200,  0.0086, -0.0060]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.2.r.orc_block.r_layer.bias',\n              tensor([-0.0737,  0.1046, -0.2281, -0.4478,  0.0368, -0.1379, -0.0611, -0.4709,\n                      -0.3583,  0.2079,  0.3147, -0.1020,  0.1555, -0.1558,  0.0257,  0.0881,\n                       0.0485,  0.0242,  0.3608, -0.0794,  0.1793,  0.0345, -0.1702, -0.4395,\n                       0.1940, -0.1357, -0.0417, -0.3546, -0.0431,  0.1414, -0.0336, -0.1635,\n                      -0.3471,  0.0043, -0.2351,  0.1470,  0.1672, -0.1030,  0.2280, -0.4611,\n                      -0.4639,  0.3620, -0.2009,  0.4836,  0.3407, -0.4115, -0.2754,  0.4590,\n                      -0.6092,  0.1112, -0.3368,  0.1812,  0.1185,  0.4425, -0.4616,  0.2280,\n                      -0.0415,  0.0977, -0.0808, -0.0704, -0.7377,  1.7437,  1.0730,  0.6982,\n                      -0.2434,  0.4963, -0.1910, -0.9247, -0.6604,  0.7104, -1.0082,  0.8216,\n                      -0.2427, -0.2156, -0.1748, -0.5202, -0.7328,  0.0084, -1.1854,  0.5937,\n                      -1.7829,  1.5759, -1.2649,  0.8465,  1.4387, -1.8325, -1.4516,  1.1083,\n                      -2.2987,  0.6482, -1.1451,  1.5130,  0.6948, -0.9738, -0.7818,  0.2734,\n                      -1.0468,  1.7817, -0.8165,  1.1813, -0.8384, -0.8480,  0.3932,  0.3006,\n                      -0.9070, -0.0381,  0.1783, -0.0688, -1.1041,  0.0972, -0.0523,  0.1081,\n                      -0.2260, -0.4563,  0.0392, -0.1437, -0.0632, -0.4595, -0.3443,  0.2085,\n                      -0.1297,  0.1554, -0.1483, -0.3178,  0.0295, -0.1301, -0.0611, -0.2544,\n                      -0.3235,  0.1972, -0.1893, -0.0392, -0.2472, -0.1121, -0.2949,  0.0333,\n                       0.0644, -0.1997, -0.2971, -0.0134,  0.4068, -0.1122,  0.3147,  0.0513,\n                       0.2361,  0.1307,  0.1885, -0.2237,  0.1858,  0.0195, -1.6461,  1.2033,\n                      -1.1356,  0.9976,  1.4343, -1.6561, -1.2746,  1.2244, -1.8058,  0.6088],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.mlp0.norm.weight',\n              tensor([3.7489, 3.6970, 3.4847,  ..., 3.6459, 3.3336, 3.2779], device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.mlp0.norm.bias',\n              tensor([-0.1014,  0.1387,  0.1121,  ..., -0.1565,  0.0079, -0.1248],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.mlp0.layer.weight',\n              tensor([[ 0.0226, -0.0212,  0.0134,  ..., -0.0068, -0.0172,  0.0068],\n                      [ 0.0085, -0.0134,  0.0144,  ...,  0.0188,  0.0024, -0.0002],\n                      [-0.0267, -0.0179, -0.0144,  ..., -0.0113, -0.0164,  0.0086],\n                      ...,\n                      [ 0.0077, -0.0173, -0.0259,  ..., -0.0005,  0.0083,  0.0081],\n                      [ 0.0041,  0.0049, -0.0251,  ...,  0.0149,  0.0173, -0.0158],\n                      [ 0.0047, -0.0086,  0.0119,  ...,  0.0135, -0.0004,  0.0094]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.mlp1.layer.weight',\n              tensor([[-0.0058, -0.0225,  0.0030,  ..., -0.0009, -0.0107, -0.0270],\n                      [ 0.0058, -0.0167, -0.0157,  ...,  0.0105, -0.0123, -0.0035],\n                      [-0.0106,  0.0107, -0.0076,  ...,  0.0017, -0.0018, -0.0143],\n                      ...,\n                      [-0.0102, -0.0039, -0.0175,  ...,  0.0056, -0.0020, -0.0058],\n                      [-0.0015,  0.0155, -0.0115,  ..., -0.0338, -0.0107, -0.0106],\n                      [ 0.0083, -0.0160, -0.0201,  ...,  0.0119,  0.0025, -0.0139]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.mlp1.layer.bias',\n              tensor([-0.4958,  0.2697, -0.4442,  ..., -0.6773,  0.1475, -0.3812],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.pre_r_ln.weight',\n              tensor([1.5689, 1.7689, 2.1141,  ..., 1.7605, 2.0321, 1.5566], device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.pre_r_ln.bias',\n              tensor([-0.0613, -0.0115, -0.0369,  ...,  0.1593, -0.0065,  0.4064],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.b_nd',\n              tensor([[ 7.8749e-02,  1.0838e-01, -1.4580e-01,  ..., -7.6605e-02,\n                       -7.8906e-02, -8.9769e-02],\n                      [ 1.6424e-01,  2.1198e-01,  6.2603e-02,  ..., -6.8088e-05,\n                       -2.3103e-02, -6.4094e-02],\n                      [ 2.1685e-01, -1.7343e-02, -3.8056e-02,  ..., -2.0934e-02,\n                       -1.0563e-02, -1.0377e-02],\n                      ...,\n                      [-4.6153e-02,  9.5272e-02,  6.8985e-02,  ..., -1.1517e-01,\n                       -1.3763e-01, -1.5259e-01],\n                      [ 2.3566e-01, -6.8452e-02, -7.2694e-02,  ...,  3.5166e-02,\n                        3.0357e-02,  1.1533e-02],\n                      [ 3.2740e-04, -9.4456e-02,  1.5718e-02,  ..., -8.1242e-02,\n                       -9.7631e-02, -1.2848e-01]], device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.q_layer.weight',\n              tensor([[ 0.0037, -0.0003, -0.0054,  ..., -0.0061, -0.0049, -0.0012],\n                      [-0.0060, -0.0071,  0.0043,  ...,  0.0025,  0.0046,  0.0053],\n                      [-0.0024,  0.0103,  0.0031,  ..., -0.0011,  0.0051, -0.0146],\n                      ...,\n                      [-0.0010,  0.0004, -0.0045,  ..., -0.0220, -0.0036,  0.0012],\n                      [-0.0034, -0.0158,  0.0058,  ...,  0.0077, -0.0036, -0.0027],\n                      [-0.0026, -0.0137, -0.0055,  ..., -0.0060,  0.0087, -0.0031]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.q_layer.bias',\n              tensor([-0.0338, -0.0323,  0.0859,  ..., -0.0633, -0.0341, -0.0135],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.k_layer.weight',\n              tensor([[ 0.0015, -0.0062, -0.0038,  ..., -0.0047, -0.0045,  0.0041],\n                      [ 0.0008, -0.0025,  0.0060,  ..., -0.0031,  0.0032,  0.0017],\n                      [-0.0102,  0.0136,  0.0091,  ...,  0.0053,  0.0097, -0.0078],\n                      ...,\n                      [-0.0152, -0.0054,  0.0065,  ..., -0.0078,  0.0023, -0.0024],\n                      [ 0.0143, -0.0010, -0.0044,  ..., -0.0080,  0.0030, -0.0004],\n                      [-0.0058, -0.0065, -0.0022,  ..., -0.0058,  0.0059, -0.0049]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.v_layer.weight',\n              tensor([[-0.0082, -0.0157, -0.0227,  ..., -0.0081, -0.0184,  0.0073],\n                      [ 0.0300, -0.0188, -0.0184,  ..., -0.0020,  0.0243, -0.0185],\n                      [-0.0054,  0.0006,  0.0128,  ...,  0.0312,  0.0042,  0.0023],\n                      ...,\n                      [ 0.0007, -0.0068,  0.0071,  ...,  0.0084, -0.0459, -0.0166],\n                      [-0.0224, -0.0155,  0.0230,  ...,  0.0007,  0.0064, -0.0017],\n                      [-0.0331,  0.0080, -0.0020,  ..., -0.0045,  0.0618,  0.0016]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.proj_layer.weight',\n              tensor([[-0.0162,  0.0015,  0.0018,  ..., -0.0303, -0.0017,  0.0078],\n                      [-0.0081,  0.0071,  0.0030,  ..., -0.0210,  0.0026, -0.0160],\n                      [ 0.0109, -0.0081,  0.0205,  ...,  0.0049, -0.0192,  0.0040],\n                      ...,\n                      [-0.0161,  0.0084,  0.0150,  ...,  0.0038, -0.0065,  0.0099],\n                      [ 0.0008,  0.0097, -0.0146,  ...,  0.0343, -0.0284, -0.0443],\n                      [-0.0149,  0.0215, -0.0005,  ...,  0.0006,  0.0151, -0.0015]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.proj_layer.bias',\n              tensor([-0.0734, -0.3515, -0.2003,  ..., -0.2159,  0.0963, -0.3036],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.r_layer.weight',\n              tensor([[-0.0007, -0.0162, -0.0079,  ...,  0.0105, -0.0037,  0.0007],\n                      [ 0.0165, -0.0011, -0.0080,  ..., -0.0187,  0.0058,  0.0063],\n                      [-0.0020, -0.0101, -0.0079,  ..., -0.0127, -0.0028,  0.0105],\n                      ...,\n                      [ 0.0054, -0.0004, -0.0015,  ...,  0.0141,  0.0248,  0.0082],\n                      [-0.0033, -0.0032, -0.0359,  ...,  0.0235, -0.0054, -0.0095],\n                      [-0.0104,  0.0063,  0.0124,  ...,  0.0054,  0.0139,  0.0157]],\n                     device='cuda:0')),\n             ('net.recurrent_layer.blocks.3.r.orc_block.r_layer.bias',\n              tensor([-0.0976, -0.0645, -0.0754,  0.0103, -0.1164,  0.2475,  0.2019, -0.2234,\n                      -0.0161, -0.0667,  0.2571,  0.3001, -0.2620, -0.2981,  0.2885, -0.0212,\n                       0.0803,  0.1238, -0.1750, -0.1955,  0.1129,  0.1577,  0.2963,  0.0070,\n                       0.0737, -0.1607,  0.1260, -0.2993,  0.3515, -0.0245,  0.2328, -0.9469,\n                       0.1128,  0.3299,  0.6665, -0.0222, -0.0810,  0.2341, -0.4013,  0.2707,\n                      -0.1442,  0.0204, -0.1234, -0.4653,  0.8009, -1.3392, -0.7741,  0.8578,\n                      -0.7297, -0.4571, -0.1860, -0.4585,  0.6408,  0.2652,  0.9405, -0.6271,\n                      -0.8448,  1.0675, -0.6386, -1.1482,  0.1376,  0.0414, -0.0387, -0.0693,\n                       0.3886, -0.2662, -0.1668,  0.2048, -0.1263, -0.2065, -0.5383,  0.2580,\n                      -0.2226, -1.0225,  0.3605, -1.5459, -0.9763,  0.7130, -0.8441, -0.2759,\n                       0.0853,  0.2043, -0.2983, -0.1430,  0.2349, -0.2877,  0.0266,  0.2421,\n                      -0.1418, -0.0300,  0.1524, -0.4927, -0.1206,  0.0406,  0.4231, -0.0403,\n                      -0.4064,  0.3188, -0.2373, -0.1419,  0.2925, -0.7857, -0.3271,  0.3143,\n                       0.7061, -0.0634, -0.6452,  0.4354, -0.1009, -0.0500,  1.0174,  1.5977,\n                      -0.5093, -0.6770,  1.4511, -0.8748,  0.4499,  1.1207, -0.6683, -0.9195,\n                       0.1022, -0.4188,  0.0194, -0.0149,  0.3876, -0.2106, -0.3323,  0.2377,\n                      -0.3479, -0.1727,  0.3860,  1.4745, -0.5567, -1.0433,  1.0331, -1.2682,\n                       0.1467,  0.9423, -0.5774, -0.6174,  0.1881, -0.5247, -0.1364,  0.0563,\n                       0.7038, -0.3573, -0.8745,  0.6347, -0.3893, -0.1531, -0.6479,  0.2399,\n                      -0.5312, -0.5893,  0.3343, -1.1836, -1.1149,  0.6779, -0.6129, -0.0592],\n                     device='cuda:0')),\n             ('net.lastlayer.norm.weight',\n              tensor([1.4087, 0.6617, 1.3752,  ..., 1.5473, 0.6071, 1.0437], device='cuda:0')),\n             ('net.lastlayer.norm.bias',\n              tensor([ 0.3860,  0.1143,  0.4320,  ...,  0.4645, -0.0615,  0.3099],\n                     device='cuda:0')),\n             ('net.lastlayer.layer.weight',\n              tensor([[ 0.0144, -0.0103, -0.0184,  ..., -0.0110,  0.0071, -0.0498],\n                      [ 0.0084,  0.0330,  0.0186,  ...,  0.0106,  0.0018,  0.0222],\n                      [-0.0047, -0.0062,  0.0129,  ..., -0.0084, -0.0116, -0.0077],\n                      ...,\n                      [-0.0047,  0.0077, -0.0136,  ..., -0.0041,  0.0137,  0.0065],\n                      [ 0.0044, -0.0224, -0.0055,  ..., -0.0020, -0.0272, -0.0174],\n                      [ 0.0132, -0.0129,  0.0001,  ...,  0.0008,  0.0170,  0.0067]],\n                     device='cuda:0')),\n             ('net.final_ln.weight',\n              tensor([0.9917, 0.9264, 0.8079,  ..., 1.3155, 0.7825, 0.5825], device='cuda:0')),\n             ('net.final_ln.bias',\n              tensor([-0.0411, -0.5579, -0.1228,  ...,  0.2248, -0.6086, -0.6180],\n                     device='cuda:0')),\n             ('value_head.linear.weight',\n              tensor([[ 0.0555, -0.0019,  0.0012,  ...,  0.0184, -0.0011,  0.0065]],\n                     device='cuda:0')),\n             ('value_head.linear.bias', tensor([-0.], device='cuda:0')),\n             ('value_head.normalizer.running_mean',\n              tensor([0.], device='cuda:0')),\n             ('value_head.normalizer.running_mean_sq',\n              tensor([0.], device='cuda:0')),\n             ('value_head.normalizer.debiasing_term',\n              tensor(0., device='cuda:0')),\n             ('pi_head.buttons.linear_layer.weight',\n              tensor([[ 0.0015,  0.0003,  0.0014,  ...,  0.0003,  0.0009,  0.0015],\n                      [-0.1603,  0.0289, -0.2256,  ..., -0.0225, -0.0022, -0.0972],\n                      [ 0.0641, -0.0628, -0.0276,  ..., -0.0205,  0.0194,  0.0161],\n                      ...,\n                      [ 0.0015,  0.0003,  0.0014,  ...,  0.0003,  0.0009,  0.0015],\n                      [ 0.0015,  0.0003,  0.0014,  ...,  0.0003,  0.0009,  0.0015],\n                      [-0.0088,  0.0645, -0.0502,  ..., -0.0171,  0.0117,  0.0017]],\n                     device='cuda:0')),\n             ('pi_head.buttons.linear_layer.bias',\n              tensor([-0.0800,  2.6498,  0.8246,  ..., -0.0800, -0.0801,  1.5611],\n                     device='cuda:0')),\n             ('pi_head.camera.linear_layer.weight',\n              tensor([[ 0.0262,  0.0113,  0.0105,  ..., -0.0463,  0.0577, -0.0036],\n                      [ 0.0201, -0.0019,  0.0167,  ..., -0.0657,  0.0569, -0.0059],\n                      [ 0.0168, -0.0272,  0.0198,  ..., -0.0870,  0.0308, -0.0218],\n                      ...,\n                      [ 0.0184,  0.0299, -0.0019,  ...,  0.0063, -0.0344,  0.0091],\n                      [ 0.0114,  0.0234,  0.0062,  ...,  0.0096, -0.0368,  0.0212],\n                      [ 0.0052,  0.0562, -0.0213,  ..., -0.0005,  0.0220,  0.0389]],\n                     device='cuda:0')),\n             ('pi_head.camera.linear_layer.bias',\n              tensor([-0.1451, -0.7914, -0.6136, -0.7570, -0.7617, -0.1521, -0.8030, -0.7344,\n                      -0.5421, -0.7060, -0.2131, -0.3936, -0.6935, -0.4585, -0.5602, -0.5796,\n                      -0.4533, -0.5607, -0.4832, -0.4369, -0.6796, -0.4444, -0.0587, -0.3975,\n                      -0.1524, -0.2416, -0.1467,  0.0402, -0.1248, -0.1413, -0.1015, -0.3395,\n                      -0.0614, -0.2351, -0.3006, -0.0146, -0.1586, -0.1108,  0.0323, -0.0702,\n                      -0.0356,  0.0446, -0.2746, -0.2060, -0.3405, -0.2554,  0.1772,  0.1266,\n                       0.3750,  0.9970,  0.4928,  0.2718,  0.2137, -0.2697, -0.2857,  0.5020,\n                      -0.0392,  0.4247,  0.3789,  1.4484, -0.4786,  1.3129,  0.3736,  0.3616,\n                      -0.0606,  0.5134, -0.3440, -0.1841,  0.2973,  0.2813,  0.6354,  1.0353,\n                       0.3840,  0.1669,  0.2654, -0.1675, -0.2480, -0.2500, -0.2285,  0.1004,\n                      -0.0913, -0.0184,  0.1137, -0.0973, -0.1551, -0.0484, -0.3246, -0.1809,\n                      -0.0467, -0.3101, -0.0680, -0.2163, -0.1523,  0.0576, -0.1794, -0.2196,\n                      -0.0852, -0.3613, -0.0087, -0.4192, -0.6992, -0.4688, -0.5815, -0.5828,\n                      -0.4616, -0.6188, -0.5697, -0.4360, -0.7159, -0.4021, -0.2008, -0.7374,\n                      -0.5326, -0.7210, -0.7639, -0.2124, -0.7857, -0.7835, -0.5467, -0.7604,\n                      -0.1777], device='cuda:0'))])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "in_model = \"../data/VPT-models/2x.model\"\n",
    "in_weights = \"../data/VPT-models/foundation-model-2x.weights\"\n",
    "out_weights = \"../data/agent_st/foundation-model-tl-tt-2x.weights\"\n",
    "\n",
    "environment = \"MineRLBasaltFindCave-v0\"\n",
    "device = \"cuda\"\n",
    "\n",
    "old_state_dict = torch.load(in_weights, map_location=device)\n",
    "\n",
    "old_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transfer Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.lib.policy import MinecraftAgentPolicy as MinecraftAgentPolicy\n",
    "\n",
    "from src.agent import ACTION_TRANSFORMER_KWARGS\n",
    "import pickle\n",
    "from src.lib.actions import ActionTransformer\n",
    "from gym3.types import DictType, Discrete, TensorType\n",
    "from src.lib.action_mapping import CameraHierarchicalMapping\n",
    "\n",
    "agent_parameters = pickle.load(open(in_model, \"rb\"))\n",
    "policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "action_mapper = CameraHierarchicalMapping(n_camera_bins=11)\n",
    "action_space = action_mapper.get_action_space_update()\n",
    "action_space = DictType(**action_space)\n",
    "\n",
    "action_transformer = ActionTransformer(**ACTION_TRANSFORMER_KWARGS)\n",
    "\n",
    "agent_kwargs = dict(policy_kwargs=policy_kwargs, pi_head_kwargs=pi_head_kwargs, action_space=action_space)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_kwargs={'active_reward_monitors': {'craft_stats': {'args': {'collapse_var': True, 'items': ['planks', 'stick', 'crafting_table', 'wooden_pickaxe', 'stone_pickaxe', 'furnace', 'iron_ingot', 'iron_pickaxe', 'diamond_pickaxe', 'torch']}, 'weight': 0}, 'mine_stats': {'args': {'collapse_var': True, 'items': ['log', 'coal_ore', 'stone', 'iron_ore', 'diamond_ore', 'obsidian']}, 'weight': 0}, 'order_invariant_curriculum': {'args': {'curriculum': {'coal': [5, 0.4], 'cobblestone': [11, 0.09090909090909091], 'crafting_table': [1, 1], 'diamond': [10000, 2.6666666666666665], 'diamond_pickaxe': [10000, 8], 'furnace': [1, 1], 'iron_ingot': [3, 1.3333333333333333], 'iron_ore': [3, 1.3333333333333333], 'iron_pickaxe': [1, 4], 'log': [8, 0.125], 'obsidian': [10000, 16], 'planks': [20, 0.05], 'stick': [16, 0.0625], 'stone_pickaxe': [1, 1], 'torch': [16, 0.125], 'wooden_pickaxe': [1, 1]}}, 'weight': 1}, 'pickup_stats': {'args': {'collapse_var': True, 'items': ['log', 'coal', 'cobblestone', 'iron_ore', 'diamond']}, 'weight': 0}, 'variety': {'args': {'collapse_var': True, 'included_items': ['beef', 'chicken', 'leather', 'mutton', 'porkchop', 'bucket', 'milk_bucket', 'water_bucket', 'coal', 'crafting_table', 'furnace', 'diamond', 'gold_ingot', 'gold_ore', 'flint', 'iron_ingot', 'iron_ore', 'shears', 'string', 'cobblestone', 'log', 'planks', 'stick', 'wool', 'obsidian', 'paper', 'redstone', 'wheat', 'cooked_beef', 'cooked_chicken', 'cooked_mutton', 'cooked_porkchop', 'egg', 'feather', 'leather_boots', 'leather_chestplate', 'leather_helmet', 'leather_leggings', 'brick', 'brick_stairs', 'clay', 'clay_ball', 'flower_pot', 'terracotta', 'torch', 'diamond_axe', 'diamond_block', 'diamond_boots', 'diamond_chestplate', 'diamond_helmet', 'diamond_hoe', 'diamond_leggings', 'diamond_pickaxe', 'diamond_shovel', 'diamond_sword', 'dirt', 'golden_apple', 'golden_axe', 'golden_boots', 'golden_chestplate', 'golden_helmet', 'golden_hoe', 'golden_leggings', 'golden_pickaxe', 'golden_shovel', 'golden_sword', 'arrow', 'gravel', 'iron_axe', 'iron_boots', 'iron_chestplate', 'iron_helmet', 'iron_hoe', 'iron_leggings', 'iron_pickaxe', 'iron_shovel', 'iron_sword', 'shield', 'fermented_spider_eye', 'leaves', 'apple', 'bread', 'activator_rail', 'clock', 'compass', 'detector_rail', 'dropper', 'book', 'bookshelf', 'cake', 'filled_map', 'sugar_cane', 'sugar', 'bow', 'dispenser', 'fishing_rod', 'spider_eye', 'stone_axe', 'stone_hoe', 'stone_pickaxe', 'stone_shovel', 'stone_sword', 'boat', 'wooden_axe', 'wooden_hoe', 'wooden_pickaxe', 'wooden_shovel', 'wooden_sword', 'banner', 'bed', 'carpet', 'map', 'redstone_torch', 'wheat_seeds', 'flint_and_steel']}, 'weight': 0}}, 'attention_heads': 16, 'attention_mask_style': 'clipped_causal', 'attention_memory_size': 256, 'diff_mlp_embedding': False, 'hidsize': 2048, 'img_shape': [128, 128, 3], 'impala_chans': [16, 32, 32], 'impala_kwargs': {'post_pool_groups': 1}, 'impala_width': 8, 'init_norm_kwargs': {'batch_norm': False, 'group_norm_groups': 1}, 'n_recurrence_layers': 4, 'only_img_input': True, 'pointwise_ratio': 4, 'pointwise_use_activation': False, 'recurrence_is_residual': True, 'recurrence_type': 'transformer', 'timesteps': 128, 'use_pointwise_layer': True, 'use_pre_lstm_ln': False}\n",
      "COPY for net.img_process.cnn.stacks.0.firstconv.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.0.firstconv.layer.bias\n",
      "COPY for net.img_process.cnn.stacks.0.n.weight\n",
      "COPY for net.img_process.cnn.stacks.0.n.bias\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.0.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.0.blocks.1.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.1.firstconv.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.1.firstconv.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.1.firstconv.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.1.n.weight\n",
      "COPY for net.img_process.cnn.stacks.1.n.bias\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.0.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.1.blocks.1.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.2.firstconv.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.2.firstconv.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.2.firstconv.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.2.n.weight\n",
      "COPY for net.img_process.cnn.stacks.2.n.bias\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.0.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv0.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv0.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv0.layer.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv1.norm.weight\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv1.norm.bias\n",
      "COPY for net.img_process.cnn.stacks.2.blocks.1.conv1.layer.weight\n",
      "COPY for net.img_process.cnn.dense.norm.weight\n",
      "COPY for net.img_process.cnn.dense.norm.bias\n",
      "COPY for net.img_process.cnn.dense.layer.weight\n",
      "COPY for net.img_process.linear.norm.weight\n",
      "COPY for net.img_process.linear.norm.bias\n",
      "COPY for net.img_process.linear.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.mlp0.norm.weight\n",
      "COPY for net.recurrent_layer.blocks.0.mlp0.norm.bias\n",
      "COPY for net.recurrent_layer.blocks.0.mlp0.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.mlp1.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.mlp1.layer.bias\n",
      "COPY for net.recurrent_layer.blocks.0.pre_r_ln.weight\n",
      "COPY for net.recurrent_layer.blocks.0.pre_r_ln.bias\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.b_nd\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.q_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.q_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.k_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.v_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.proj_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.proj_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.r_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.0.r.orc_block.r_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.1.mlp0.norm.weight\n",
      "COPY for net.recurrent_layer.blocks.1.mlp0.norm.bias\n",
      "COPY for net.recurrent_layer.blocks.1.mlp0.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.mlp1.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.mlp1.layer.bias\n",
      "COPY for net.recurrent_layer.blocks.1.pre_r_ln.weight\n",
      "COPY for net.recurrent_layer.blocks.1.pre_r_ln.bias\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.b_nd\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.q_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.q_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.k_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.v_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.proj_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.proj_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.r_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.1.r.orc_block.r_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.2.mlp0.norm.weight\n",
      "COPY for net.recurrent_layer.blocks.2.mlp0.norm.bias\n",
      "COPY for net.recurrent_layer.blocks.2.mlp0.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.mlp1.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.mlp1.layer.bias\n",
      "COPY for net.recurrent_layer.blocks.2.pre_r_ln.weight\n",
      "COPY for net.recurrent_layer.blocks.2.pre_r_ln.bias\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.b_nd\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.q_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.q_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.k_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.v_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.proj_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.proj_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.r_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.2.r.orc_block.r_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.3.mlp0.norm.weight\n",
      "COPY for net.recurrent_layer.blocks.3.mlp0.norm.bias\n",
      "COPY for net.recurrent_layer.blocks.3.mlp0.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.mlp1.layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.mlp1.layer.bias\n",
      "COPY for net.recurrent_layer.blocks.3.pre_r_ln.weight\n",
      "COPY for net.recurrent_layer.blocks.3.pre_r_ln.bias\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.b_nd\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.q_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.q_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.k_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.v_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.proj_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.proj_layer.bias\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.r_layer.weight\n",
      "COPY for net.recurrent_layer.blocks.3.r.orc_block.r_layer.bias\n",
      "COPY for net.lastlayer.norm.weight\n",
      "COPY for net.lastlayer.norm.bias\n",
      "COPY for net.lastlayer.layer.weight\n",
      "COPY for net.final_ln.weight\n",
      "COPY for net.final_ln.bias\n",
      "COPY for value_head.linear.weight\n",
      "COPY for value_head.linear.bias\n",
      "COPY for value_head.normalizer.running_mean\n",
      "COPY for value_head.normalizer.running_mean_sq\n",
      "COPY for value_head.normalizer.debiasing_term\n",
      "COPY for pi_head.buttons.linear_layer.weight\n",
      "COPY for pi_head.buttons.linear_layer.bias\n",
      "COPY for pi_head.camera.linear_layer.weight\n",
      "COPY for pi_head.camera.linear_layer.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new model with a different architecture\n",
    "new_model = MinecraftAgentPolicy(**agent_kwargs)\n",
    "\n",
    "# Initialize a dictionary to keep track of the layers in the new model that will be initialized with weights from the old model\n",
    "new_state_dict = {}\n",
    "\n",
    "# Iterate through the state_dict of the old model\n",
    "for key, value in old_state_dict.items():\n",
    "    # Check if the layer name in the old model corresponds to a layer in the new model\n",
    "    if key in new_model.state_dict():\n",
    "        # If it does, add the layer and its weights to the new_state_dict\n",
    "        print(f\"COPY for {key}\")\n",
    "        new_state_dict[key] = value\n",
    "    else:\n",
    "        print(f\"DO NOT COPY for {key}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "_IncompatibleKeys(missing_keys=['net.add_subtasks.norm.weight', 'net.add_subtasks.norm.bias', 'net.add_subtasks.layers.0.weight', 'net.add_subtasks.layers.1.weight'], unexpected_keys=[])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the state_dict of the new model with the layers and weights from the old model\n",
    "new_model.load_state_dict(new_state_dict, strict=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0188, -0.0292, -0.0034,  ..., -0.0010, -0.0067,  0.0018],\n       device='cuda:0')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_state_dict['net.recurrent_layer.blocks.2.r.orc_block.proj_layer.weight'][10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "state_dict = new_model.state_dict()\n",
    "torch.save(state_dict, out_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
