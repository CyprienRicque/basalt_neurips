{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import DataLoader\n",
    "\n",
    "# N_WORKERS = 8\n",
    "# BATCH_SIZE = 8\n",
    "# EPOCHS = 3\n",
    "\n",
    "# data_loader = DataLoader(\n",
    "#     dataset_dir=\"../basalt_neurips_data/BuildWaterFall\",\n",
    "#     n_workers=N_WORKERS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     n_epochs=EPOCHS,\n",
    "#     dataset_max_size=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from src.openai_vpt.preprocessing import MineRLAgentPP\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import gym\n",
    "import minerl\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.openai_vpt.agent import PI_HEAD_KWARGS, MineRLAgent\n",
    "from src.data_loader import DataLoader\n",
    "from src.openai_vpt.lib.tree_util import tree_map\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Originally this code was designed for a small dataset of ~20 demonstrations per task.\n",
    "# The settings might not be the best for the full BASALT dataset (thousands of demonstrations).\n",
    "# Use this flag to switch between the two settings\n",
    "USING_FULL_DATASET = False\n",
    "\n",
    "EPOCHS = 1 if USING_FULL_DATASET else 1\n",
    "# Needs to be <= number of videos\n",
    "BATCH_SIZE = 64 if USING_FULL_DATASET else 8\n",
    "# Ideally more than batch size to create\n",
    "# variation in datasets (otherwise, you will\n",
    "# get a bunch of consecutive samples)\n",
    "# Decrease this (and batch_size) if you run out of memory\n",
    "N_WORKERS = 100 if USING_FULL_DATASET else 16\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "LOSS_REPORT_RATE = 100\n",
    "\n",
    "# Tuned with bit of trial and error\n",
    "LEARNING_RATE = 0.000181\n",
    "# OpenAI VPT BC weight decay\n",
    "# WEIGHT_DECAY = 0.039428\n",
    "WEIGHT_DECAY = 0.0\n",
    "# KL loss to the original model was not used in OpenAI VPT\n",
    "KL_LOSS_WEIGHT = 1.0\n",
    "MAX_GRAD_NORM = 5.0\n",
    "\n",
    "# MAX_BATCHES = 2000 if USING_FULL_DATASET else int(1e9)\n",
    "# MAX_BATCHES = 10\n",
    "\n",
    "MAX_EPISODES = 16\n",
    "\n",
    "data_dir = \"../basalt_neurips_data/BuildWaterFall/\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Shuffle is set to false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset_dir=data_dir,\n",
    "    n_workers=N_WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=EPOCHS,\n",
    "    dataset_max_size=MAX_EPISODES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Keep track of the hidden state per episode/trajectory.\n",
    "# DataLoader provides unique id for each episode, which will\n",
    "# be different even for the same trajectory when it is loaded\n",
    "# up again\n",
    "\n",
    "episode_hidden_states = {}\n",
    "dummy_first = torch.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "agent = MineRLAgentPP(\n",
    "    env=\"MineRLBasaltMakeWaterfall-v0\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "\n",
    "def training_loop(pbar):\n",
    "\n",
    "    for batch_i, (batch_images, batch_actions, batch_episode_id) in pbar:\n",
    "        batch_loss = 0\n",
    "        for image, action, episode_id in zip(\n",
    "            batch_images, batch_actions, batch_episode_id\n",
    "        ):\n",
    "\n",
    "            \"\"\"\n",
    "            action={'ESC': 0, 'back': 0, 'drop': 0, 'forward': 0, 'hotbar.1': 0, 'hotbar.2': 0, 'hotbar.3': 0, 'hotbar.4': 0, 'hotbar.5': 0, 'hotbar.6': 0, 'hotbar.7': 0, 'hotbar.8': 0, 'hotbar.9': 0, 'inventory': 0, 'jump': 0, 'left': 0, 'right': 0, 'sneak': 0, 'sprint': 0, 'swapHands': 0, 'camera': array([ 0, -1]), 'attack': 0, 'use': 0, 'pickItem': 0}\n",
    "\n",
    "            image.shape=(128, 128, 3)\n",
    "            \"\"\"\n",
    "\n",
    "            if image is None and action is None:\n",
    "                # A work-item was done. Remove hidden state\n",
    "                if episode_id in episode_hidden_states:\n",
    "                    removed_hidden_state = episode_hidden_states.pop(episode_id)\n",
    "                    del removed_hidden_state\n",
    "                continue\n",
    "\n",
    "            agent_action = agent._env_action_to_agent(action, to_torch=True, check_if_null=True)\n",
    "            if agent_action is None:\n",
    "                continue\n",
    "\n",
    "            agent_obs = agent._env_obs_to_agent({\"pov\": image})\n",
    "\n",
    "            \"\"\"\n",
    "            agent_action={'buttons': tensor([[288]], device='cuda:0'), 'camera': tensor([[60]], device='cuda:0')}\n",
    "\n",
    "            agent_obs.keys()=dict_keys(['img'])\n",
    "            agent_obs['img'].shape=torch.Size([1, 128, 128, 3])\n",
    "            \"\"\"\n",
    "            agent_action_input = torch.concat((agent_action[\"buttons\"], agent_action[\"camera\"]), dim=1)\n",
    "            yield agent_obs[\"img\"], agent_action_input, episode_id\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0000:   0%|          | 11/3792 [00:00<00:51, 73.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 0\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 3\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 7\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 12\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 14\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 3\n",
      "torch.Size([1, 128, 128, 3]) torch.Size([1, 2]) 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.end2end_vid_segmentation_rcnn import VideoSegmentationModel\n",
    "\n",
    "model = VideoSegmentationModel(128, 2, 3).to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_sum = 0\n",
    "pbar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Avg loss: {loss_sum / LOSS_REPORT_RATE:.4f}\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "for image_tensor, action_tensor, episode_id in training_loop(pbar):\n",
    "    print(image_tensor.shape, action_tensor.shape, episode_id)\n",
    "\n",
    "    # Initialize batch loss\n",
    "    batch_loss = 0\n",
    "\n",
    "    batch_size = 1  # FIXME\n",
    "    # Initialize hidden state for the current batch\n",
    "    hidden_state = model.init_hidden(batch_size)  # FIXME\n",
    "\n",
    "    # Forward pass through the model\n",
    "    logits, hidden_state = model(image_tensor, action_tensor, hidden_state)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(logits, action_tensor)\n",
    "    batch_loss += loss.item()\n",
    "\n",
    "    # Backpropagate the error and update the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update progress bar with average loss for the current batch\n",
    "    pbar.set_description(f\"Avg loss: {batch_loss / len(batch_images):.4f}\")\n",
    "    loss_sum += batch_loss\n",
    "\n",
    "    # Stop training if maximum number of batches has been reached\n",
    "    if batch_i > MAX_BATCHES:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pbar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Avg loss: {loss_sum / LOSS_REPORT_RATE:.4f}\")\n",
    "\n",
    "# Loop through data loader\n",
    "for batch_i, (batch_images, batch_actions, batch_episode_id) in pbar:\n",
    "    # Initialize batch loss\n",
    "    batch_loss = 0\n",
    "\n",
    "    # Initialize hidden state for the current batch\n",
    "    hidden_state = model.init_hidden(batch_size)\n",
    "\n",
    "    # Process each image and action in the batch\n",
    "    for image, action, episode_id in zip(batch_images, batch_actions, batch_episode_id):\n",
    "        if image is None and action is None:\n",
    "            # A work-item was done. Remove hidden state\n",
    "            if episode_id in episode_hidden_states:\n",
    "                removed_hidden_state = episode_hidden_states.pop(episode_id)\n",
    "                del removed_hidden_state\n",
    "            continue\n",
    "\n",
    "        # Convert image and action to tensors\n",
    "        image_tensor = torch.from_numpy(image).to(DEVICE)\n",
    "        action_tensor = torch.from_numpy(action).to(DEVICE)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        logits, hidden_state = model(image_tensor, hidden_state)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(logits, action_tensor)\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        # Backpropagate the error and update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Update progress bar with average loss for the current batch\n",
    "    pbar.set_description(f\"Avg loss: {batch_loss / len(batch_images):.4f}\")\n",
    "    loss_sum += batch_loss\n",
    "\n",
    "    # Stop training if maximum number of batches has been reached\n",
    "    if batch_i > MAX_BATCHES:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "action = {'ESC': 1, 'back': 0, 'drop': 0, 'forward': 0, 'hotbar.1': 0, 'hotbar.2': 0, 'hotbar.3': 0, 'hotbar.4': 0, 'hotbar.5': 0, 'hotbar.6': 0, 'hotbar.7': 0, 'hotbar.8': 0, 'hotbar.9': 0, 'inventory': 0, 'jump': 0, 'left': 0, 'right': 0, 'sneak': 0, 'sprint': 0, 'swapHands': 0, 'camera': np.array([0, 0]), 'attack': 0, 'use': 0, 'pickItem': 0}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def print_raw_action(action):\n",
    "    print(\"[[[[[[[[[[[[[[[[\")\n",
    "    for e, f in action.items():\n",
    "        if (isinstance(f, np.ndarray) and (f[0] or f[1])) or (not isinstance(f, np.ndarray) and f != 0):\n",
    "            print(f\"{e}: {' ' * (10 - len(e))}{f}\")\n",
    "    print(\"]]]]]]]]]]]]]]]]\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Shuffle is set to false\n",
      "Avg loss: 0.0000:   0%|          | 3/7029 [00:00<03:55, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is NOT null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "camera:     [-4 24]\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is NOT null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "camera:     [ 2 -2]\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n",
      "Action is null:\n",
      "[[[[[[[[[[[[[[[[\n",
      "]]]]]]]]]]]]]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset_dir=data_dir,\n",
    "    n_workers=N_WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=EPOCHS,\n",
    "    dataset_max_size=10,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Keep track of the hidden state per episode/trajectory.\n",
    "# DataLoader provides unique id for each episode, which will\n",
    "# be different even for the same trajectory when it is loaded\n",
    "# up again\n",
    "episode_hidden_states = {}\n",
    "dummy_first = torch.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "agent = MineRLAgentPP(\n",
    "    env=\"MineRLBasaltMakeWaterfall-v0\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "loss_sum = 0\n",
    "pbar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Avg loss: {loss_sum / LOSS_REPORT_RATE:.4f}\")\n",
    "\n",
    "for batch_i, (batch_images, batch_actions, batch_episode_id) in pbar:\n",
    "    batch_loss = 0\n",
    "    for image, action, episode_id in zip(\n",
    "        batch_images, batch_actions, batch_episode_id\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        action={'ESC': 0, 'back': 0, 'drop': 0, 'forward': 0, 'hotbar.1': 0, 'hotbar.2': 0, 'hotbar.3': 0, 'hotbar.4': 0, 'hotbar.5': 0, 'hotbar.6': 0, 'hotbar.7': 0, 'hotbar.8': 0, 'hotbar.9': 0, 'inventory': 0, 'jump': 0, 'left': 0, 'right': 0, 'sneak': 0, 'sprint': 0, 'swapHands': 0, 'camera': array([ 0, -1]), 'attack': 0, 'use': 0, 'pickItem': 0}\n",
    "\n",
    "        image.shape=(128, 128, 3)\n",
    "        \"\"\"\n",
    "\n",
    "        if image is None and action is None:\n",
    "            # A work-item was done. Remove hidden state\n",
    "            if episode_id in episode_hidden_states:\n",
    "                removed_hidden_state = episode_hidden_states.pop(episode_id)\n",
    "                del removed_hidden_state\n",
    "            continue\n",
    "\n",
    "\n",
    "        agent_action = agent._env_action_to_agent(\n",
    "            action, to_torch=True, check_if_null=True\n",
    "        )\n",
    "\n",
    "        if agent_action is None:\n",
    "            continue\n",
    "\n",
    "        agent_obs = agent._env_obs_to_agent({\"pov\": image})\n",
    "\n",
    "        \"\"\"\n",
    "        agent_action={'buttons': tensor([[288]], device='cuda:0'), 'camera': tensor([[60]], device='cuda:0')}\n",
    "\n",
    "        agent_obs.keys()=dict_keys(['img'])\n",
    "        agent_obs['img'].shape=torch.Size([1, 128, 128, 3])\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    if batch_i > MAX_BATCHES:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
